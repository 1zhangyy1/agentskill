{
  "id": "66594d1e4dc65945",
  "slug": "langconfig",
  "name": "Langconfig",
  "description": "LangConfig is a open-source visual workflow builder designed to make AI agent development accessible to everyone. Build, test, and share LangChain and LangGraph agent workflows with an intuitive drag-",
  "author": "LangConfig",
  "authorAvatar": "https://avatars.githubusercontent.com/u/245523204?v=4",
  "repoUrl": "https://github.com/LangConfig/langconfig",
  "repoFullName": "LangConfig/langconfig",
  "stars": 8,
  "forks": 0,
  "category": "testing",
  "categories": [
    "testing"
  ],
  "tags": [],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-12-01T17:28:59Z",
  "updatedAt": "2025-12-16T20:19:06Z",
  "lastCommitAt": "2025-12-16T20:19:08Z",
  "source": "github-search",
  "collectedAt": "2025-12-17T03:30:47.758Z",
  "authorUrl": "https://github.com/LangConfig",
  "license": "MIT",
  "readme": "# LangConfig\n\n[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)\n[![Node](https://img.shields.io/badge/Node-18+-green.svg)](https://nodejs.org/)\n[![React](https://img.shields.io/badge/React-19-blue.svg)](https://react.dev/)\n[![LangChain](https://img.shields.io/badge/LangChain-v1.0-orange.svg)](https://langchain.com/)\n[![LangGraph](https://img.shields.io/badge/LangGraph-latest-orange.svg)](https://langchain-ai.github.io/langgraph/)\n\n\n<img width=\"2615\" height=\"816\" alt=\"Langconfig Banner\" src=\"https://github.com/user-attachments/assets/059f5595-2a48-4fae-bab8-5760661bcbb5\" />\n\n\n\n# Open-source visual platform for building, testing, and deploying LangChain agents and LangGraph workflows.\n\nLangConfig makes agentic AI accessible. Build LangChain Agents and Deep Agents with full control over their toolsets, prompts, and memory configurations—no coding required.\n\nDrop agents onto a visual canvas and connect them into multi-agent LangGraph workflows. Run workflows and watch agent thinking, tool selection, outputs, and errors in real-time. Test a workflow, review the output, tweak tools or RAG settings, run it again, and compare results—all in one place.\n\nCreate custom tools using LangChain's middleware system, or use prebuilt templates for Discord, Slack, and other integrations. Open a chat interface with any agent to collaboratively improve its system prompt, test behavior, and get feedback. Conversation context flows seamlessly into workflow execution with simple on/off controls.\n\nWhen you're ready to share or deploy, export your workflow as a JSON config that anyone with LangConfig can import instantly. Or download a complete Python package—LangChain/LangGraph code, execution scripts, and a Streamlit web UI—ready to run anywhere.\n\nLangConfig includes workflow templates for research and content creation. We're actively building new features and templates to make it easy to pick up and start experimenting with agentic AI.\n\n---\n\n## Key Features\n\n- **Visual Workflow Builder** - Drag-and-drop LangGraph state graphs on an interactive canvas\n- **Custom Agent Builder** - Create specialized agents with AI-generated configurations\n- **Interactive Chat Testing** - Test agents with live streaming, tool execution visibility, and document upload\n- **RAG Knowledge Base** - Upload documents (PDF, DOCX, code) for semantic search with pgvector\n- **Multi-Model Support** - OpenAI (GPT-4o, GPT-5), Anthropic (Claude 4.5 Sonnet/Opus/Haiku), Google (Gemini 3 Pro, Gemini 2.5), DeepSeek, local models (Ollama, LM Studio)\n- **Custom Tool Builder** - Create specialized tools beyond built-in MCP servers\n- **Real-Time Monitoring** - Watch agent execution, tool calls, token usage, and costs live\n- **Export to Code** - Generate standalone Python packages with Streamlit UI, or view LangGraph code\n- **Human-in-the-Loop** - Add approval checkpoints for critical decisions - Still Experimental\n- **Advanced Memory** - Short-term (LangGraph checkpoints) and long-term (pgvector + LangGraph Store) persistence\n- **Local-First** - All data stays on your machine\n\n<img width=\"1872\" height=\"930\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a4c3ad34-39ee-4792-9f1d-77e563c6e3f3\" />\n\n---\n\n## Quick Start\n\n### Prerequisites\n\n- **Node.js** 18+ ([Download](https://nodejs.org/))\n- **Python** 3.10+ ([Download](https://www.python.org/downloads/))\n- **Docker Desktop** ([Download](https://www.docker.com/products/docker-desktop/))\n\n### Installation\n\n**1. Clone Repository**\n```bash\ngit clone https://github.com/langconfig/langconfig.git\ncd langconfig\n```\n\n**2. Install Frontend Dependencies**\n```bash\nnpm install\n```\n\n**3. Run Backend Setup Script**\n```bash\npython backend/scripts/setup.py\n```\n\nThis automated script will:\n- Check Python 3.11+ and Docker prerequisites\n- Create `.env` from `.env.example`\n- Install backend Python dependencies\n- Start PostgreSQL via Docker\n- Initialize the database and seed agent templates\n\n**4. Add Your API Keys**\n\nEdit `.env` and add your API keys:\n```env\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\nGOOGLE_API_KEY=AIza...\n```\n\n---\n\n## Running LangConfig\n\n### Web App Mode (Recommended)\n\n**Terminal 1 - Start Backend:**\n```bash\ncd backend\npython main.py\n```\n\nBackend runs at: `http://127.0.0.1:8765`\n\n**Terminal 2 - Start Frontend:**\n```bash\nnpm run dev\n```\n\nFrontend runs at: `http://localhost:1420`\n\nOpen your browser to `http://localhost:1420`\n\n### Desktop App Mode (Advanced)\n\nRequires **Rust** ([Install](https://rustup.rs/))\n\n**Windows users**: Install [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022)\n\n```bash\n# Start backend in Terminal 1\ncd backend\npython main.py\n\n# Start desktop app in Terminal 2\nnpm run tauri dev\n```\n\nThis opens a native desktop window instead of a browser.\n\n---\n\n## Project Structure\n\n```\nlangconfig/\n├── src/                      # React 19 frontend (TypeScript + Tailwind)\n│   ├── features/\n│   │   ├── workflows/        # Visual canvas & workflow management\n│   │   ├── agents/           # Agent builder & library\n│   │   ├── chat/             # Interactive chat testing\n│   │   ├── knowledge/        # RAG document upload\n│   │   ├── memory/           # Memory visualization\n│   │   ├── tools/            # Custom tool builder\n│   │   └── settings/         # App settings & API keys\n│   ├── components/           # Shared UI components\n│   ├── contexts/             # React context providers\n│   ├── hooks/                # Custom React hooks\n│   └── lib/                  # API client & utilities\n├── backend/                  # Python FastAPI backend\n│   ├── api/                  # REST API routes\n│   │   ├── workflows/        # Workflow execution & management\n│   │   ├── agents/           # Agent CRUD & templates\n│   │   ├── chat/             # Chat sessions & streaming\n│   │   ├── knowledge/        # Document upload & RAG\n│   │   ├── tools/            # Custom tool management\n│   │   └── settings/         # API keys & configuration\n│   ├── core/\n│   │   ├── workflows/        # LangGraph orchestration engine\n│   │   ├── agents/           # Agent factory & base classes\n│   │   ├── templates/        # Pre-built agent & workflow templates\n│   │   ├── tools/            # Native and custom tool integrations\n│   │   ├── codegen/          # Python code export generation\n│   │   └── middleware/       # LangGraph middleware (RAG, validation)\n│   ├── services/             \n│   │   ├── context_retrieval.py    # RAG retrieval with HyDE\n│   │   ├── llama_config.py         # Vector store (pgvector)\n│   │   └── token_counter.py        # Token tracking & cost calculation\n│   ├── models/               # SQLAlchemy ORM models\n│   ├── middleware/           # FastAPI middleware (performance, CORS)\n│   ├── db/                   # Database initialization\n│   │   ├── init_postgres.sql       # pgvector setup (auto-run on Docker start)\n│   │   └── init_deepagents.py      # Seed agent templates\n│   └── alembic/              # Database migrations\n├── docs/                     # Documentation\n├── scripts/                  # Utility scripts\n├── src-tauri/                # Tauri desktop app (optional)\n├── docker-compose.yml        # PostgreSQL + pgvector setup\n└── .env                      # API keys (create from .env.example)\n```\n\n---\n\n## Database Setup Explained\n\nLangConfig uses a single PostgreSQL database with pgvector for:\n\n- **Workflows & Projects** - Visual workflow definitions and project organization\n- **Agents & Templates** - Custom agents and pre-built templates\n- **Chat Sessions** - Conversation history and session state\n- **Vector Storage** - Document embeddings for RAG retrieval\n- **LangGraph Checkpoints** - Workflow state persistence (via `langgraph-checkpoint-postgres`)\n\n**Setup Steps:**\n\n1. **Docker starts PostgreSQL** - `docker-compose up -d postgres`\n   - Automatically runs `backend/db/init_postgres.sql`\n   - Creates `vector` extension (pgvector)\n   - Creates initial `vector_documents` table\n\n2. **Alembic creates all tables** - `alembic upgrade head`\n   - Runs migrations in `backend/alembic/versions/`\n   - Creates: workflows, projects, agents, chat_sessions, session_documents, checkpoints, etc.\n\n3. **Seed agent templates (optional)** - `python db/init_deepagents.py`  **Experimental**\n   - Populates `deep_agent_templates` table with pre-built agents\n   - Adds templates like Research Agent, Code Reviewer, etc.\n\n---\n\n## Usage Examples\n\n### Example 1: Test an Agent Interactively\n\n1. Click an agent from the library (e.g., \"Research Agent\")\n2. Click the **Chat** icon\n3. Upload documents for RAG context (optional)\n4. Send a message: `\"Summarize the key findings in these papers\"`\n5. Watch the agent use tools in real-time\n6. View token costs and metrics in the sidebar\n\n### Example 2: Build a Multi-Agent Workflow\n\n1. Go to **Studio** → **New Workflow**\n2. Drag \"Research Agent\" to canvas\n3. Drag \"Code Implementer\" to canvas\n4. Connect them: Research → Implementer\n5. Click **Run**\n6. Enter task: `\"Research best practices for authentication and implement it\"`\n7. Research Agent finds information → passes to Implementer → code is generated\n\n### Example 3: Create a Custom Agent with AI\n\n1. Click **Agent Builder** from toolbar\n2. Enter name: `\"Security Auditor\"`\n3. Enter description: `\"Reviews code for security vulnerabilities and suggests fixes\"`\n4. Click **AI Generate** → GPT-4o suggests:\n   - Model: `gpt-4o` (reasoning capability)\n   - Temperature: `0.2` (focused, deterministic)\n   - Tools: `filesystem`, `grep`, `web_search`\n   - System prompt: Specialized security analysis prompt\n5. Review and customize (add more tools, adjust prompt)\n6. Click **Save** → use in workflows or chat testing\n\n### Example 4: Export Workflow as Standalone App\n\n1. Build workflow visually (e.g., Research → Plan → Implement → Test)\n2. Click **Export** → **Download Python Package**\n3. Extract the ZIP file to any folder\n4. Run `pip install -r requirements.txt`\n5. Add API keys to `.env`\n6. Run `streamlit run streamlit_app.py`\n7. Use your workflow as a standalone web app with live streaming output\n\n---\n\n## Configuration\n\n### Environment Variables\n\nCopy `.env.example` to `.env` and configure:\n\n```bash\ncp .env.example .env\n```\n\n**Required:**\n| Variable | Description |\n|----------|-------------|\n| `DATABASE_URL` | PostgreSQL connection string (default: `postgresql://langconfig:langconfig_dev@localhost:5433/langconfig`) |\n\n**LLM API Keys** (at least one required):\n| Variable | Description |\n|----------|-------------|\n| `OPENAI_API_KEY` | OpenAI API key for GPT models |\n| `ANTHROPIC_API_KEY` | Anthropic API key for Claude models |\n| `GOOGLE_API_KEY` | Google API key for Gemini models |\n\n**Optional:**\n| Variable | Description | Default |\n|----------|-------------|--------|\n| `DEEPSEEK_API_KEY` | DeepSeek API key | - |\n| `GITHUB_PAT` | GitHub Personal Access Token | - |\n| `GITLAB_PAT` | GitLab Personal Access Token | - |\n| `LOCAL_LLM_HOST` | Local model server URL | `http://localhost:11434` |\n| `SECRET_KEY` | App secret key | Auto-generated |\n| `ENVIRONMENT` | `development` or `production` | `development` |\n| `LOG_LEVEL` | Logging level | `INFO` |\n\n**Workflow Execution:**\n| Variable | Description | Default |\n|----------|-------------|--------|\n| `MAX_WORKFLOW_TIMEOUT` | Max workflow runtime (seconds) | `300` |\n| `MAX_CONCURRENT_WORKFLOWS` | Parallel workflow limit | `5` |\n| `MAX_EXECUTION_HISTORY_PER_WORKFLOW` | History entries to keep | `100` |\n| `EXECUTION_HISTORY_RETENTION_DAYS` | Days to retain history | `90` |\n\nAPI keys can also be configured via **Settings UI** in the app (stored encrypted in database, takes priority over `.env`).\n\n### Local Models\n\nRun models locally with zero API costs:\n\n1. Install [Ollama](https://ollama.ai/) or [LM Studio](https://lmstudio.ai/)\n2. Start local model server (default: `http://localhost:11434`)\n3. Go to **Settings** → **API Keys**\n4. Add Local Provider:\n   - **Base URL**: `http://localhost:11434/v1`\n   - **Model**: `llama3.1` (or your model name)\n5. Use in any agent configuration\n\n### Built-in Tools\n\n**Native Python Tools** (no external dependencies):\n- `web_search` - Web search via DuckDuckGo (free, no API key)\n- `web_fetch` - Fetch webpage content\n- `file_read` / `file_write` / `file_list` - File system operations\n- `memory_store` / `memory_recall` - Long-term memory (PostgreSQL-backed)\n- `reasoning_chain` - Break down complex tasks into logical steps\n\n**Browser Automation** (Playwright, requires `playwright install chromium`):\n- `browser_navigate` - Navigate URLs with JavaScript rendering\n- `browser_click` - Click elements on page\n- `browser_extract` - Extract text/links from pages\n- `browser_screenshot` - Capture page screenshots\n\n**Custom Tool Templates** (create via UI):\n- **Notifications**: Slack, Discord (multi-channel webhooks)\n- **CMS/Publishing**: WordPress REST API, Twitter/X API\n- **Image/Video**: DALL-E 3, Sora, Imagen 3, Nano Banana (Gemini 2.5 Flash Image), Veo 3\n- **Database**: PostgreSQL, MySQL, MongoDB queries\n- **API/Webhook**: Custom REST API calls with auth\n- **Data Transform**: JSON ↔ CSV ↔ XML ↔ YAML conversion\n\n---\n\n## Tech Stack\n\n**Frontend:**\n- React 19.2 + TypeScript 5.8\n- Tailwind CSS 4.1\n- ReactFlow 11.11 (visual canvas)\n- TanStack Query 5.90\n- Tauri 2.0 (optional desktop app)\n\n**Backend:**\n- Python 3.11+\n- FastAPI 0.115\n- LangChain v1.0 (full ecosystem)\n- LangGraph 0.4+ (with checkpoint-postgres)\n- LlamaIndex (document indexing & RAG)\n\n**Database:**\n- PostgreSQL 16 with pgvector\n- SQLAlchemy 2.0 + Alembic (migrations)\n- langgraph-checkpoint-postgres (state persistence)\n\n**AI/ML:**\n- OpenAI (GPT-4o, GPT-4o-mini, GPT-5, o3, o3-mini, o4-mini)\n- Anthropic (Claude 4.5 Sonnet, Claude 4.5 Opus, Claude 4.5 Haiku)\n- Google (Gemini 3 Pro Preview, Gemini 2.5 Flash, Gemini 2.0 Flash)\n- DeepSeek (DeepSeek Chat, DeepSeek Reasoner)\n- Local models via Ollama/LM Studio\n- Sentence Transformers (embeddings)\n- Unstructured (document processing)\n\n---\n\n## Troubleshooting\n\n### Port Already in Use\n\n```bash\n# Windows\ntaskkill /F /IM node.exe\n\n# macOS/Linux\nlsof -ti:1420 | xargs kill -9\n```\n\n### PostgreSQL Connection Failed\n\n```bash\n# Check Docker is running\ndocker-compose ps\n\n# Restart PostgreSQL\ndocker-compose restart postgres\n\n# Check logs\ndocker-compose logs postgres\n```\n\n### Database Migration Issues\n\n```bash\n# Reset migrations (WARNING: deletes all data)\ncd backend\nalembic downgrade base\nalembic upgrade head\n```\n\n### Python Dependencies Issues\n\n```bash\n# Reinstall all dependencies\ncd backend\npip install --upgrade pip\npip install -r requirements.txt\n```\n\n---\n\n## Building Desktop Installers (Optional)\n\n**Prerequisites:**\n- Rust installed ([Install](https://rustup.rs/))\n- Visual Studio Build Tools (Windows only)\n\n```bash\nnpm run tauri build\n```\n\nGenerates platform-specific installers:\n- **Windows**: `.exe`, `.msi`\n- **macOS**: `.app`, `.dmg`\n- **Linux**: `.AppImage`, `.deb`\n\nTotal size: ~250MB (includes Python runtime and dependencies)\n\n---\n\n## Development\n\n### Running Tests\n\n```bash\n# Backend tests\ncd backend\npytest\n\n# Frontend tests\nnpm test\n```\n\n### Database Migrations\n\n```bash\ncd backend\n\n# Create new migration\nalembic revision --autogenerate -m \"Description of changes\"\n\n# Apply migration\nalembic upgrade head\n\n# Rollback migration\nalembic downgrade -1\n```\n\n### Adding Custom Agent Templates\n\nAgent templates are defined in `backend/core/agents/templates.py`. Workflow recipes (multi-node templates) are in `backend/core/templates/workflow_recipes.py`.\n\nTo add new templates:\n1. Add your template definition to the appropriate file\n2. Templates are auto-registered on backend startup\n3. For database-stored agents, use the Agent Builder UI or run:\n\n```bash\ncd backend\npython db/init_deepagents.py\n```\n\n---\n\n## Documentation\n\n- **[Chat API Documentation](./backend/api/chat/README.md)** - Interactive chat testing API\n- **[GitHub Issues](https://github.com/langconfig/langconfig/issues)** - Report bugs and request features\n\n---\n\n## Contributing\n\nWe welcome contributions! Whether you're:\n- Adding agent templates\n- Improving UI/UX\n- Writing documentation\n- Reporting bugs\n- Suggesting features\n\n**How to Contribute:**\n\n1. Fork the repository\n2. Create a feature branch: `git checkout -b feature/amazing-feature`\n3. Make your changes and add tests\n4. Commit: `git commit -m 'Add amazing feature'`\n5. Push: `git push origin feature/amazing-feature`\n6. Open a Pull Request\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed guidelines.\n\n---\n\n## License\n\nCopyright 2025 LangConfig Contributors\n\nLicensed under the MIT License. See [LICENSE](./LICENSE) file for details.\n\n### Third-Party Licenses\n\n- **LangChain & LangGraph** - MIT License\n- **FastAPI** - MIT License\n- **React** - MIT License\n- **Tauri** - Apache 2.0 / MIT License\n- **PostgreSQL** - PostgreSQL License\n\n---\n\n## Support\n\n- **GitHub Issues**: [Report bugs and request features](https://github.com/langconfig/langconfig/issues)\n- **Discussions**: [Ask questions and share ideas](https://github.com/langconfig/langconfig/discussions)\n\n---\n\n**LangConfig - Visual AI Agent Workflows Powered by LangChain & LangGraph**\n",
  "installCommand": "git clone https://github.com/LangConfig/langconfig ~/.claude/skills/langconfig",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}