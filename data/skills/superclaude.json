{
  "id": "619498cd35499ab6",
  "slug": "superclaude",
  "name": "SuperClaude",
  "description": "A configuration framework that enhances Claude Code with specialized commands, cognitive personas, and development methodologies.",
  "author": "Tony363",
  "authorAvatar": "https://avatars.githubusercontent.com/u/48950649?v=4",
  "repoUrl": "https://github.com/Tony363/SuperClaude",
  "repoFullName": "Tony363/SuperClaude",
  "stars": 10,
  "forks": 0,
  "category": "testing",
  "categories": [
    "testing"
  ],
  "tags": [],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-08-26T17:37:31Z",
  "updatedAt": "2025-12-26T06:15:42Z",
  "lastCommitAt": "2025-12-26T06:15:50Z",
  "source": "github-search",
  "collectedAt": "2025-12-27T03:31:18.840Z",
  "authorUrl": "https://github.com/Tony363",
  "license": "MIT",
  "readme": "# SuperClaude Framework\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/version-6.0.0--alpha-blue\" alt=\"Version\">\n  <img src=\"https://img.shields.io/badge/python-3.10%2B-green\" alt=\"Python\">\n  <img src=\"https://img.shields.io/badge/agents-130-orange\" alt=\"Agents\">\n  <img src=\"https://img.shields.io/badge/commands-13-purple\" alt=\"Commands\">\n  <img src=\"https://img.shields.io/badge/license-MIT-lightgrey\" alt=\"License\">\n</p>\n\n**An intelligent AI orchestration framework for Claude Code that provides multi-model consensus, specialized agents, behavioral modes, and quality-driven execution with iterative improvement loops.**\n\nSuperClaude transforms Claude Code into a powerful development platform with 130 specialized agents (16 core + 114 extended), Claude Agent SDK integration, multi-provider AI routing, MCP server integration, and sophisticated quality validation pipelines featuring deterministic safety grounding.\n\n---\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Key Features](#key-features)\n- [Architecture](#architecture)\n  - [High-Level System Architecture](#high-level-system-architecture)\n  - [Claude Agent SDK Integration](#claude-agent-sdk-integration)\n  - [Request Flow](#request-flow)\n- [The Agentic Loop (`--loop`)](#the-agentic-loop---loop)\n  - [How It Works](#how-it-works)\n  - [Termination Conditions](#termination-conditions)\n  - [P0/P1 Safety Features](#p0p1-safety-features)\n- [Core Components](#core-components)\n  - [Agent System](#agent-system)\n  - [Command System](#command-system)\n  - [Model Router](#model-router)\n  - [Quality Pipeline](#quality-pipeline)\n  - [Worktree Isolation](#worktree-isolation)\n- [MCP Integrations](#mcp-integrations)\n  - [Rube MCP](#rube-mcp)\n  - [PAL MCP](#pal-mcp)\n  - [LinkUp Search](#linkup-search)\n- [Behavioral Modes](#behavioral-modes)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Environment Variables](#environment-variables)\n- [Extensibility Guide](#extensibility-guide)\n- [Troubleshooting](#troubleshooting)\n- [CI/CD Pipeline](#cicd-pipeline)\n- [Project Structure](#project-structure)\n- [Contributing](#contributing)\n\n---\n\n## Overview\n\nSuperClaude is a sophisticated AI orchestration framework that enhances Claude Code with:\n\n- **130 Specialized Agents**: 16 core Python agents + 114 extended agents across 10 categories\n- **Claude Agent SDK Integration**: Native SDK support with quality hooks and evidence collection\n- **Multi-Model Consensus**: Route requests to GPT-5, Gemini 2.5 Pro, Claude, xAI Grok\n- **13 Commands**: analyze, implement, test, design, document, and more\n- **Agentic Loop**: Iterative improvement with PAL MCP code reviews (`--loop` flag)\n- **Behavioral Modes**: Normal, Task Management, Token Efficiency\n- **Quality Validation**: Multi-stage pipelines with deterministic safety grounding\n- **MCP Integration**: Rube (500+ apps), PAL (consensus & code review), LinkUp (web search)\n\n---\n\n## Key Features\n\n### Claude Agent SDK Integration\n\nSuperClaude v6.0.0 introduces native Claude Agent SDK integration for programmatic execution:\n\n```python\nfrom SuperClaude.SDK import SuperClaudeSDKClient, AgentToSDKAdapter\n\n# Create SDK client with SuperClaude capabilities\nclient = SuperClaudeSDKClient(\n    registry=agent_registry,\n    selector=agent_selector,\n    quality_scorer=quality_scorer\n)\n\n# Execute with automatic agent selection\nasync for message in client.execute_with_agent(\n    task=\"Fix the authentication bug in auth.py\",\n    context={\"cwd\": \"/project\", \"requires_evidence\": True}\n):\n    process_message(message)\n```\n\n**SDK Components:**\n- `SuperClaudeSDKClient` - High-level execution API with agent orchestration\n- `AgentToSDKAdapter` - Converts SuperClaude agents to SDK format\n- `QualityHooks` - Evidence collection during execution\n- `SDKMessage`, `SDKOptions`, `ExecutionResult` - Type-safe data structures\n\n### Agentic Loop for Iterative Development\n\nThe `--loop` flag enables automatic iteration until quality thresholds are met:\n\n```bash\n/sc:implement --loop \"Add user authentication\"\n```\n\nEach iteration:\n1. Executes the implementation\n2. Runs PAL MCP code review (`mcp__pal__codereview`)\n3. Evaluates quality across 9 dimensions\n4. Re-delegates with feedback if score < threshold\n5. Terminates on success, oscillation, or max iterations\n\n### Deterministic Safety Grounding\n\nUnlike pure LLM self-evaluation, SuperClaude grounds quality scores in **verifiable facts**:\n\n- **Test failures** cap maximum score at 40-60%\n- **Security vulnerabilities** cap score at 30%\n- **Build failures** cap score at 45%\n- **Clean signals** (tests pass, lint clean) add bonuses up to +25 points\n\nThis prevents the system from hallucinating success when real problems exist.\n\n---\n\n## Architecture\n\n### High-Level System Architecture\n\n```mermaid\ngraph TB\n    subgraph \"SuperClaude Framework v6.0.0\"\n        User[User Input] --> Parser[Command Parser]\n        Parser --> Executor[Command Executor]\n\n        Executor --> SDK[SDK Module]\n        Executor --> Router[Model Router]\n        Executor --> Agents[Agent System<br/>130 Agents]\n        Executor --> Modes[Behavioral Modes]\n\n        SDK --> SDKClient[SuperClaudeSDKClient]\n        SDK --> SDKAdapter[AgentToSDKAdapter]\n        SDK --> SDKHooks[Quality Hooks]\n\n        Router --> Anthropic[Claude Opus 4.5]\n        Router --> OpenAI[GPT-5 / GPT-4.1]\n        Router --> Google[Gemini 2.5 Pro]\n        Router --> xAI[Grok 4]\n\n        Agents --> Registry[Agent Registry<br/>LRU Cache]\n        Registry --> CoreAgents[16 Core Agents]\n        Registry --> ExtendedAgents[114 Extended Agents]\n\n        Executor --> MCP[MCP Integrations]\n        MCP --> Rube[Rube MCP<br/>500+ Apps]\n        MCP --> PAL[PAL MCP<br/>Consensus]\n        MCP --> LinkUp[LinkUp<br/>Web Search]\n\n        Executor --> Quality[Quality Pipeline]\n        Quality --> Validation[5 Validation Stages]\n        Quality --> Signals[Deterministic Signals]\n    end\n\n    style User fill:#e1f5fe\n    style Executor fill:#fff3e0\n    style SDK fill:#e8f5e9\n    style Router fill:#f3e5f5\n    style Agents fill:#e8f5e9\n    style MCP fill:#fce4ec\n    style Quality fill:#fff9c4\n```\n\n### Claude Agent SDK Integration\n\n```mermaid\nflowchart LR\n    subgraph UserLayer[\"Caller / CLI / Workflow\"]\n        U[Developer]\n    end\n\n    subgraph SdkModule[\"SuperClaude/SDK\"]\n        C[\"SuperClaudeSDKClient<br/>(high-level execution API)\"]\n        A[\"AgentToSDKAdapter<br/>(Agent â†’ SDK format)\"]\n        T[\"Types<br/>SDKMessage<br/>SDKOptions<br/>ExecutionResult\"]\n        HQ[\"Quality Hooks<br/>(evidence collection)\"]\n    end\n\n    subgraph AgentLayer[\"SuperClaude Agents\"]\n        Core[\"Core Agents (16)<br/>backend_architect<br/>general_purpose<br/>...\"]\n        Ext[\"Extended Agents (114)<br/>10 categories\"]\n    end\n\n    subgraph LoopQuality[\"SuperClaude/Quality\"]\n        Loop[\"Agentic Loop<br/>(iterative improvement)\"]\n        Score[\"Quality Scoring<br/>(9 dims + caps/bonuses)\"]\n    end\n\n    subgraph Telemetry[\"SuperClaude/Telemetry\"]\n        Evidence[\"Evidence Store\"]\n        Metrics[\"Metrics / Logs\"]\n    end\n\n    U --> C\n    C --> A\n    A --> Core\n    A --> Ext\n\n    C --> HQ\n    HQ --> Evidence\n    Evidence --> Score\n    Score --> Loop\n    Loop --> C\n```\n\n### Request Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Parser as Command Parser\n    participant Registry as Command Registry\n    participant Executor as Command Executor\n    participant SDK as SDK Client\n    participant Agent as Agent Selector\n    participant Router as Model Router\n    participant Quality as Quality Pipeline\n\n    User->>Parser: /sc:command --flags\n    Parser->>Registry: Lookup Command\n    Registry-->>Parser: Command Metadata\n    Parser->>Executor: ParsedCommand\n\n    Executor->>Agent: Select Agent(context)\n    Agent-->>Executor: Best Match Agent\n\n    alt SDK Execution Path\n        Executor->>SDK: Execute via SDK\n        SDK->>Router: Route Request\n        Router-->>SDK: Model Response\n        SDK-->>Executor: SDKExecutionResult\n    else Legacy Execution Path\n        Executor->>Router: Route Request\n        Router-->>Executor: Model Response\n    end\n\n    Executor->>Quality: Validate Output\n    Quality->>Quality: Apply Deterministic Signals\n    Quality-->>Executor: QualityAssessment\n\n    alt Score >= 90 (production_ready)\n        Executor-->>User: Success Response\n    else Score >= 75 (needs_attention)\n        Executor-->>User: Success with Suggestions\n    else Score < 75\n        Executor->>Agent: Re-delegate with feedback\n        Agent-->>Executor: Improved Result\n        Executor-->>User: Iterated Response\n    end\n```\n\n---\n\n## The Agentic Loop (`--loop`)\n\nThe agentic loop is SuperClaude's core iterative improvement mechanism. When enabled via `--loop [n]`, the system automatically re-runs implementations until quality thresholds are met.\n\n### How It Works\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Executor as Command Executor\n    participant SDK as SDK Client\n    participant PAL as PAL MCP<br/>(mcp__pal__codereview)\n    participant Quality as Quality Scorer\n    participant Signals as Deterministic Signals\n\n    User->>Executor: /sc:implement --loop [n]\n\n    Note over Executor: --loop enables<br/>PAL review automatically\n\n    loop Iteration 1..n (max capped at HARD_MAX=5)\n        Executor->>SDK: Execute agent pipeline\n        SDK-->>Executor: Code changes + tests\n\n        Executor->>PAL: mcp__pal__codereview(changed_files)\n        PAL-->>Executor: Review findings\n\n        Executor->>Quality: evaluate(output, context)\n        Quality->>Signals: Apply test/lint/security signals\n        Signals-->>Quality: Hard caps + bonuses\n        Quality-->>Executor: QualityAssessment<br/>(score, band, improvements_needed)\n\n        alt score >= 90 (QUALITY_MET)\n            Executor-->>User: âœ… Success Response\n        else score >= 75 AND iterations < max\n            Note over Executor: Build feedback context:<br/>improvements_needed,<br/>PAL findings,<br/>current_score\n            Executor->>SDK: Re-delegate with feedback\n        else Oscillation/Stagnation detected\n            Executor-->>User: âš ï¸ Best result + warnings\n        else Max iterations reached\n            Executor-->>User: â¹ï¸ Best result + termination reason\n        end\n    end\n```\n\n### Termination Conditions\n\nThe agentic loop terminates when any of these conditions are met:\n\n| Condition | Description | Trigger |\n|-----------|-------------|---------|\n| `QUALITY_MET` | Quality threshold achieved | Score >= 90 (production_ready) |\n| `MAX_ITERATIONS` | Hard cap reached | Iterations >= HARD_MAX_ITERATIONS (5) |\n| `INSUFFICIENT_IMPROVEMENT` | Progress stalled | Improvement < MIN_IMPROVEMENT (5.0) |\n| `OSCILLATION` | Scores alternating | Pattern like [65, 72, 65, 71] detected |\n| `STAGNATION` | Scores flat | All recent scores within 2.0 points |\n| `TIMEOUT` | Wall-clock limit exceeded | Best-effort timeout exceeded |\n| `ERROR` | Improver function failed | Exception during iteration |\n| `HUMAN_ESCALATION` | Requires manual review | Complex issues needing human judgment |\n\n### P0/P1 Safety Features\n\nSuperClaude implements layered safety to prevent runaway loops and inflated scores:\n\n#### P0 Safety: Hard Iteration Limits\n\n```python\n# From quality_scorer.py\nMAX_ITERATIONS = 3          # Default iterations\nHARD_MAX_ITERATIONS = 5     # Absolute ceiling, CANNOT be overridden\nOSCILLATION_WINDOW = 3      # Scores checked for oscillation\nSTAGNATION_THRESHOLD = 2.0  # Minimum score difference\nMIN_IMPROVEMENT = 5.0       # Minimum improvement to continue\n```\n\n**Key guarantee**: Even if you pass `max_iterations=100`, the loop caps at 5.\n\n#### P1 Safety: Deterministic Signal Grounding\n\nUnlike pure LLM self-evaluation, quality scores are grounded in verifiable facts:\n\n```mermaid\nflowchart TB\n    subgraph \"Deterministic Signal Pipeline\"\n        Base[Base LLM Score] --> Collect[Collect Signals]\n\n        subgraph Signals[\"Deterministic Signals\"]\n            Tests[\"Tests<br/>(pass/fail %)\"]\n            Lint[\"Lint<br/>(clean/issues)\"]\n            Type[\"Type Check<br/>(pass/fail)\"]\n            Build[\"Build<br/>(pass/fail)\"]\n            Sec[\"Security Scan<br/>(critical/high)\"]\n        end\n\n        Collect --> Signals\n        Signals --> Check{Hard Failures?}\n\n        Check -->|Security Critical| Cap30[Cap at 30%]\n        Check -->|Tests >50% Failing| Cap40[Cap at 40%]\n        Check -->|Build Errors| Cap45[Cap at 45%]\n        Check -->|Tests >20% Failing| Cap50[Cap at 50%]\n        Check -->|Security High| Cap65[Cap at 65%]\n        Check -->|No Failures| Bonus[Apply Bonuses]\n\n        subgraph BonusPoints[\"Bonus Points (max +25)\"]\n            B1[\"Coverage â‰¥ 80%: +10\"]\n            B2[\"Clean lint: +5\"]\n            B3[\"Type check pass: +5\"]\n            B4[\"All tests pass: +5\"]\n            B5[\"Security pass: +5\"]\n        end\n\n        Bonus --> BonusPoints\n        BonusPoints --> Final[Final Score]\n\n        Cap30 --> Final\n        Cap40 --> Final\n        Cap45 --> Final\n        Cap50 --> Final\n        Cap65 --> Final\n    end\n```\n\n---\n\n## Core Components\n\n### Agent System\n\nSuperClaude features **130 specialized agents** organized into 16 core Python agents and 114 extended markdown agents across 10 categories:\n\n```mermaid\nflowchart TB\n    Total[\"SuperClaude Agents<br/>Total: 130\"] --> Core[\"Core Python Agents<br/>16 total\"]\n    Total --> Extended[\"Extended Agents<br/>114 total<br/>(10 categories)\"]\n\n    subgraph CoreList[\"Core Agents (16)\"]\n        C1[\"backend_architect\"]\n        C2[\"devops_architect\"]\n        C3[\"frontend_architect\"]\n        C4[\"fullstack_developer\"]\n        C5[\"general_purpose\"]\n        C6[\"learning_guide\"]\n        C7[\"performance\"]\n        C8[\"python_expert\"]\n        C9[\"quality\"]\n        C10[\"refactoring\"]\n        C11[\"requirements_analyst\"]\n        C12[\"root_cause\"]\n        C13[\"security\"]\n        C14[\"socratic_mentor\"]\n        C15[\"system_architect\"]\n        C16[\"technical_writer\"]\n    end\n\n    subgraph ExtCats[\"Extended Agent Categories (10)\"]\n        E1[\"01-core-development: 10\"]\n        E2[\"02-language-specialists: 23\"]\n        E3[\"03-infrastructure: 12\"]\n        E4[\"04-quality-security: 12\"]\n        E5[\"05-data-ai: 12\"]\n        E6[\"06-developer-experience: 10\"]\n        E7[\"07-specialized-domains: 11\"]\n        E8[\"08-business-product: 10\"]\n        E9[\"09-meta-orchestration: 8\"]\n        E10[\"10-research-analysis: 6\"]\n    end\n\n    Core --> CoreList\n    Extended --> ExtCats\n```\n\n#### Agent Selection Algorithm\n\nAgents are selected using a weighted scoring algorithm:\n\n```mermaid\nflowchart TB\n    Context[Task Context] --> Domain{Domain Match?}\n\n    Domain -->|Yes +30%| DomainScore[Domain Score]\n    Domain -->|No| Keyword\n\n    DomainScore --> Keyword{Keyword Match?}\n    Keyword -->|Yes +20%| KeywordScore[Keyword Score]\n    Keyword -->|No| FilePattern\n\n    KeywordScore --> FilePattern{File Pattern?}\n    FilePattern -->|Yes +20%| PatternScore[Pattern Score]\n    FilePattern -->|No| Language\n\n    PatternScore --> Language{Language Match?}\n    Language -->|Yes +15%| LangScore[Language Score]\n    Language -->|No| Framework\n\n    LangScore --> Framework{Framework Match?}\n    Framework -->|Yes +15%| FrameScore[Framework Score]\n    Framework -->|No| Calculate\n\n    FrameScore --> Calculate[Calculate Total]\n    Calculate --> Threshold{Score >= 0.6?}\n    Threshold -->|Yes| Select[Select Agent]\n    Threshold -->|No| Default[Use general-purpose]\n```\n\n#### Agent Coordination Strategies\n\n| Strategy | Description | Use Case |\n|----------|-------------|----------|\n| **Hierarchical** | Top-down task delegation | Complex multi-step tasks |\n| **Consensus** | Multi-agent voting via PAL MCP | Critical decisions |\n| **Pipeline** | Sequential processing | Data transformation |\n| **Parallel** | Concurrent execution | Independent subtasks |\n| **Adaptive** | Dynamic strategy selection | Uncertain requirements |\n| **Swarm** | Emergent coordination | Large-scale analysis |\n\n### Command System\n\n13 commands available via `/sc:` syntax:\n\n```mermaid\ngraph TB\n    subgraph \"Command System\"\n        Parser[Command Parser<br/>YAML Frontmatter]\n        Registry[Command Registry<br/>Auto-discovery]\n        Executor[Command Executor]\n\n        Parser --> Registry\n        Registry --> Executor\n\n        subgraph \"Sub-Executors\"\n            AO[agent_orchestration.py]\n            CS[consensus.py]\n            GO[git_operations.py]\n            CM[change_management.py]\n            TE[testing.py]\n            QU[quality.py]\n            AS[ast_analysis.py]\n        end\n\n        Executor --> AO\n        Executor --> CS\n        Executor --> GO\n        Executor --> CM\n        Executor --> TE\n        Executor --> QU\n        Executor --> AS\n    end\n```\n\n| Command | Purpose | Key Flags |\n|---------|---------|-----------|\n| `/sc:analyze` | Code analysis, quality assessment | `--deep`, `--agent` |\n| `/sc:implement` | Feature/code implementation | `--persona`, `--loop [n]` |\n| `/sc:test` | Test execution with coverage | `--coverage`, `--watch` |\n| `/sc:design` | Architecture and system design | `--diagram`, `--adr` |\n| `/sc:document` | Documentation generation | `--api`, `--readme` |\n| `/sc:brainstorm` | Creative ideation | `--divergent`, `--converge` |\n| `/sc:build` | Project building and compilation | `--target`, `--optimize` |\n| `/sc:estimate` | Effort and resource estimation | `--breakdown`, `--risk` |\n| `/sc:explain` | Code/concept explanation | `--depth`, `--audience` |\n| `/sc:improve` | Code enhancement | `--refactor`, `--optimize` |\n| `/sc:workflow` | Multi-step workflow management | `--steps`, `--parallel` |\n| `/sc:git` | Git operations | `--commit`, `--pr` |\n| `/sc:index` | Search and indexing | `--rebuild`, `--query` |\n\n### Model Router\n\nThe Model Router intelligently distributes requests across multiple AI providers:\n\n```mermaid\ngraph LR\n    subgraph \"Model Router\"\n        Input[Request] --> Selector[Provider Selector]\n\n        Selector --> |deep_thinking| GPT5[GPT-5<br/>400K context]\n        Selector --> |long_context| Gemini[Gemini 2.5 Pro<br/>2M context]\n        Selector --> |fallback| Claude[Claude Opus 4.5<br/>200K context]\n        Selector --> |fast_iteration| Grok[Grok 4<br/>256K context]\n\n        GPT5 --> Consensus[Consensus Engine]\n        Gemini --> Consensus\n        Claude --> Consensus\n        Grok --> Consensus\n\n        Consensus --> Output[Final Response]\n    end\n```\n\n#### Supported Models\n\n| Provider | Model | Context | Features | Priority |\n|----------|-------|---------|----------|----------|\n| **OpenAI** | GPT-5 | 400K | Thinking, Vision | 1 |\n| **OpenAI** | GPT-4.1 | 1M | Large context | 3 |\n| **OpenAI** | GPT-4o | 128K | Fast, Cost-effective | 4 |\n| **Google** | Gemini 2.5 Pro | **2M** | Thinking, Vision | 1 |\n| **Anthropic** | Claude Opus 4.5 | 200K | Fallback, Validation | 2 |\n| **xAI** | Grok 4 | 256K | Thinking, Fast | 2 |\n\n### Quality Pipeline\n\nThe validation pipeline enforces layered quality checks with short-circuit behavior:\n\n```mermaid\nflowchart TB\n    subgraph \"Validation Pipeline\"\n        Input[Context] --> Syntax[Syntax Stage<br/>Required]\n\n        Syntax -->|passed| Security[Security Stage<br/>Required]\n        Syntax -->|fatal| Skip1[Skip All]\n\n        Security -->|passed| Style[Style Stage<br/>Optional]\n        Security -->|fatal| Skip2[Skip All]\n\n        Style --> Tests[Tests Stage<br/>Required]\n\n        Tests -->|passed| Perf[Performance Stage<br/>Optional]\n        Tests -->|fatal| Skip3[Skip All]\n\n        Perf --> Signals[Apply Deterministic Signals]\n        Skip1 --> Signals\n        Skip2 --> Signals\n        Skip3 --> Signals\n\n        Signals --> Results[Aggregate Results]\n        Results --> Evidence[Write Evidence<br/>JSON files]\n    end\n```\n\n#### Quality Dimensions (9 Total)\n\n```mermaid\npie title Quality Score Weights\n    \"Correctness\" : 25\n    \"Completeness\" : 20\n    \"Performance\" : 10\n    \"Maintainability\" : 10\n    \"Security\" : 10\n    \"Scalability\" : 10\n    \"Testability\" : 10\n    \"PAL Review\" : 10\n    \"Usability\" : 5\n```\n\n| Dimension | Weight | Metrics |\n|-----------|--------|---------|\n| **Correctness** | 25% | Tests pass, no runtime errors, output validation |\n| **Completeness** | 20% | Feature coverage, edge cases, documentation |\n| **Performance** | 10% | Time/space complexity, resource usage |\n| **Maintainability** | 10% | Readability, modularity, naming |\n| **Security** | 10% | Input validation, authentication, data protection |\n| **Scalability** | 10% | Architecture, database design, caching |\n| **Testability** | 10% | Unit tests, integration tests, test quality |\n| **PAL Review** | 10% | External code review via `mcp__pal__codereview` |\n| **Usability** | 5% | UI consistency, error messages, accessibility |\n\n#### Quality Thresholds & Actions\n\n| Score Range | Band | Action |\n|-------------|------|--------|\n| 90-100 | `production_ready` | Auto-approve, fast-track |\n| 75-89 | `needs_attention` | Accept with improvement suggestions |\n| 50-74 | `iterate` | Iterate with feedback (max 5 iterations) |\n| < 50 | `iterate` | Delegate to quality-engineer, escalate |\n\n### Worktree Isolation\n\nSuperClaude uses git worktrees to safely isolate file modifications:\n\n```mermaid\ngraph LR\n    subgraph \"Worktree Management\"\n        Main[Main Branch] --> WT[.worktrees/]\n        WT --> WT1[worktree-1<br/>Feature A]\n        WT --> WT2[worktree-2<br/>Feature B]\n        WT --> WTN[worktree-n<br/>Feature N]\n\n        WT1 --> Validate{Validation<br/>Passed?}\n        Validate -->|Yes| Merge[Merge to Main]\n        Validate -->|No| Fix[Fix & Retry]\n    end\n```\n\n---\n\n## MCP Integrations\n\nSuperClaude integrates with Model Context Protocol (MCP) servers via Claude Code's native tools.\n\n```mermaid\ngraph TB\n    subgraph \"MCP Architecture\"\n        Executor[Command Executor]\n\n        Executor --> RubeInt[Rube MCP]\n        Executor --> PALInt[PAL MCP]\n        Executor --> LinkUpInt[LinkUp Search]\n\n        subgraph \"Rube MCP - 500+ Apps\"\n            RubeInt --> Search[RUBE_SEARCH_TOOLS]\n            RubeInt --> Execute[RUBE_MULTI_EXECUTE_TOOL]\n            RubeInt --> Plan[RUBE_CREATE_PLAN]\n            RubeInt --> Connect[RUBE_MANAGE_CONNECTIONS]\n\n            Execute --> Slack[Slack]\n            Execute --> GitHub[GitHub]\n            Execute --> Gmail[Gmail]\n            Execute --> Sheets[Google Sheets]\n        end\n\n        subgraph \"PAL MCP - Consensus & Analysis\"\n            PALInt --> Chat[chat]\n            PALInt --> Think[thinkdeep]\n            PALInt --> Plan2[planner]\n            PALInt --> Consensus[consensus]\n            PALInt --> CodeRev[codereview]\n            PALInt --> PreCommit[precommit]\n            PALInt --> Debug[debug]\n        end\n\n        subgraph \"LinkUp - Web Search\"\n            LinkUpInt --> WebSearch[LINKUP_SEARCH]\n        end\n    end\n```\n\n### Rube MCP\n\nConnects to 500+ apps for cross-application automation:\n\n| Tool | Purpose |\n|------|---------|\n| `RUBE_SEARCH_TOOLS` | Discover available app integrations |\n| `RUBE_MULTI_EXECUTE_TOOL` | Execute up to 50 tools in parallel |\n| `RUBE_CREATE_PLAN` | Create workflow execution plans |\n| `RUBE_MANAGE_CONNECTIONS` | Manage OAuth/API connections |\n| `RUBE_REMOTE_WORKBENCH` | Execute Python in sandbox |\n| `RUBE_CREATE_UPDATE_RECIPE` | Create reusable automation recipes |\n\n### PAL MCP\n\nProvides multi-model consensus and analysis via meta-prompting:\n\n| Tool | Purpose | When to Use |\n|------|---------|-------------|\n| `mcp__pal__chat` | Collaborative thinking | General queries with specific model |\n| `mcp__pal__thinkdeep` | Multi-stage investigation | Complex analysis, architecture decisions |\n| `mcp__pal__planner` | Sequential planning | Implementation planning, task breakdown |\n| `mcp__pal__consensus` | Multi-model consensus | Critical decisions, architectural choices |\n| `mcp__pal__codereview` | Systematic code review | PR reviews, security audits (used by `--loop`) |\n| `mcp__pal__precommit` | Git change validation | Pre-commit checks, change impact |\n| `mcp__pal__debug` | Root cause analysis | Complex bugs, systematic debugging |\n\n### LinkUp Search\n\nWeb search integration for current information:\n\n```python\n# Example: Search via Rube MCP\n{\n  \"tools\": [{\n    \"tool_slug\": \"LINKUP_SEARCH\",\n    \"arguments\": {\n      \"query\": \"latest Python 3.12 features\",\n      \"depth\": \"deep\",\n      \"output_type\": \"sourcedAnswer\"\n    }\n  }]\n}\n```\n\n---\n\n## Behavioral Modes\n\nSuperClaude supports multiple behavioral modes that change how the framework operates:\n\n```mermaid\nstateDiagram-v2\n    [*] --> Normal\n\n    Normal --> TaskManagement: >3 steps or complex deps\n    Normal --> TokenEfficiency: --uc flag\n\n    TaskManagement --> Normal: complete\n    TokenEfficiency --> Normal: complete\n\n    TaskManagement --> TokenEfficiency: context > 75%\n\n    state TaskManagement {\n        [*] --> Plan\n        Plan --> Track\n        Track --> Execute\n        Execute --> Evaluate\n        Evaluate --> Iterate\n        Iterate --> [*]\n    }\n```\n\n| Mode | Trigger | Features | Use Case |\n|------|---------|----------|----------|\n| **Normal** | default | Balanced verbosity, standard flow | Day-to-day development |\n| **Task Management** | >3 steps, complex deps | TodoWrite tracking, hierarchical breakdown | Multi-step operations |\n| **Token Efficiency** | `--uc` flag | Compressed symbols, minimal verbosity | Context/cost constraints |\n\n### Token Efficiency Symbols\n\n```\nStatus:  âœ… Done  âŒ Failed  âš ï¸ Warning  ğŸ”„ Progress  â³ Pending\nDomain:  âš¡ Perf  ğŸ” Analysis  ğŸ›¡ï¸ Security  ğŸ“¦ Deploy  ğŸ—ï¸ Arch\nLogic:   â†’ Leads to  â‡’ Transforms  âˆ´ Therefore  Â» Sequence\n```\n\n---\n\n## Installation\n\n### Requirements\n\n- Python 3.10+\n- pip or poetry\n- Claude Code CLI\n\n### Install from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/SuperClaude-Org/SuperClaude_Framework.git\ncd SuperClaude\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # Linux/macOS\n# or: .venv\\Scripts\\activate  # Windows\n\n# Install in development mode\npip install -e .[dev]\n\n# Verify installation\nSuperClaude --help\n```\n\n### Install with SDK Support\n\n```bash\n# Install with Claude Agent SDK integration\npip install -e .[sdk]\n```\n\n---\n\n## Quick Start\n\n### Basic Usage with Claude Code\n\n```bash\n# Start Claude Code\nclaude\n\n# Use SuperClaude commands\n/sc:analyze --deep src/auth.py\n/sc:implement --agent=backend-developer \"Add user authentication\"\n/sc:implement --loop 3 \"Add rate limiting middleware\"  # Iterate up to 3 times\n/sc:test --coverage tests/\n/sc:design --diagram \"microservices architecture\"\n```\n\n### Using the Agentic Loop\n\n```bash\n# Basic loop (uses default MAX_ITERATIONS=3)\n/sc:implement --loop \"Add input validation\"\n\n# Specify max iterations (capped at HARD_MAX=5)\n/sc:implement --loop 5 \"Refactor authentication module\"\n\n# Loop with specific agent\n/sc:implement --loop --agent=security-engineer \"Add CSRF protection\"\n```\n\n### Programmatic Usage with SDK\n\n```python\nfrom SuperClaude.SDK import SuperClaudeSDKClient, SDKOptions\nfrom SuperClaude.Agents.registry import AgentRegistry\nfrom SuperClaude.Agents.selector import AgentSelector\nfrom SuperClaude.Quality.quality_scorer import QualityScorer\n\n# Initialize components\nregistry = AgentRegistry()\nselector = AgentSelector(registry)\nscorer = QualityScorer()\n\n# Create SDK client\nclient = SuperClaudeSDKClient(\n    registry=registry,\n    selector=selector,\n    quality_scorer=scorer\n)\n\n# Execute with SDK\noptions = SDKOptions(\n    model=\"sonnet\",\n    max_turns=50,\n    permission_mode=\"default\"\n)\n\nasync for message in client.execute_with_agent(\n    task=\"Fix the bug in auth.py\",\n    context={\"cwd\": \"/project\"},\n    options=options\n):\n    if message.type == \"text\":\n        print(message.content)\n```\n\n### Using the Agentic Loop Programmatically\n\n```python\nfrom SuperClaude.SDK.agentic_loop import run_sdk_loop, create_sdk_loop_context\n\n# Create context with expectations\ncontext = create_sdk_loop_context(\n    command_name=\"implement\",\n    task=\"Add user authentication\",\n    cwd=\"/project\",\n    requires_evidence=True,\n    expects_file_changes=True,\n    expects_tests=True\n)\n\n# Run SDK loop with quality iteration\nfinal_record, assessment, history = await run_sdk_loop(\n    executor=sdk_executor,\n    task=\"Add user authentication\",\n    context=context,\n    scorer=quality_scorer,\n    max_iterations=3\n)\n\nprint(f\"Final score: {assessment.overall_score}\")\nprint(f\"Band: {assessment.band}\")\nprint(f\"Iterations: {len(history)}\")\n```\n\n---\n\n## Configuration\n\n### CLAUDE.md Integration\n\nSuperClaude integrates with Claude Code via `CLAUDE.md` configuration files:\n\n```markdown\n# ~/.claude/CLAUDE.md (Global)\n\n# SuperClaude Entry Point\n@AGENTS.md\n@CLAUDE_CORE.md\n@FLAGS.md\n@PRINCIPLES.md\n@TOOLS.md\n\n# Behavioral Modes\n@MODE_Normal.md\n@MODE_Task_Management.md\n@MODE_Token_Efficiency.md\n\n# MCP Documentation\n@MCP_Rube.md\n@MCP_Pal.md\n@MCP_LinkUp.md\n```\n\n### Configuration Files (YAML)\n\n| File | Purpose |\n|------|---------|\n| `config/superclaud.yaml` | Main framework config, modes, quality settings |\n| `config/models.yaml` | Model routing, provider settings |\n| `config/quality.yaml` | Quality scoring, thresholds, gates |\n\n---\n\n## Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| **API Keys** | | |\n| `ANTHROPIC_API_KEY` | Claude API key | Required |\n| `OPENAI_API_KEY` | OpenAI API key | Optional |\n| `GOOGLE_API_KEY` | Google/Gemini API key | Optional |\n| `XAI_API_KEY` | xAI/Grok API key | Optional |\n| **Framework** | | |\n| `SUPERCLAUDE_DECOMPOSED` | Enable Skills/Legacy routing | `false` |\n| `SUPERCLAUDE_DECOMPOSED_COMMANDS` | Allowlisted commands | `analyze` |\n| `SUPERCLAUDE_OFFLINE_MODE` | Disable network for testing | `false` |\n| `SUPERCLAUDE_REPO_ROOT` | Repository root path | Auto-detected |\n| `SUPERCLAUDE_SKIP_BOOTSTRAP` | Skip auto-install | `false` |\n| **Telemetry** | | |\n| `SUPERCLAUDE_TELEMETRY_ENABLED` | Enable telemetry | `true` |\n| `SUPERCLAUDE_METRICS_DIR` | Metrics directory | `.superclaude_metrics` |\n\n---\n\n## Extensibility Guide\n\n### Adding a New Agent\n\n1. **Create markdown file** in appropriate `SuperClaude/Agents/Extended/` category:\n\n```markdown\n---\nname: my-custom-agent\ncategory: 01-core-development\ndescription: Expert at custom task\ntriggers:\n  - custom\n  - special\n  - my-task\ntools:\n  - Read\n  - Write\n  - Bash\ndomains:\n  - backend\n  - api\nlanguages:\n  - python\n  - typescript\n---\n\n# My Custom Agent\n\n## Capabilities\n- Specialized capability 1\n- Specialized capability 2\n\n## Approach\n1. Step one\n2. Step two\n```\n\n2. **Run agent discovery** to verify registration:\n\n```python\nfrom SuperClaude.Agents.registry import AgentRegistry\n\nregistry = AgentRegistry()\nregistry.discover_agents(force=True)\nprint(registry.get_agent_config(\"my-custom-agent\"))\n```\n\n### Adding a New Command\n\n1. **Create markdown file** in `SuperClaude/Commands/`:\n\n```markdown\n---\nname: mycommand\ndescription: Does something useful\ncategory: workflow\ncomplexity: medium\ntriggers:\n  - mycommand\n  - my-action\nparameters:\n  - name: target\n    type: string\n    required: true\n    description: Target file or directory\nflags:\n  - name: verbose\n    short: v\n    description: Enable verbose output\n---\n\n# /sc:mycommand\n\n## Usage\n/sc:mycommand [target] --verbose\n```\n\n2. **Implement handler** in `SuperClaude/Commands/executor/` if needed.\n\n---\n\n## Troubleshooting\n\n### Common Issues\n\n#### Loop Terminates Early\n\n**Symptom:** `--loop` stops before quality threshold is met.\n\n**Causes & Solutions:**\n\n| Cause | Solution |\n|-------|----------|\n| Oscillation detected | Scores alternating (e.g., 65â†’72â†’65). Review feedback to find conflicting improvements. |\n| Stagnation detected | Scores not changing. Add more specific requirements or change approach. |\n| Insufficient improvement | Score improved < 5 points. Provide more detailed feedback. |\n| Hard cap reached | Hit HARD_MAX_ITERATIONS=5. This is intentional; refine requirements. |\n| Timeout exceeded | Wall-clock timeout hit. Increase timeout or simplify task. |\n\n#### Low Quality Score\n\n**Symptom:** Score below expected threshold.\n\n**Check deterministic signals:**\n\n```bash\n# View quality assessment details\ncat .superclaude_metrics/quality_assessment_*.json\n```\n\n**Common caps:**\n- Score capped at 30%? Check for critical security issues.\n- Score capped at 40-60%? Check test failures.\n- Score capped at 45%? Check build errors.\n\n#### SDK Not Available\n\n**Symptom:** SDK features not working.\n\n**Solutions:**\n\n```python\nfrom SuperClaude.SDK import is_sdk_available, get_sdk_version\n\nif not is_sdk_available():\n    print(\"SDK not installed. Run: pip install -e .[sdk]\")\nelse:\n    print(f\"SDK version: {get_sdk_version()}\")\n```\n\n### Debug Mode\n\nEnable verbose logging:\n\n```bash\nexport SUPERCLAUD_LOG_LEVEL=DEBUG\n```\n\nView execution traces:\n\n```bash\ncat .superclaude_metrics/execution_*.jsonl\n```\n\n---\n\n## CI/CD Pipeline\n\nSuperClaude uses GitHub Actions for continuous integration and deployment.\n\n```mermaid\nflowchart LR\n    subgraph \"CI Pipeline\"\n        Q[Quality Gate] --> T[Test Matrix<br/>Python 3.10+]\n        T --> C[Coverage Gate<br/>35% min]\n        C --> B[Build Check]\n        B --> BM[Benchmark Smoke]\n    end\n\n    subgraph \"Security Pipeline\"\n        CQ[CodeQL] --> PA[pip-audit]\n        PA --> BA[Bandit]\n    end\n\n    subgraph \"Review Pipeline\"\n        AI[PAL MCP<br/>Consensus Review]\n        RQ[README Quality Check]\n    end\n\n    subgraph \"Deploy Pipeline\"\n        PY[PyPI Publish]\n    end\n```\n\n| Workflow | Trigger | Checks |\n|----------|---------|--------|\n| **CI** (`ci.yml`) | Push/PR | Ruff lint, Ruff format, MyPy, Tests, Coverage (35%), Build |\n| **Security** (`security.yml`) | Push/PR + Weekly | CodeQL, pip-audit, Bandit |\n| **AI Review** (`ai-review.yml`) | PR opened | PAL MCP Consensus Code Review |\n| **README Quality** (`readme-quality-check.yml`) | PR | Documentation quality check |\n| **Claude** (`claude.yml`) | Claude Code integration | CI integration for Claude |\n| **Publish** (`publish-pypi.yml`) | Release | Build, version check, PyPI upload |\n\n---\n\n## Project Structure\n\n```\nSuperClaude/\nâ”œâ”€â”€ SuperClaude/\nâ”‚   â”œâ”€â”€ Agents/\nâ”‚   â”‚   â”œâ”€â”€ Extended/              # 114 extended agents\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 01-core-development/        (10 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 02-language-specialists/    (23 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 03-infrastructure/          (12 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 04-quality-security/        (12 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 05-data-ai/                 (12 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 06-developer-experience/    (10 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 07-specialized-domains/     (11 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 08-business-product/        (10 agents)\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 09-meta-orchestration/      (8 agents)\nâ”‚   â”‚   â”‚   â””â”€â”€ 10-research-analysis/       (6 agents)\nâ”‚   â”‚   â”œâ”€â”€ core/                  # 16 core Python agent implementations\nâ”‚   â”‚   â”œâ”€â”€ base.py                # BaseAgent ABC\nâ”‚   â”‚   â”œâ”€â”€ registry.py            # Agent discovery & catalog\nâ”‚   â”‚   â””â”€â”€ selector.py            # Intelligent selection\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Commands/\nâ”‚   â”‚   â”œâ”€â”€ execution/             # Execution routing\nâ”‚   â”‚   â”‚   â”œâ”€â”€ facade.py          # Skills/Legacy router\nâ”‚   â”‚   â”‚   â”œâ”€â”€ routing.py         # Command router\nâ”‚   â”‚   â”‚   â””â”€â”€ context.py         # Execution context\nâ”‚   â”‚   â”œâ”€â”€ executor/              # Sub-executors\nâ”‚   â”‚   â”‚   â”œâ”€â”€ agent_orchestration.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ consensus.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ git_operations.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ testing.py\nâ”‚   â”‚   â”‚   â””â”€â”€ quality.py\nâ”‚   â”‚   â”œâ”€â”€ command_executor.py    # Main executor\nâ”‚   â”‚   â”œâ”€â”€ parser.py              # Command parsing\nâ”‚   â”‚   â””â”€â”€ registry.py            # Command catalog\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ SDK/                       # Claude Agent SDK Integration\nâ”‚   â”‚   â”œâ”€â”€ __init__.py            # Public API exports\nâ”‚   â”‚   â”œâ”€â”€ client.py              # SuperClaudeSDKClient\nâ”‚   â”‚   â”œâ”€â”€ adapter.py             # AgentToSDKAdapter\nâ”‚   â”‚   â”œâ”€â”€ executor.py            # SDKExecutor\nâ”‚   â”‚   â”œâ”€â”€ agentic_loop.py        # SDK loop integration\nâ”‚   â”‚   â”œâ”€â”€ hooks.py               # Quality & Evidence hooks\nâ”‚   â”‚   â””â”€â”€ types.py               # Type definitions\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Quality/\nâ”‚   â”‚   â”œâ”€â”€ quality_scorer.py      # 9-dimension scoring + agentic loop\nâ”‚   â”‚   â””â”€â”€ validation_pipeline.py # 5-stage validation\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Telemetry/\nâ”‚   â”‚   â”œâ”€â”€ factory.py             # Telemetry factory\nâ”‚   â”‚   â”œâ”€â”€ evidence_store.py      # Evidence collection\nâ”‚   â”‚   â”œâ”€â”€ jsonl.py               # JSONL storage\nâ”‚   â”‚   â””â”€â”€ interfaces.py          # Client interfaces\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Modes/                     # Behavioral modes\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ behavioral_manager.py\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Skills/                    # Skills runtime\nâ”‚   â”œâ”€â”€ Core/                      # Core utilities\nâ”‚   â””â”€â”€ MCP/                       # MCP integrations\nâ”‚\nâ”œâ”€â”€ config/                        # YAML configurations\nâ”œâ”€â”€ setup/                         # Installation system\nâ”œâ”€â”€ tests/                         # Test suites\nâ”œâ”€â”€ Docs/                          # User & developer guides\nâ”œâ”€â”€ scripts/                       # Build scripts\nâ”œâ”€â”€ benchmarks/                    # Performance tests\nâ”œâ”€â”€ .github/workflows/             # CI/CD pipelines\nâ”œâ”€â”€ pyproject.toml                 # Package config\nâ””â”€â”€ README.md                      # This file\n```\n\n---\n\n## Contributing\n\n### Development Setup\n\n```bash\n# Clone and setup\ngit clone https://github.com/SuperClaude-Org/SuperClaude_Framework.git\ncd SuperClaude\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .[dev]\n\n# Run tests\nPYTEST_DISABLE_PLUGIN_AUTOLOAD=1 pytest -m \"not slow\" tests/\n\n# Run linting\nruff check .\nruff format --check .\nmypy SuperClaude --ignore-missing-imports\n```\n\n### Commit Guidelines\n\n- Use concise, imperative subjects\n- Reference issues/specs in body\n- Include test results for significant changes\n- Co-authored-by: Claude for AI-assisted commits\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n---\n\n## Acknowledgments\n\n- **Anthropic** for Claude and Claude Code\n- **OpenAI** for GPT-5 API\n- **Google** for Gemini API\n- **xAI** for Grok API\n- **Composio** for Rube MCP\n- **PAL MCP** for consensus tools\n\n---\n\n<p align=\"center\">\n  <strong>SuperClaude v6.0.0-alpha</strong><br/>\n  Intelligent AI Orchestration for Claude Code<br/>\n  <em>130 Agents â€¢ 13 Commands â€¢ 9 Quality Dimensions â€¢ 3 Modes</em><br/>\n  <em>Claude Agent SDK Integration â€¢ Iterative Development with Deterministic Safety Grounding</em>\n</p>\n",
  "installCommand": "git clone https://github.com/Tony363/SuperClaude ~/.claude/skills/superclaude",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}