{
  "id": "619498cd35499ab6",
  "slug": "superclaude",
  "name": "SuperClaude",
  "description": "A configuration framework that enhances Claude Code with specialized commands, cognitive personas, and development methodologies.",
  "author": "Tony363",
  "authorAvatar": "https://avatars.githubusercontent.com/u/48950649?v=4",
  "repoUrl": "https://github.com/Tony363/SuperClaude",
  "repoFullName": "Tony363/SuperClaude",
  "stars": 9,
  "forks": 0,
  "category": "testing",
  "categories": [
    "testing"
  ],
  "tags": [],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-08-26T17:37:31Z",
  "updatedAt": "2025-12-18T07:36:13Z",
  "lastCommitAt": "2025-12-18T07:36:11Z",
  "source": "github-search",
  "collectedAt": "2025-12-19T03:40:35.394Z",
  "authorUrl": "https://github.com/Tony363",
  "license": "MIT",
  "readme": "# SuperClaude Framework\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/version-6.0.0--alpha-blue\" alt=\"Version\">\n  <img src=\"https://img.shields.io/badge/python-3.10%2B-green\" alt=\"Python\">\n  <img src=\"https://img.shields.io/badge/agents-131-orange\" alt=\"Agents\">\n  <img src=\"https://img.shields.io/badge/commands-13-purple\" alt=\"Commands\">\n  <img src=\"https://img.shields.io/badge/license-MIT-lightgrey\" alt=\"License\">\n</p>\n\n**An intelligent AI orchestration framework for Claude Code that provides multi-model consensus, specialized agents, behavioral modes, and quality-driven execution.**\n\nSuperClaude transforms Claude Code into a powerful development platform with 131 specialized agents, multi-provider AI routing, MCP server integration, and sophisticated quality validation pipelines.\n\n---\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Architecture](#architecture)\n- [Core Components](#core-components)\n  - [Agent System](#agent-system)\n  - [Command System](#command-system)\n  - [Model Router](#model-router)\n  - [MCP Integrations](#mcp-integrations)\n  - [Behavioral Modes](#behavioral-modes)\n  - [Quality Pipeline](#quality-pipeline)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [CI/CD Pipeline](#cicd-pipeline)\n- [Project Structure](#project-structure)\n- [Contributing](#contributing)\n\n---\n\n## Overview\n\nSuperClaude is a sophisticated AI orchestration framework that enhances Claude Code with:\n\n- **131 Specialized Agents**: 15 core + 116 extended agents across 10 categories\n- **Multi-Model Consensus**: Route requests to GPT-5, Gemini 2.5 Pro, Claude, xAI Grok\n- **13 Commands**: analyze, implement, test, design, document, and more\n- **Behavioral Modes**: Normal, Task Management, Token Efficiency\n- **Quality Validation**: Multi-stage pipelines with syntax, security, and performance checks\n- **MCP Server Integration**: Rube (500+ app tools), PAL (consensus & code review), LinkUp (web search)\n\n```mermaid\ngraph TB\n    subgraph \"SuperClaude Framework v6.0.0\"\n        User[User Input] --> Parser[Command Parser]\n        Parser --> Executor[Command Executor]\n\n        Executor --> Router[Model Router]\n        Executor --> Agents[Agent System<br/>131 Agents]\n        Executor --> Modes[Behavioral Modes]\n\n        Router --> Anthropic[Claude Opus 4.1]\n        Router --> OpenAI[GPT-5 / GPT-4.1]\n        Router --> Google[Gemini 2.5 Pro]\n        Router --> xAI[Grok 4]\n\n        Agents --> Registry[Agent Registry<br/>LRU Cache]\n        Registry --> CoreAgents[15 Core Agents]\n        Registry --> ExtendedAgents[116 Extended Agents]\n\n        Executor --> MCP[MCP Integrations]\n        MCP --> Rube[Rube MCP<br/>500+ Apps]\n        MCP --> PAL[PAL MCP<br/>Consensus]\n\n        Executor --> Quality[Quality Pipeline]\n        Quality --> Validation[5 Validation Stages]\n    end\n\n    style User fill:#e1f5fe\n    style Executor fill:#fff3e0\n    style Router fill:#f3e5f5\n    style Agents fill:#e8f5e9\n    style MCP fill:#fce4ec\n```\n\n---\n\n## Architecture\n\n### High-Level System Architecture\n\n```mermaid\nflowchart TB\n    subgraph Input[\"Input Layer\"]\n        CLI[CLI Interface<br/>SuperClaude/superclaude]\n        CLAUDE_MD[CLAUDE.md Config]\n        Flags[Command Flags]\n    end\n\n    subgraph Core[\"Core Framework\"]\n        direction TB\n        CMD[Command System<br/>13 Commands]\n        MODE[Mode Manager<br/>3 Modes]\n        AGENT[Agent Coordinator<br/>131 Agents]\n        ROUTER[Model Router<br/>8 Models]\n    end\n\n    subgraph Execution[\"Execution Layer\"]\n        EXEC[Executor<br/>5,337 lines]\n        QUAL[Quality Scorer<br/>8 Dimensions]\n        VALID[Validation Pipeline<br/>5 Stages]\n        ARTIFACT[Artifact Manager]\n    end\n\n    subgraph External[\"External Services\"]\n        direction LR\n        API_A[Anthropic]\n        API_O[OpenAI]\n        API_G[Google]\n        API_X[xAI]\n        MCP_R[Rube MCP]\n        MCP_P[PAL MCP]\n    end\n\n    subgraph Storage[\"Storage & State\"]\n        STORE[UnifiedStore<br/>SQLite]\n        METRICS[Metrics Store]\n        EVIDENCE[Evidence Files]\n    end\n\n    CLI --> CMD\n    CLAUDE_MD --> CMD\n    Flags --> CMD\n\n    CMD --> MODE\n    CMD --> AGENT\n    CMD --> ROUTER\n\n    MODE --> EXEC\n    AGENT --> EXEC\n    ROUTER --> EXEC\n\n    EXEC --> QUAL\n    EXEC --> VALID\n    EXEC --> ARTIFACT\n\n    ROUTER --> API_A\n    ROUTER --> API_O\n    ROUTER --> API_G\n    ROUTER --> API_X\n\n    EXEC --> MCP_R\n    EXEC --> MCP_P\n\n    EXEC --> STORE\n    QUAL --> METRICS\n    VALID --> EVIDENCE\n```\n\n### Request Flow\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Parser as Command Parser\n    participant Registry as Command Registry\n    participant Executor as Command Executor\n    participant Mode as Mode Manager\n    participant Agent as Agent Selector\n    participant Router as Model Router\n    participant Quality as Quality Pipeline\n\n    User->>Parser: /sc:command --flags\n    Parser->>Registry: Lookup Command\n    Registry-->>Parser: Command Metadata\n    Parser->>Executor: ParsedCommand\n\n    Executor->>Mode: Detect Mode\n    Mode-->>Executor: BehavioralMode\n\n    Executor->>Agent: Select Agent(context)\n    Agent-->>Executor: Best Match Agent\n\n    Executor->>Router: Route Request\n    Router->>Router: Select Provider\n    Router-->>Executor: Model Response\n\n    Executor->>Quality: Validate Output\n    Quality-->>Executor: ValidationResult\n\n    alt Quality Score >= 70\n        Executor-->>User: Success Response\n    else Quality Score < 70\n        Executor->>Agent: Re-delegate with feedback\n        Agent-->>Executor: Improved Result\n        Executor-->>User: Iterated Response\n    end\n```\n\n### Agentic Quality Loop with PAL MCP\n\nWhen `--loop` is enabled, SuperClaude runs an iterative improvement cycle with automatic PAL MCP code review:\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant Executor as Command Executor\n    participant Agents as Expert Sub-Agents<br/>(quality-engineer,<br/>refactoring-expert)\n    participant PAL as PAL MCP<br/>(mcp__pal__codereview)\n    participant Quality as Quality Scorer\n\n    User->>Executor: /sc:implement --loop [n]\n\n    Note over Executor: --loop enables<br/>PAL review automatically\n\n    loop Iteration 1..n (max capped at HARD_MAX_ITERATIONS)\n        Executor->>Agents: Run agent pipeline\n        Agents-->>Executor: Code changes + tests\n\n        Executor->>PAL: mcp__pal__codereview(changed_files)\n        PAL-->>Executor: Review findings\n\n        Executor->>Quality: evaluate(output, context)\n        Quality-->>Executor: QualityAssessment<br/>(score, improvements_needed)\n\n        alt score >= 70 (QUALITY_MET)\n            Executor-->>User: Success Response\n        else score < 70 AND iterations < max\n            Note over Executor: Build feedback context:<br/>improvements_needed,<br/>PAL findings,<br/>current_score\n            Executor->>Agents: Re-delegate with feedback\n        else Oscillation/Stagnation detected\n            Executor-->>User: Best result + warnings\n        else Max iterations reached\n            Executor-->>User: Best result + termination reason\n        end\n    end\n```\n\n**Loop Termination Conditions:**\n| Condition | Description |\n|-----------|-------------|\n| `QUALITY_MET` | Score >= 70, quality threshold achieved |\n| `MAX_ITERATIONS` | Hard cap reached (prevents infinite loops) |\n| `INSUFFICIENT_IMPROVEMENT` | Score improvement below minimum threshold |\n| `OSCILLATION` | Scores alternating up/down without convergence |\n| `STAGNATION` | Scores not changing meaningfully |\n\n**Key Integration Points:**\n- `--loop` flag automatically enables `--pal-review`\n- `QualityDimension.PAL_REVIEW` contributes 10% to overall score\n- Expert sub-agents (`quality-engineer`, `refactoring-expert`) handle remediation\n- Feedback context includes: `improvements_needed`, PAL findings, `current_score`, `target_score`\n\n---\n\n## Core Components\n\n### Agent System\n\nSuperClaude features a sophisticated agent system with **131 specialized agents** organized into 10 categories.\n\n```mermaid\ngraph TB\n    subgraph \"Agent Architecture\"\n        Registry[Agent Registry<br/>LRU Cache: 128 agents<br/>TTL: 1 hour]\n\n        Registry --> Discovery[Agent Discovery]\n        Registry --> Loader[Extended Loader]\n        Registry --> Selector[Agent Selector]\n\n        Discovery --> MD[Markdown Parser]\n        MD --> Config[Agent Config]\n\n        Loader --> Base[BaseAgent ABC]\n        Base --> Generic[Generic Agent]\n        Base --> Heuristic[HeuristicMarkdownAgent]\n\n        Selector --> Scoring[Weighted Scoring]\n        Scoring --> Match[Best Match<br/>Threshold: 0.6]\n    end\n```\n\n#### Agent Selection Algorithm\n\n```mermaid\nflowchart TB\n    Context[Task Context] --> Domain{Domain Match?}\n\n    Domain -->|Yes| DomainScore[+30% Score]\n    Domain -->|No| Keyword{Keyword Match?}\n\n    DomainScore --> Keyword\n    Keyword -->|Yes| KeywordScore[+20% Score]\n    Keyword -->|No| FilePattern{File Pattern?}\n\n    KeywordScore --> FilePattern\n    FilePattern -->|Yes| PatternScore[+20% Score]\n    FilePattern -->|No| Language{Language Match?}\n\n    PatternScore --> Language\n    Language -->|Yes| LangScore[+15% Score]\n    Language -->|No| Framework{Framework Match?}\n\n    LangScore --> Framework\n    Framework -->|Yes| FrameScore[+15% Score]\n    Framework -->|No| Calculate[Calculate Total]\n\n    FrameScore --> Calculate\n    Calculate --> Threshold{Score >= 0.6?}\n    Threshold -->|Yes| Select[Select Agent]\n    Threshold -->|No| Default[Use general-purpose]\n```\n\n#### Agent Categories (131 Total)\n\n```mermaid\nmindmap\n  root((131 Agents))\n    Core Agents\n      15 agents\n      general-purpose\n      root-cause-analyst\n      refactoring-expert\n      security-engineer\n      system-architect\n    01-Core Development\n      11 agents\n      fullstack-developer\n      frontend-developer\n      backend-developer\n    02-Language Specialists\n      23 agents\n      python-pro\n      typescript-pro\n      rust-engineer\n      golang-pro\n    03-Infrastructure\n      12 agents\n      cloud-architect\n      kubernetes-specialist\n      terraform-engineer\n    04-Quality Security\n      12 agents\n      code-reviewer\n      penetration-tester\n      qa-expert\n    05-Data AI\n      12 agents\n      ml-engineer\n      data-scientist\n      llm-architect\n    06-Developer Experience\n      10 agents\n      technical-writer\n      api-designer\n    07-Specialized Domains\n      11 agents\n      domain experts\n    08-Business Product\n      11 agents\n      product-manager\n      business-analyst\n    09-Meta Orchestration\n      8 agents\n      coordinators\n    10-Research Analysis\n      6 agents\n      researchers\n```\n\n#### Agent Coordination Strategies\n\n```mermaid\ngraph LR\n    subgraph \"Coordination Strategies\"\n        H[Hierarchical] --> D[Delegation Tree]\n        C[Consensus] --> V[Voting]\n        P[Pipeline] --> S[Sequential]\n        PA[Parallel] --> Co[Concurrent]\n        A[Adaptive] --> Dy[Dynamic Selection]\n        SW[Swarm] --> Em[Emergent Behavior]\n    end\n```\n\n| Strategy | Description | Use Case |\n|----------|-------------|----------|\n| **Hierarchical** | Top-down task delegation | Complex multi-step tasks |\n| **Consensus** | Multi-agent voting | Critical decisions |\n| **Pipeline** | Sequential processing | Data transformation |\n| **Parallel** | Concurrent execution | Independent subtasks |\n| **Adaptive** | Dynamic strategy selection | Uncertain requirements |\n| **Swarm** | Emergent coordination | Large-scale analysis |\n\n---\n\n### Command System\n\n13 commands available via `/sc:` syntax:\n\n```mermaid\ngraph TB\n    subgraph \"Command System\"\n        Parser[Command Parser<br/>YAML Frontmatter]\n        Registry[Command Registry<br/>Auto-discovery]\n        Executor[Command Executor<br/>5,337 lines]\n\n        Parser --> Registry\n        Registry --> Executor\n\n        subgraph \"Sub-Executors\"\n            AO[agent_orchestration.py]\n            CS[consensus.py]\n            GO[git_operations.py]\n            CM[change_management.py]\n            TE[testing.py]\n            QU[quality.py]\n            AS[ast_analysis.py]\n        end\n\n        Executor --> AO\n        Executor --> CS\n        Executor --> GO\n        Executor --> CM\n        Executor --> TE\n        Executor --> QU\n        Executor --> AS\n    end\n```\n\n| Command | Purpose | Key Flags |\n|---------|---------|-----------|\n| `/sc:analyze` | Code analysis, quality assessment | `--deep`, `--agent` |\n| `/sc:implement` | Feature/code implementation | `--persona`, `--loop` |\n| `/sc:test` | Test execution with coverage | `--coverage`, `--watch` |\n| `/sc:design` | Architecture and system design | `--diagram`, `--adr` |\n| `/sc:document` | Documentation generation | `--api`, `--readme` |\n| `/sc:brainstorm` | Creative ideation | `--divergent`, `--converge` |\n| `/sc:build` | Project building and compilation | `--target`, `--optimize` |\n| `/sc:estimate` | Effort and resource estimation | `--breakdown`, `--risk` |\n| `/sc:explain` | Code/concept explanation | `--depth`, `--audience` |\n| `/sc:improve` | Code enhancement | `--refactor`, `--optimize` |\n| `/sc:workflow` | Multi-step workflow management | `--steps`, `--parallel` |\n| `/sc:git` | Git operations | `--commit`, `--pr` |\n| `/sc:index` | Search and indexing | `--rebuild`, `--query` |\n\n---\n\n### Model Router\n\nThe Model Router intelligently distributes requests across multiple AI providers.\n\n```mermaid\ngraph LR\n    subgraph \"Model Router\"\n        Input[Request] --> Selector[Provider Selector]\n\n        Selector --> |deep_thinking| GPT5[GPT-5<br/>400K context]\n        Selector --> |long_context| Gemini[Gemini 2.5 Pro<br/>2M context]\n        Selector --> |fallback| Claude[Claude Opus 4.1<br/>200K context]\n        Selector --> |fast_iteration| Grok[Grok 4<br/>256K context]\n\n        GPT5 --> Consensus[Consensus Engine]\n        Gemini --> Consensus\n        Claude --> Consensus\n        Grok --> Consensus\n\n        Consensus --> Output[Final Response]\n    end\n```\n\n#### Supported Models\n\n| Provider | Model | Context Window | Features | Priority |\n|----------|-------|----------------|----------|----------|\n| **OpenAI** | GPT-5 | 400K tokens | Thinking, Vision | 1 |\n| **OpenAI** | GPT-4.1 | 1M tokens | Large context | 3 |\n| **OpenAI** | GPT-4o | 128K tokens | Fast, Cost-effective | 4 |\n| **OpenAI** | GPT-4o-mini | 128K tokens | Quick tasks | 5 |\n| **Google** | Gemini 2.5 Pro | **2M tokens** | Thinking, Vision | 1 |\n| **Anthropic** | Claude Opus 4.1 | 200K tokens | Fallback, Validation | 2 |\n| **xAI** | Grok 4 | 256K tokens | Thinking, Fast | 2 |\n| **xAI** | Grok Code Fast | 128K tokens | Quick iteration | 3 |\n\n#### Routing Strategies\n\n```mermaid\ngraph TB\n    subgraph \"Routing Strategies\"\n        DT[deep_thinking] --> |GPT-5, Gemini| Complex[Complex Reasoning]\n        CS[consensus] --> |Ensemble| Critical[Critical Decisions]\n        LC[long_context] --> |Gemini 2.5 Pro| Large[Large Documents]\n        FI[fast_iteration] --> |Grok, GPT-4o-mini| Quick[Quick Tasks]\n        ST[standard] --> |GPT-4o, Claude| General[General Tasks]\n    end\n```\n\n---\n\n### MCP Integrations\n\nSuperClaude integrates with Model Context Protocol (MCP) servers via Claude Code's native tools.\n\n```mermaid\ngraph TB\n    subgraph \"MCP Architecture\"\n        Executor[Command Executor]\n\n        Executor --> RubeInt[Rube MCP]\n        Executor --> PALInt[PAL MCP]\n\n        subgraph \"Rube MCP - 500+ Apps\"\n            RubeInt --> Search[RUBE_SEARCH_TOOLS]\n            RubeInt --> Execute[RUBE_MULTI_EXECUTE_TOOL]\n            RubeInt --> Plan[RUBE_CREATE_PLAN]\n            RubeInt --> Connect[RUBE_MANAGE_CONNECTIONS]\n\n            Execute --> Slack[Slack]\n            Execute --> GitHub[GitHub]\n            Execute --> Gmail[Gmail]\n            Execute --> Sheets[Google Sheets]\n            Execute --> LinkUp[LinkUp Search]\n        end\n\n        subgraph \"PAL MCP - Consensus & Analysis\"\n            PALInt --> Chat[chat]\n            PALInt --> Think[thinkdeep]\n            PALInt --> Plan2[planner]\n            PALInt --> Consensus[consensus]\n            PALInt --> CodeRev[codereview]\n            PALInt --> PreCommit[precommit]\n            PALInt --> Debug[debug]\n        end\n    end\n```\n\n#### Rube MCP Tools\n\n| Tool | Purpose |\n|------|---------|\n| `RUBE_SEARCH_TOOLS` | Discover available app integrations |\n| `RUBE_MULTI_EXECUTE_TOOL` | Execute up to 50 tools in parallel |\n| `RUBE_CREATE_PLAN` | Create workflow execution plans |\n| `RUBE_MANAGE_CONNECTIONS` | Manage OAuth/API connections |\n| `RUBE_REMOTE_WORKBENCH` | Execute Python in sandbox |\n| `RUBE_CREATE_UPDATE_RECIPE` | Create reusable automation recipes |\n\n#### PAL MCP Tools\n\n| Tool | Purpose |\n|------|---------|\n| `mcp__pal__chat` | Collaborative thinking with external models |\n| `mcp__pal__thinkdeep` | Multi-stage investigation and reasoning |\n| `mcp__pal__planner` | Sequential planning with revision |\n| `mcp__pal__consensus` | Multi-model consensus building |\n| `mcp__pal__codereview` | Systematic code review with expert validation |\n| `mcp__pal__precommit` | Git change validation |\n| `mcp__pal__debug` | Systematic debugging and root cause analysis |\n\n---\n\n### Behavioral Modes\n\nSuperClaude supports three behavioral modes that change how the framework operates.\n\n```mermaid\nstateDiagram-v2\n    [*] --> Normal\n\n    Normal --> TaskManagement: >3 steps or complex deps\n    Normal --> TokenEfficiency: --uc flag\n\n    TaskManagement --> Normal: complete\n    TokenEfficiency --> Normal: complete\n\n    TaskManagement --> TokenEfficiency: context > 75%\n\n    state TaskManagement {\n        [*] --> Plan\n        Plan --> Track\n        Track --> Execute\n        Execute --> Evaluate\n        Evaluate --> Iterate\n        Iterate --> [*]\n    }\n```\n\n| Mode | Trigger | Features | Use Case |\n|------|---------|----------|----------|\n| **Normal** | default | Balanced verbosity, standard flow | Day-to-day development |\n| **Task Management** | >3 steps, complex deps | TodoWrite tracking, hierarchical breakdown, UnifiedStore persistence | Multi-step operations |\n| **Token Efficiency** | `--uc` flag | Compressed symbols, minimal verbosity, context optimization | Context/cost constraints |\n\n#### Token Efficiency Symbols\n\n```\nStatus:  âœ… Done  âŒ Failed  âš ï¸ Warning  ðŸ”„ Progress  â³ Pending\nDomain:  âš¡ Perf  ðŸ” Analysis  ðŸ›¡ï¸ Security  ðŸ“¦ Deploy  ðŸ—ï¸ Arch\nLogic:   â†’ Leads to  â‡’ Transforms  âˆ´ Therefore  Â» Sequence\n```\n\n**Example:**\n```\nStandard: \"The authentication system has a security vulnerability\"\nToken Efficient: \"auth.js:45 â†’ ðŸ›¡ï¸ sec risk in user val()\"\n```\n\n---\n\n### Quality Pipeline\n\nThe validation pipeline enforces layered quality checks with short-circuit behavior.\n\n```mermaid\nflowchart TB\n    subgraph \"Validation Pipeline\"\n        Input[Context] --> Syntax[Syntax Stage<br/>Required]\n\n        Syntax -->|passed| Security[Security Stage<br/>Required]\n        Syntax -->|fatal| Skip1[Skip All]\n\n        Security -->|passed| Style[Style Stage<br/>Optional]\n        Security -->|fatal| Skip2[Skip All]\n\n        Style --> Tests[Tests Stage<br/>Required]\n\n        Tests -->|passed| Perf[Performance Stage<br/>Optional]\n        Tests -->|fatal| Skip3[Skip All]\n\n        Perf --> Results[Aggregate Results]\n        Skip1 --> Results\n        Skip2 --> Results\n        Skip3 --> Results\n\n        Results --> Evidence[Write Evidence<br/>JSON files]\n    end\n```\n\n#### Quality Scoring (8 Dimensions)\n\n```mermaid\npie title Quality Score Weights\n    \"Correctness\" : 25\n    \"Completeness\" : 20\n    \"Performance\" : 10\n    \"Maintainability\" : 10\n    \"Security\" : 10\n    \"Scalability\" : 10\n    \"Testability\" : 10\n    \"Usability\" : 5\n```\n\n| Dimension | Weight | Metrics |\n|-----------|--------|---------|\n| **Correctness** | 25% | Tests pass, no runtime errors, output validation |\n| **Completeness** | 20% | Feature coverage, edge cases, documentation |\n| **Performance** | 10% | Time/space complexity, resource usage |\n| **Maintainability** | 10% | Readability, modularity, naming |\n| **Security** | 10% | Input validation, authentication, data protection |\n| **Scalability** | 10% | Architecture, database design, caching |\n| **Testability** | 10% | Unit tests, integration tests, test quality |\n| **Usability** | 5% | UI consistency, error messages, accessibility |\n\n#### Auto-Actions\n\n| Score Range | Action |\n|-------------|--------|\n| < 50 | Delegate to quality-engineer, escalate |\n| 50-69 | Iterate with feedback (max 5 iterations) |\n| 70-89 | Accept with improvement suggestions |\n| 90+ | Auto-approve, fast-track |\n\n---\n\n## Installation\n\n### Requirements\n\n- Python 3.10+\n- pip or poetry\n\n### Install from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/SuperClaude-Org/SuperClaude_Framework.git\ncd SuperClaude\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # Linux/macOS\n# or: .venv\\Scripts\\activate  # Windows\n\n# Install in development mode\npip install -e .[dev]\n\n# Verify installation\nSuperClaude --help\n```\n\n### Environment Variables\n\n```bash\n# Required API Keys\nexport ANTHROPIC_API_KEY=\"your-key\"\nexport OPENAI_API_KEY=\"your-key\"\nexport GOOGLE_API_KEY=\"your-key\"\nexport XAI_API_KEY=\"your-key\"\n\n# Optional Configuration\nexport SUPERCLAUDE_OFFLINE_MODE=\"1\"  # Disable network for testing\nexport SC_NETWORK_MODE=\"online\"       # or \"offline\"\n```\n\n---\n\n## Quick Start\n\n### Basic Usage with Claude Code\n\n```bash\n# Start Claude Code\nclaude\n\n# Use SuperClaude commands\n/sc:analyze --deep src/auth.py\n/sc:implement --agent=backend-developer \"Add user authentication\"\n/sc:test --coverage tests/\n/sc:design --diagram \"microservices architecture\"\n```\n\n### Programmatic Usage\n\n```python\nfrom SuperClaude.Commands.command_executor import CommandExecutor\nfrom SuperClaude.Agents.registry import AgentRegistry\n\n# Initialize\nregistry = AgentRegistry()\nexecutor = CommandExecutor()\n\n# Execute command\nresult = await executor.execute(\"/sc:analyze --agent=root-cause-analyst src/bug.py\")\n\nif result.success:\n    print(f\"Analysis complete: {result.output}\")\n    print(f\"Quality score: {result.quality_score}\")\nelse:\n    print(f\"Errors: {result.errors}\")\n```\n\n---\n\n## Configuration\n\n### CLAUDE.md Integration\n\nSuperClaude integrates with Claude Code via `CLAUDE.md` configuration files:\n\n```markdown\n# ~/.claude/CLAUDE.md (Global)\n\n# SuperClaude Entry Point\n@AGENTS.md\n@CLAUDE_CORE.md\n@FLAGS.md\n@PRINCIPLES.md\n@TOOLS.md\n\n# Behavioral Modes\n@MODE_Normal.md\n@MODE_Task_Management.md\n@MODE_Token_Efficiency.md\n\n# MCP Documentation\n@MCP_Rube.md\n@MCP_Pal.md\n@MCP_LinkUp.md\n```\n\n### Configuration Files (YAML)\n\n| File | Purpose |\n|------|---------|\n| `agents.yaml` | Agent system config, selection algorithm |\n| `models.yaml` | Model routing, provider settings |\n| `quality.yaml` | Quality scoring, thresholds, gates |\n| `mcp.yaml` | MCP server references |\n| `consensus_policies.yaml` | Multi-model consensus rules |\n\n---\n\n## CI/CD Pipeline\n\nSuperClaude uses GitHub Actions for continuous integration and deployment.\n\n```mermaid\nflowchart LR\n    subgraph \"CI Pipeline\"\n        Q[Quality Gate] --> T[Test Matrix<br/>Python 3.10]\n        T --> C[Coverage Gate<br/>35% min]\n        C --> B[Build Check]\n        B --> BM[Benchmark Smoke]\n    end\n\n    subgraph \"Security Pipeline\"\n        CQ[CodeQL] --> PA[pip-audit]\n        PA --> BA[Bandit]\n    end\n\n    subgraph \"Review Pipeline\"\n        AI[PAL MCP<br/>Consensus Review]\n    end\n\n    subgraph \"Deploy Pipeline\"\n        PY[PyPI Publish]\n    end\n```\n\n| Workflow | Trigger | Checks |\n|----------|---------|--------|\n| **CI** | Push/PR | Ruff lint, Ruff format, MyPy, Tests (Python 3.10), Coverage (35%), Build |\n| **Security** | Push/PR + Weekly | CodeQL, pip-audit, Bandit |\n| **AI Review** | PR opened | PAL MCP Consensus Code Review (multi-model) |\n| **Publish** | Release | Build, version check, PyPI upload |\n| **README Quality** | README changes | Structure, links, translation sync |\n\n---\n\n## Project Structure\n\n```\nSuperClaude/\nâ”œâ”€â”€ SuperClaude/\nâ”‚   â”œâ”€â”€ Agents/\nâ”‚   â”‚   â”œâ”€â”€ Extended/              # 116 extended agents\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 01-core-development/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 02-language-specialists/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 03-infrastructure/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 04-quality-security/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 05-data-ai/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 06-developer-experience/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 07-specialized-domains/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 08-business-product/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ 09-meta-orchestration/\nâ”‚   â”‚   â”‚   â””â”€â”€ 10-research-analysis/\nâ”‚   â”‚   â”œâ”€â”€ base.py                # BaseAgent ABC\nâ”‚   â”‚   â”œâ”€â”€ registry.py            # Agent discovery & catalog\nâ”‚   â”‚   â”œâ”€â”€ extended_loader.py     # LRU caching loader\nâ”‚   â”‚   â”œâ”€â”€ selector.py            # Intelligent selection\nâ”‚   â”‚   â””â”€â”€ cli.py                 # Agent CLI interface\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ APIClients/\nâ”‚   â”‚   â”œâ”€â”€ anthropic_client.py    # Claude API\nâ”‚   â”‚   â”œâ”€â”€ openai_client.py       # GPT API\nâ”‚   â”‚   â”œâ”€â”€ google_client.py       # Gemini API\nâ”‚   â”‚   â”œâ”€â”€ xai_client.py          # Grok API\nâ”‚   â”‚   â””â”€â”€ http_utils.py          # Shared HTTP utilities\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Commands/\nâ”‚   â”‚   â”œâ”€â”€ command_executor.py    # Main executor (5,337 lines)\nâ”‚   â”‚   â”œâ”€â”€ executor/              # Sub-executors\nâ”‚   â”‚   â”‚   â”œâ”€â”€ agent_orchestration.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ consensus.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ git_operations.py\nâ”‚   â”‚   â”‚   â”œâ”€â”€ testing.py\nâ”‚   â”‚   â”‚   â””â”€â”€ quality.py\nâ”‚   â”‚   â”œâ”€â”€ parser.py              # Command parsing\nâ”‚   â”‚   â””â”€â”€ registry.py            # Command catalog\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Config/                    # YAML configurations\nâ”‚   â”œâ”€â”€ Core/                      # Core markdown docs\nâ”‚   â”œâ”€â”€ MCP/                       # MCP documentation\nâ”‚   â”œâ”€â”€ ModelRouter/\nâ”‚   â”‚   â”œâ”€â”€ router.py              # Intelligent routing\nâ”‚   â”‚   â”œâ”€â”€ models.py              # Model definitions\nâ”‚   â”‚   â””â”€â”€ consensus.py           # Consensus strategies\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ Modes/\nâ”‚   â”‚   â”œâ”€â”€ MODE_Normal.md\nâ”‚   â”‚   â”œâ”€â”€ MODE_Task_Management.md\nâ”‚   â”‚   â””â”€â”€ MODE_Token_Efficiency.md\nâ”‚   â”‚\nâ”‚   â””â”€â”€ Quality/\nâ”‚       â”œâ”€â”€ validation_pipeline.py\nâ”‚       â””â”€â”€ quality_scorer.py      # 8-dimension scoring\nâ”‚\nâ”œâ”€â”€ setup/                         # Installation system\nâ”‚   â”œâ”€â”€ cli/                       # CLI setup\nâ”‚   â”œâ”€â”€ core/                      # Core installer\nâ”‚   â”œâ”€â”€ components/                # Modular components\nâ”‚   â”œâ”€â”€ services/                  # Configuration services\nâ”‚   â””â”€â”€ utils/                     # Security, logging, UI\nâ”‚\nâ”œâ”€â”€ tests/                         # 42 test files\nâ”œâ”€â”€ Docs/                          # User & developer guides\nâ”œâ”€â”€ examples/                      # Integration demos\nâ”œâ”€â”€ scripts/                       # Build scripts\nâ”œâ”€â”€ benchmarks/                    # Performance tests\nâ”œâ”€â”€ .github/workflows/             # CI/CD pipelines\nâ”œâ”€â”€ pyproject.toml                 # Package config\nâ””â”€â”€ README.md                      # This file\n```\n\n---\n\n## Contributing\n\n### Development Setup\n\n```bash\n# Clone and setup\ngit clone https://github.com/SuperClaude-Org/SuperClaude_Framework.git\ncd SuperClaude\npython -m venv .venv\nsource .venv/bin/activate\npip install -e .[dev]\n\n# Run tests\nPYTEST_DISABLE_PLUGIN_AUTOLOAD=1 pytest -m \"not slow\" tests/\n\n# Run linting\nruff check .\nruff format --check .\nmypy SuperClaude --ignore-missing-imports\n```\n\n### Adding New Agents\n\n1. Create markdown file in appropriate `Extended/` category\n2. Define agent metadata: id, name, triggers, domains, languages\n3. Run agent discovery to verify registration\n4. Add tests for agent selection\n\n### Commit Guidelines\n\n- Use concise, imperative subjects\n- Reference issues/specs in body\n- Include test results for significant changes\n- Co-authored-by: Claude for AI-assisted commits\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n---\n\n## Acknowledgments\n\n- **Anthropic** for Claude and Claude Code\n- **OpenAI** for GPT-5 API\n- **Google** for Gemini API\n- **xAI** for Grok API\n- **Composio** for Rube MCP\n- **PAL MCP** for consensus tools\n\n---\n\n<p align=\"center\">\n  <strong>SuperClaude v6.0.0-alpha</strong><br/>\n  Intelligent AI Orchestration for Claude Code<br/>\n  <em>131 Agents â€¢ 13 Commands â€¢ 8 Models â€¢ 3 Modes</em>\n</p>\n",
  "installCommand": "git clone https://github.com/Tony363/SuperClaude ~/.claude/skills/superclaude",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}