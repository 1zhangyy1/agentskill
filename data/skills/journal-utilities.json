{
  "id": "157266f9b82bf1b3",
  "slug": "journal-utilities",
  "name": "Journal Utilities",
  "description": "Utilities and Documentation for creating contents for the Active Inference Journal",
  "author": "ActiveInferenceInstitute",
  "authorAvatar": "https://avatars.githubusercontent.com/u/79860900?v=4",
  "repoUrl": "https://github.com/ActiveInferenceInstitute/Journal-Utilities",
  "repoFullName": "ActiveInferenceInstitute/Journal-Utilities",
  "stars": 9,
  "forks": 3,
  "category": "writing",
  "categories": [
    "writing"
  ],
  "tags": [],
  "tier": 3,
  "status": "maintained",
  "createdAt": "2022-11-07T14:21:08Z",
  "updatedAt": "2025-11-06T21:21:10Z",
  "lastCommitAt": "2025-11-06T21:21:06Z",
  "source": "github-search",
  "collectedAt": "2025-12-19T03:46:25.881Z",
  "authorUrl": "https://github.com/ActiveInferenceInstitute",
  "license": "CC0-1.0",
  "readme": "# Journal-Utilities\nUtilities and Documentation for creating contents for the Active Inference Journal\nhttps://github.com/ActiveInferenceInstitute/ActiveInferenceJournal\n\nThis repository provides a complete pipeline for processing Active Inference Journal content:\n- **Transcription**: Local transcription pipeline using WhisperX\n- **Entity Extraction**: Extract entities and relationships from transcripts using Cohere AI\n- **Graph Storage**: Store and query data in SurrealDB graph database\n\n---\n## WhisperX Transcription Pipeline\n\n## Installation\n\n### Prerequisites\n\n1. Install [uv](https://github.com/astral-sh/uv) - Fast Python package installer\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Ensure CUDA 12.8 is installed for GPU support (optional but recommended)\n\n### Setup with uv\n\n```bash\n# Clone the repository\ngit clone https://github.com/ActiveInferenceInstitute/Journal-Utilities.git\ncd Journal-Utilities\n\n# Create virtual environment and install dependencies\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install all dependencies including PyTorch with CUDA support\nuv pip install -e .\n# For CUDA 12.8 support (required for GPU acceleration)\nuv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n\n# Install cuDNN 8 (required for pyannote speaker embeddings)\nsudo apt install libcudnn8 libcudnn8-dev -y\nsudo ldconfig\n\n# For development\nuv pip install -e \".[dev]\"\n```\n\n**Note:** After installation, you'll need to apply compatibility patches to WhisperX for pyannote.audio 4.0+. Run:\n```bash\npython scripts/patch_whisperx.py\n```\n\n### Install ffmpeg\n```bash\nwget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x\n```\n\n### Setup .env file\n\n1. [Generate a Hugging Face Token](https://huggingface.co/settings/tokens) and accept the user agreement for the following models:\n   - [Segmentation](https://huggingface.co/pyannote/segmentation-3.0)\n   - [Speaker-Diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n   - [Speaker-Diarization-Community-1](https://hf.co/pyannote/speaker-diarization-community-1) (for speaker embeddings)\n\n2. Get the YouTube Data API v3 Key from https://console.developers.google.com/apis/\n3. Get Your Coda API Token at https://coda.io/account, scroll to \"API settings,\" and generate an API token.\n\n4. Configure environment variables:\n```bash\ncp .env.example .env\n```\n\nUpdate the following values in `.env`:\n- `HUGGINGFACE_TOKEN`: Your Hugging Face token\n- `API_KEY`: Your YouTube Data API v3 key\n- `WAV_DIRECTORY`: Directory for WAV file storage\n- `OUTPUT_DIR`: Output directory for processed files\n- `JOURNAL_REPO_DIR`: Path to Active Inference Journal repository\n- `CODA_API_TOKEN`: Your Coda API token (for fetching session data)\n\n## Usage\n\n### Complete Workflow\n\nThe typical workflow consists of these steps:\n\n```bash\n# 1. Start the database\nmake db-start\n\n# 2. Fetch latest data from Coda API\nmake fetch-coda\n\n# 3. Import sessions into SurrealDB (with audit trail)\nmake import-sessions\n\n# 4. Fetch metadata from YouTube API\nmake fetch-metadata\n\n# 5. Run WhisperX transcription\nmake transcribe\n\n# 6. Copy processed files to journal repository\nmake copy-to-journal\n```\n\n### Individual Steps\n\n#### Fetch Data from Coda\n```bash\nmake fetch-coda\n```\nDownloads the latest session data from Coda API. The JSON file can be formatted in VS Code with `Format Document` for better readability.\n\n#### Import Sessions\n```bash\nmake import-sessions\n# Or with custom JSON file:\npython src/ingest_db_create_wav.py --step import --json /path/to/file.json\n```\nImports sessions with full audit trail tracking. Use rollback functions if needed.\n\n#### Fetch YouTube Metadata\n```bash\nmake fetch-metadata\n```\nAny \"private video\" failures should be added to `src/private_videos.json` to skip youtube metadata fetching and transcription.\n\n#### Run Transcription\n```bash\nmake transcribe\n```\nThis script:\n- Loads WAV files from the database\n- Performs transcription using WhisperX\n- Applies speaker diarization and alignment\n- Stores results back in SurrealDB\n\n#### Copy to Journal\n```bash\nmake copy-to-journal\n```\nOrganizes transcripts by category/series/episode in the journal repository.\n\n---\n## Entity Extraction Pipeline (JournalRAG)\n\n### Overview\n\nThe entity extraction pipeline uses Cohere AI to analyze transcripts and extract:\n- **Entities**: People, organizations, concepts, theories, methodologies, publications, events, and locations\n- **Relationships**: Connections between entities (collaborations, studies, applications, etc.)\n\nAll extracted data is stored in the SurrealDB graph database for semantic queries and analysis.\n\n### Entity Types\n\n- **Person**: Researchers, contributors, speakers\n- **Organization**: Institutions, research groups\n- **Concept**: Theoretical concepts, ideas\n- **Theory**: Formal theories, frameworks\n- **Methodology**: Research methods, approaches\n- **Publication**: Papers, books, articles\n- **Event**: Conferences, workshops, meetings\n- **Location**: Physical or virtual locations\n\n### Relationship Types\n\n- `collaborates_with`: Between persons or organizations\n- `studies`: Person studying a concept/theory\n- `applies`: Application of methodology/theory\n- `extends`: One theory extending another\n- `member_of`: Person member of organization\n- `located_at`: Entity at a location\n- `publishes`: Publication relationships\n\n### Usage\n\n#### Process a Transcript for Entity Extraction\n\n```python\nimport asyncio\nfrom pathlib import Path\nfrom journalrag.main import JournalRAGPipeline\n\nasync def main():\n    pipeline = JournalRAGPipeline()\n    await pipeline.connect()\n\n    # Process a transcript file\n    transcript_path = Path(\"path/to/transcript.txt\")\n    stats = await pipeline.process_transcript_file(transcript_path)\n\n    print(f\"Extracted {stats['entities']} entities\")\n    print(f\"Extracted {stats['relationships']} relationships\")\n\n    await pipeline.disconnect()\n\nasyncio.run(main())\n```\n\n#### Query Extracted Entities\n\n```python\nimport asyncio\nfrom journalrag.graph import SurrealDBClient\n\nasync def main():\n    client = SurrealDBClient()\n    await client.connect()\n\n    # Get an entity by name\n    entity = await client.get_entity_by_name(\"Active Inference\")\n    print(entity)\n\n    # Query entities by type\n    results = await client.query(\n        \"SELECT * FROM entity WHERE type = $type\",\n        {\"type\": \"concept\"}\n    )\n    print(results)\n\n    await client.disconnect()\n\nasyncio.run(main())\n```\n\n### Configuration\n\nThe entity extraction pipeline requires additional environment variables in `.env`:\n\n```env\n# Cohere API (for entity extraction)\nCOHERE_API_KEY=your_cohere_api_key_here\nCOHERE_MODEL=command-a-03-2025\n```\n\n---\n### Query Database\n```bash\nsurreal sql --endpoint http://localhost:8080 --username root --password root --namespace actinf --database actinf\n```\n\nExample queries:\n```sql\n-- View all sessions\nSELECT * FROM session;\n\n-- View transcribed sessions\nSELECT * FROM session WHERE transcribed = true;\n\n-- View sessions pending transcription\nSELECT * FROM session WHERE transcribed = false AND is_private != true;\n\n-- View specific session by name\nSELECT * FROM session WHERE session_name = 'video_id';\n\n-- View import audit trail\nSELECT * FROM import_audit ORDER BY timestamp DESC LIMIT 10;\n\n-- View recent import summary\nSELECT * FROM import_audit WHERE operation = 'import_summary' ORDER BY timestamp DESC;\n```\n\n### Database Maintenance\n```bash\n# Upgrade SurrealDB\nsudo surreal upgrade\n\n# Fix database after upgrade\nsurreal fix rocksdb://database\n```\n\n## Testing\n\nRun unit tests:\n```bash\npython -m unittest tests.test_output_final_artifacts\npython -m unittest tests.test_transcript\n```\n\n## Project Structure\n\n```\nJournal-Utilities/\n├── src/\n│   ├── journal_utilities/       # Transcription pipeline\n│   │   ├── ingest_db_create_wav.py\n│   │   ├── transcribe.py\n│   │   └── fix_scheduled_dates.py\n│   ├── journalrag/             # Entity extraction pipeline\n│   │   ├── main.py             # Main pipeline\n│   │   ├── extractors/         # Entity extraction (Cohere)\n│   │   │   └── cohere_extractor.py\n│   │   ├── graph/              # Graph database (SurrealDB)\n│   │   │   └── surreal_client.py\n│   │   ├── models/             # Pydantic data models\n│   │   │   └── entities.py\n│   │   ├── adapters/           # Data adapters\n│   │   │   └── entity_adapter.py\n│   │   ├── schemas/            # JSON schemas for entity extraction\n│   │   ├── settings.py         # Configuration management\n│   │   └── utils/              # Utilities\n│   │       └── logging.py\n│   └── private_videos.json     # List of private video IDs\n├── tests/                      # Unit tests\n├── data/                       # Database and output files\n│   ├── database/               # SurrealDB storage\n│   ├── input/                  # Input data files (Coda JSON)\n│   └── output/                 # Processed outputs\n├── Archive/                    # Archived AssemblyAI tools\n├── Makefile                    # Workflow automation\n├── CLAUDE.md                   # Documentation for Claude Code\n├── README.md                   # This file\n├── .env.example                # Environment configuration template\n└── pyproject.toml              # Python package configuration\n```\n\n## Archived Components\n\nThe AssemblyAI-based transcription tools have been moved to the `Archive/` directory. These legacy tools provided cloud-based transcription with features like custom vocabulary boosting, spell checking, and document conversion. They remain available for historical reference but are no longer actively maintained.\n\n## Acknowledgements\n\n- WhisperX transcription pipeline and SurrealDB integration contributed by Holly Grimm @hollygrimm, 2024\n- Initial AssemblyAI scripts and documentation contributed by Dave Douglass, November 2022\n\n\n",
  "installCommand": "git clone https://github.com/ActiveInferenceInstitute/Journal-Utilities ~/.claude/skills/journal-utilities",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}