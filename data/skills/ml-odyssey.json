{
  "id": "16676664f98bc3a0",
  "slug": "ml-odyssey",
  "name": "Ml Odyssey",
  "description": "Implementation of older AI papers for the modern age.",
  "author": "mvillmow",
  "authorAvatar": "https://avatars.githubusercontent.com/u/4211002?v=4",
  "repoUrl": "https://github.com/mvillmow/ml-odyssey",
  "repoFullName": "mvillmow/ml-odyssey",
  "stars": 6,
  "forks": 1,
  "category": "ai-ml",
  "categories": [
    "ai-ml"
  ],
  "tags": [],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-11-03T20:56:15Z",
  "updatedAt": "2025-12-11T06:41:07Z",
  "lastCommitAt": "2025-12-11T07:37:20Z",
  "source": "github-search",
  "collectedAt": "2025-12-11T09:00:33.315Z",
  "authorUrl": "https://github.com/mvillmow",
  "license": "BSD-3-Clause",
  "readme": "# ML Odyssey\n\nA Mojo-based AI research platform for reproducing classic deep learning papers.\n\n[![Mojo](https://img.shields.io/badge/Mojo-0.26+-orange.svg)](https://www.modular.com/mojo)\n[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n\n**Status**: Active Research Project | **Current Focus**: Foundation Models\n\n## Overview\n\nML Odyssey is a from-scratch implementation of classic deep learning papers in Mojo, designed to demonstrate modern\nsystems programming for AI. The project provides pure Mojo implementations of neural network architectures (LeNet-5,\nAlexNet, VGG-16, ResNet-18, etc.), manual gradient computation for educational clarity, and a production-quality\nshared library with tensor operations, optimizers, and training loops.\n\nThis is a **research and education platform**, not a production ML framework. Think \"PyTorch from scratch\" rather\nthan \"use this for production.\"\n\n## Quick Start\n\n### Prerequisites\n\n- **Mojo 0.26+** ([Download from Modular](https://www.modular.com/mojo))\n- **Pixi** (optional but recommended for dependency management)\n- **Just** ([Install from just.systems](https://just.systems/))\n- **Git** for cloning the repository\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/mvillmow/ml-odyssey.git\ncd ml-odyssey\n\n# Install dependencies (if using Pixi)\npixi install\n\n# Build the shared library\njust build\n```\n\n### Train Your First Model: LeNet-5 on EMNIST\n\nLeNet-5 is the **only fully functional model** with complete forward/backward passes and achieves **~81% accuracy** on EMNIST.\n\n```bash\n# 1. Download the dataset\npython scripts/download_emnist.py --split balanced\n\n# 2. Train LeNet-5 (simple command, 10 epochs)\njust train\n\n# Or with full control:\npixi run mojo run -I . examples/lenet-emnist/train.mojo \\\n  --epochs 10 \\\n  --batch-size 32 \\\n  --lr 0.001\n\n# 3. Run inference on test set\njust infer lenet lenet5_weights\n```\n\n**Expected Results:**\n\n- Training: ~81% accuracy on EMNIST Balanced (47 classes)\n- Training time: ~30 minutes on modern CPU\n- Model size: ~61K parameters (~244KB)\n\n## Project Status\n\n### What Works ‚úÖ\n\n- **LeNet-5 + EMNIST**: Fully functional training pipeline with 81% accuracy\n- **Shared Library**:\n  - Core ops: conv2d, maxpool2d, linear, relu, sigmoid, tanh (forward + backward)\n  - Training: SGD optimizer, cross-entropy loss, data loaders, metrics\n  - Utils: Argument parsing, logging, weight serialization\n- **Build System**: Comprehensive justfile with 40+ recipes\n- **Documentation**: BUILD.md (489 lines), INSTALL.md (615 lines)\n\n### In Development üöß\n\n- **7 models with forward-only passes**: AlexNet, VGG-16, ResNet-18, DenseNet-121, GoogLeNet, MobileNetV1\n  - Complete forward passes implemented\n  - Missing: ~2000-3000 lines of backward pass gradients per model\n  - See [Issue #2576](https://github.com/mvillmow/ml-odyssey/issues/2576) for details\n- **Optimizer Enhancements**: SGD with momentum, Adam, learning rate schedulers\n- **Autograd System**: Replacing manual gradient computation\n\n### Known Issues ‚ö†Ô∏è\n\n- **Broken Examples**: Getting-started examples use non-existent Sequential/Layer API\n  - See [Issue #2575](https://github.com/mvillmow/ml-odyssey/issues/2575)\n- **Dataset Coverage**: Only EMNIST download script exists, CIFAR-10 script needed\n  - See [Issue #2577](https://github.com/mvillmow/ml-odyssey/issues/2577)\n\n## Model Zoo\n\n| Model | Status | Dataset | Forward | Backward |\n|-------|--------|---------|---------|----------|\n| **LeNet-5** | ‚úÖ **READY** | EMNIST | ‚úÖ Complete | ‚úÖ Complete |\n| AlexNet | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n| VGG-16 | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n| ResNet-18 | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n| DenseNet-121 | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n| GoogLeNet | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n| MobileNetV1 | Forward only | CIFAR-10 | ‚úÖ Complete | ‚ùå Missing |\n\n**Note**: Each incomplete model needs ~2000-3000 lines of gradient computation code. See individual model directories\nfor `GAP_ANALYSIS.md` with detailed backward pass requirements.\n\n## Build & Development\n\n### Quick Reference\n\n```bash\n# Show all available commands\njust --list\n\n# Build commands\njust build              # Build shared library (debug mode)\njust build-release      # Build with optimizations\njust ci-validate        # Full CI validation (build + test)\n\n# Testing\njust test               # Run all tests (Mojo + Python)\njust test-mojo          # Mojo tests only\n\n# Linting & Formatting\njust lint               # Run all linters\njust format             # Format all files\n\n# Training\njust train              # Train LeNet-5 with defaults\njust train lenet fp16 20  # Train with FP16, 20 epochs\n```\n\n### Detailed Documentation\n\nFor comprehensive build and installation instructions, see:\n\n- **[shared/BUILD.md](shared/BUILD.md)** - Complete build system guide (489 lines)\n- **[shared/INSTALL.md](shared/INSTALL.md)** - Installation methods and troubleshooting (615 lines)\n\n### Development Workflow\n\n```bash\n# 1. Set up environment\npixi install\npixi run pre-commit install\n\n# 2. Make changes to shared library\n# Edit files in shared/core/, shared/training/, etc.\n\n# 3. Build and test\njust build\njust test-mojo\n\n# 4. Run pre-commit checks\njust pre-commit\n\n# 5. Create PR\ngit checkout -b feature/my-feature\ngit add .\ngit commit -m \"feat: add new feature\"\ngh pr create --title \"Add feature\" --body \"Closes #<issue-number>\"\n```\n\n## Documentation\n\n### User Documentation\n\n- **[Quick Start](#quick-start)** - Get running in 5 minutes\n- **[shared/INSTALL.md](shared/INSTALL.md)** - Installation guide (615 lines)\n- **[shared/BUILD.md](shared/BUILD.md)** - Build system reference (489 lines)\n\n### Developer Documentation\n\n- **[CONTRIBUTING.md](CONTRIBUTING.md)** - How to contribute\n- **[.claude/shared/mojo-guidelines.md](.claude/shared/mojo-guidelines.md)** - Mojo syntax patterns\n- **[.claude/shared/mojo-anti-patterns.md](.claude/shared/mojo-anti-patterns.md)** - 64+ failure patterns to avoid\n- **[agents/hierarchy.md](agents/hierarchy.md)** - AI agent development system\n\n## Key Features\n\n- **Zero Python dependencies** for core ML operations (pure Mojo)\n- **Type-safe tensor operations** with compile-time shape checking\n- **SIMD optimization** for performance-critical operations\n- **Functional API design** (ExTensor, functional ops like conv2d, linear, relu)\n- **Manual backpropagation** for educational transparency\n- **Comprehensive build system** via Just (just build, just test, just train)\n\n## Contributing\n\nContributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n**Priority Areas:**\n\n- Complete backward passes for AlexNet, VGG-16, ResNet-18, etc. ([Issue #2576](https://github.com/mvillmow/ml-odyssey/issues/2576))\n- Fix broken getting-started examples ([Issue #2575](https://github.com/mvillmow/ml-odyssey/issues/2575))\n- Add CIFAR-10 dataset download script ([Issue #2577](https://github.com/mvillmow/ml-odyssey/issues/2577))\n- Implement autograd system\n- Add data augmentation module\n\n## License\n\nThis project is licensed under the MIT License - see [LICENSE](LICENSE) for details.\n\n## Acknowledgments\n\nBuilt with [Mojo](https://www.modular.com/mojo) from Modular. Inspired by classic papers from LeCun, Krizhevsky,\nSimonyan, He, and others.\n",
  "installCommand": "git clone https://github.com/mvillmow/ml-odyssey ~/.claude/skills/ml-odyssey",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}