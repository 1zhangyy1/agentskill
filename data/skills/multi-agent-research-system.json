{
  "id": "29c25bdd4fe0bcc5",
  "slug": "multi-agent-research-system",
  "name": "Multi Agent Research System",
  "description": "A Multi-Agent Research System using Claude Code Skills. it is inspired by Anthropic claude-agent-sdk-demos",
  "author": "ahmedibrahim085",
  "authorAvatar": "https://avatars.githubusercontent.com/u/1140606?v=4",
  "repoUrl": "https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill",
  "repoFullName": "ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill",
  "stars": 6,
  "forks": 1,
  "category": "coding",
  "categories": [
    "coding"
  ],
  "tags": [
    "agents",
    "anthropic-claude",
    "claude",
    "claude-code",
    "claude-skills",
    "multi-agent",
    "multi-agent-systems",
    "orchestration",
    "skills",
    "subagents"
  ],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-11-17T14:49:27Z",
  "updatedAt": "2025-12-22T12:59:34Z",
  "lastCommitAt": "2025-12-22T12:59:31Z",
  "source": "github-topic",
  "collectedAt": "2025-12-26T03:38:39.382Z",
  "authorUrl": "https://github.com/ahmedibrahim085",
  "license": "Apache-2.0",
  "readme": "# Claude Code Multi-Agent Research Skill\n\n**Orchestrated multi-agent research with architectural enforcement, parallel execution, and comprehensive audit trails.**\n\n[![Version](https://img.shields.io/badge/version-2.5.4-blue.svg)](https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill/releases)\n[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)\n[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n\n---\n\n## ğŸ‰ v2.5.2: Fresh Clone Auto-Detection Fix\n\nA **tri-skill platform** with smart routing, auto-indexing, and compound request detection:\n\n| Skill | Purpose | Agents |\n|-------|---------|--------|\n| **multi-agent-researcher** | Comprehensive topic investigation | researcher, report-writer |\n| **spec-workflow-orchestrator** | Planning from ideation to dev-ready specs | spec-analyst, spec-architect, spec-planner |\n| **semantic-search** | RAG-powered semantic code search (finds code by meaning, not keywords) | semantic-search-reader, semantic-search-indexer |\n\n**Key Features**:\n- **Auto-Reindex on File Changes** - Triggers on Write/Edit with 5-min cooldown (IndexFlatIP auto-fallback (full reindex only))\n- **Auto-Reindex on Session Start** - Smart change detection when Claude Code starts\n- **Comprehensive Decision Tracing** - Full visibility into reindex decisions (skip reasons, timing, errors)\n- **Smart Compound Detection** - When prompts trigger multiple skills, asks for clarification\n- **200+ Trigger Keywords** - Automatic skill routing via hook (3 skills)\n- **Quality Gates** - 85% threshold with max 3 iterations\n- **Token Savings** - Semantic search saves 5,000-10,000 tokens per task (~90% reduction)\n\n**Quick Examples**:\n```\nresearch quantum computing fundamentals     â†’ multi-agent-researcher\nplan a task management PWA with offline     â†’ spec-workflow-orchestrator\nfind authentication logic in the codebase   â†’ semantic-search\nresearch auth methods and build login page  â†’ asks which skill to use\n```\n\nSee [Planning Workflow](#planning-workflow-new-in-v220) and [CHANGELOG.md](CHANGELOG.md) for details.\n\n---\n\n## Table of Contents\n\n- [Quick Start](#quick-start)\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n  - [Post-Installation: CLAUDE.md Setup](#post-installation-claudemd-setup-options-2--3)\n  - [Fresh Clone Quick Start](#fresh-clone-quick-start)\n  - [Your First Research Query](#your-first-research-query)\n- [Why This Approach?](#why-this-approach)\n  - [vs. Direct Tools (WebSearch/WebFetch)](#vs-direct-tools-websearchwebfetch)\n  - [vs. MCP Servers](#vs-mcp-servers)\n  - [vs. Sequential Research](#vs-sequential-research)\n  - [Architectural Benefits](#architectural-benefits)\n  - [When NOT to Use](#when-not-to-use)\n- [How It Works](#how-it-works)\n  - [Phase 1: Decomposition](#phase-1-decomposition)\n  - [Phase 2: Parallel Research](#phase-2-parallel-research)\n  - [Phase 3: Synthesis](#phase-3-synthesis)\n  - [Phase 4: Delivery](#phase-4-delivery)\n- [Planning Workflow (New in v2.2.0)](#planning-workflow-new-in-v220)\n- [Semantic-Search Workflow (RAG System)](#semantic-search-workflow-rag-system)\n  - [What is RAG?](#what-is-rag)\n  - [Trigger Keywords](#trigger-keywords)\n  - [Agent Roles](#agent-roles)\n  - [RAG Workflow Details](#rag-workflow-details)\n  - [Features](#semantic-search-features)\n  - [Benefits Over Traditional Search](#benefits-over-traditional-search)\n- [Testing](#testing)\n- [Configuration](#configuration)\n  - [File Structure](#file-structure)\n  - [File & Directory Reference](#file--directory-reference)\n  - [Environment Variables](#environment-variables)\n  - [Advanced Setup](#advanced-setup)\n- [Architecture Deep Dive](#architecture-deep-dive)\n  - [Comparison to Reference SDK](#comparison-to-reference-sdk)\n  - [Enforcement Mechanisms](#enforcement-mechanisms)\n  - [Hooks Architecture](#hooks-architecture)\n  - [Session Logging](#session-logging)\n- [Troubleshooting](#troubleshooting)\n- [Inspiration & Credits](#inspiration--credits)\n- [Author & Acknowledgments](#author--acknowledgments)\n- [License](#license)\n- [References](#references)\n\n---\n\n## Quick Start\n\n### Prerequisites\n\n**Required for All Features**:\n- **Claude Code** installed ([Pro, Max, Team, or Enterprise tier](https://www.anthropic.com/news/skills))<sup>[[1]](#ref-1)</sup>\n- **Python 3.8+** with `python3` command available in PATH\n  - Verify: `python3 --version` (should show 3.8 or higher)\n- **Git** installed and available in PATH\n- **Bash shell** (for hooks and scripts)\n  - macOS/Linux: built-in\n  - Windows: Use WSL2 (Windows Subsystem for Linux)\n\n**Additional for Semantic-Search Skill** (optional):\n\nThe semantic-search skill implements **RAG (Retrieval-Augmented Generation)** - an AI technique that finds relevant code by understanding meaning rather than matching keywords. It converts code into vector embeddings and uses semantic similarity to retrieve contextually relevant chunks when you ask questions in natural language.\n\n- **~1.5GB disk space** for embedding model download\n  - Model: `google/embeddinggemma-300m` (768 dimensions)\n  - Downloads automatically on first use (10-30 minutes)\n  - Cached at: `~/.claude_code_search/models/`\n  - One-time download, reused across all projects\n\n### Platform Support\n\nâœ… **Fully Supported**:\n- **macOS** (Intel + Apple Silicon)\n  - **Apple Silicon**: Tested on M1/M2/M3 chips - semantic search works perfectly with MPS (Metal Performance Shaders) GPU acceleration\n  - Model loads on `mps:0` device for optimal performance\n- **Linux** (x86_64, ARM64)\n- **Windows** (via WSL)\n\n**Index Type**: Uses IndexFlatIP (FAISS) - simple, reliable, cross-platform compatible\n\n### Installation\n\nChoose one installation method based on your needs:\n\n**ğŸ“‹ Quick Decision Guide**:\n| Scenario | Installation Method |\n|----------|---------------------|\n| Add skills to **one existing project** | [Option 1: Project Skills](#option-1-project-skills-recommended) |\n| Make skills available to **all projects** | [Option 2: Personal Skills](#option-2-personal-skills) |\n| Explore this repository **standalone** | [Option 3: Standalone Usage](#option-3-standalone-usage) |\n\n---\n\n#### Option 1: Project Skills (Recommended)\n\n**Use Case**: Add multi-agent research, planning, and semantic search to an existing Claude Code project.\n\n**How It Works**: Claude Code auto-discovers skills in `.claude/skills/` directory. No manual configuration needed.\n\n```bash\n# Navigate to your existing project\ncd ~/my-existing-project\n\n# Clone into .claude/skills/ directory\nmkdir -p .claude/skills\ncd .claude/skills\ngit clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill.git\n```\n\n**Optional: Enable semantic-search skill**\n\n> **Note:** The multi-agent-researcher and spec-workflow-orchestrator skills work immediately. Only install if you want semantic code search.\n\n```bash\n# Clone Python library to standard location (one-time, 30 seconds)\ngit clone https://github.com/FarhanAliRaza/claude-context-local.git ~/.local/share/claude-context-local\n```\n\n**That's it!** Start Claude Code in your project:\n\n```bash\ncd ~/my-existing-project\nclaude\n```\n\nThe SessionStart hook will automatically initialize all skills.\n\n**Optional: Import Orchestration Rules**\n\nIf you want to use this project's orchestration rules (auto-skill-activation hooks) in your existing project:\n\n```markdown\n# Add to your project's .claude/CLAUDE.md\n@import .claude/skills/Claude-Multi-Agent-Research-System-Skill/.claude/CLAUDE.md\n```\n\nThis imports the trigger keyword system that auto-activates skills based on your requests (e.g., \"research X\" â†’ multi-agent-researcher, \"plan feature Y\" â†’ spec-workflow-orchestrator).\n\n---\n\n#### Option 2: Personal Skills\n\n**Use Case**: Make skills available to **all** your Claude Code projects (system-wide installation).\n\n**How It Works**: Claude Code auto-discovers skills in `~/.claude/skills/` and makes them available to every project.\n\n```bash\n# Clone into personal skills directory\nmkdir -p ~/.claude/skills\ncd ~/.claude/skills\ngit clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill.git\n\n# Optional: Enable semantic-search\ngit clone https://github.com/FarhanAliRaza/claude-context-local.git ~/.local/share/claude-context-local\n```\n\n**That's it!** Skills are now available in **every** Claude Code project:\n\n```bash\ncd ~/any-project\nclaude\n# Skills automatically available\n```\n\n**Note**: Personal skills don't include project-specific hooks or CLAUDE.md rules. You'll need to manually invoke skills using the Skill tool or add @import statements to individual projects.\n\n---\n\n#### Option 3: Standalone Usage\n\n**Use Case**: Explore this repository as a dedicated research/planning workspace.\n\n```bash\ngit clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill.git\ncd Claude-Multi-Agent-Research-System-Skill\n\n# Optional: Enable semantic-search\ngit clone https://github.com/FarhanAliRaza/claude-context-local.git ~/.local/share/claude-context-local\n\n# Start Claude Code\nclaude\n```\n\n**Full Experience**: This option includes:\n- All 3 skills (multi-agent-researcher, spec-workflow-orchestrator, semantic-search)\n- Auto-activation hooks (trigger keywords automatically invoke skills)\n- Pre-configured directory structure\n- Session logging and state management\n- 4 custom slash commands (`/research-topic`, `/plan-feature`, `/project-status`, `/verify-structure`)\n\n---\n\n#### Common Setup (All Options)\n\n**Automatic Initialization**: The SessionStart hook runs on every `claude` command and:\n- Auto-reindexes semantic search (smart change detection, 60-min cooldown)\n- Creates required directories (`files/research_notes/`, `files/reports/`, `logs/`)\n- Initializes session logging\n- Checks prerequisites and displays setup status\n\n**No Manual Configuration**: Hooks are pre-configured in `.claude/settings.json` and work out-of-the-box.\n\n**First-Time Semantic Search**: The embedding model (~1.2GB) downloads automatically on first use (10-30 minutes). Subsequent uses are instant. Model cached at `~/.claude_code_search/models/`.\n\n**Semantic Search Details**:\n- Imports Python modules from claude-context-local via `sys.path.insert()`\n- No virtual environment, no pip install, no `uv` needed\n- Merkle tree change detection for smart reindexing\n- Multi-language code chunking (15+ languages)\n- Embedding generation (sentence-transformers, FAISS)\n\n**License Note**: claude-context-local is GPL-3.0. Our project imports it via PYTHONPATH (dynamic linking), preserving our Apache 2.0 license. See `docs/architecture/MCP-DEPENDENCY-STRATEGY.md` for details.\n\n**Important**: Do not duplicate hooks in `settings.local.json` to avoid duplicate hook executions.\n\n---\n\n#### Post-Installation: CLAUDE.md Setup (Options 2 & 3)\n\n**For Option 2 (Personal Skills)** and when integrating skills into existing projects, add the following to your project's `.claude/CLAUDE.md` to help Claude understand the available skills:\n\n```markdown\n## Multi-Agent Research System Skills\n\nThis project has access to 3 specialized skills with hook-based auto-activation:\n\n| Skill | Purpose | Trigger |\n|-------|---------|---------|\n| multi-agent-researcher | Research requiring 2+ sources, synthesis | \"research...\", \"investigate...\" |\n| spec-workflow-orchestrator | Feature planning, specs, ADRs | \"plan...\", \"design...\", \"spec...\" |\n| semantic-search | Find code by meaning, not keywords | \"find...\", \"where is...\", \"how does...\" |\n\n**Usage**: Skills auto-activate via hooks when trigger keywords detected.\nManual invocation: Use `/research-topic`, `/plan-feature`, or `/semantic-search`.\n\n**Documentation**: See skill SKILL.md files for detailed workflows.\n```\n\n**Automated Setup**: Run `python3 setup.py --repair` to automatically add skill instructions to your project's CLAUDE.md.\n\n---\n\n### Fresh Clone Quick Start\n\n**If you already have semantic-search prerequisites from another project**:\n\nThe semantic-search skill uses **global shared components** (Python library + embedding model). If you've used this skill in any project before, new projects automatically detect and reuse these components.\n\n**Expected Flow**:\n```bash\n$ git clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill.git\n$ cd Claude-Multi-Agent-Research-System-Skill\n$ claude\n\n# Output (automatic):\nğŸ” Detecting semantic-search prerequisites...\nâœ“ Semantic-search prerequisites found (using global components)\nğŸ”„ Indexing project in background...\nğŸ“ Session logs: logs/session_...\n\n# You can start working immediately!\n# Index completes in background (~3-10 min)\n```\n\n**What Gets Auto-Detected**:\n| Component | Location | Size |\n|-----------|----------|------|\n| Python library | `~/.local/share/claude-context-local/` | ~500KB |\n| Embedding model | `~/.claude_code_search/models/` | ~1.2GB |\n| Project index | `~/.claude_code_search/projects/{project}_{hash}/` | Per-project |\n\n**If Auto-Detection Fails** (verify-setup diagnostic):\n```bash\n# Quick diagnostic (5 checks, instant)\n.claude/skills/semantic-search/scripts/verify-setup\n\n# Full prerequisite check (25 checks, ~10 sec)\n.claude/skills/semantic-search/scripts/check-prerequisites\n```\n\n### What Makes This Different?\n\n**Quick Answer**: This project uses **orchestrated multi-agent research** instead of single-query web search.\n\n**Direct Approach** (typing \"tell me about quantum computing\"):\n```\nYou â†’ Claude â†’ 1-2 WebSearch calls â†’ Summary\nTime: 30-60 seconds\nDepth: Limited to what fits in single response\nSources: 2-3 quick sources\n```\n\n**This Skill** (typing \"research quantum computing\"):\n```\nYou â†’ Orchestrator â†’ Decomposes into 3-4 subtopics\n                  â†’ Spawns 4 researcher agents (parallel)\n                  â†’ Each does multi-source research\n                  â†’ Report-writer synthesizes findings\n                  â†’ Comprehensive cross-referenced report\n\nTime: 5-8 minutes\nDepth: Multi-source, peer-reviewed quality\nSources: 8-15 authoritative sources per topic\nAudit Trail: Session logs + research notes + final report\n```\n\n**When to Use This Skill**:\n| Scenario | Use This Skill | Use Direct Approach |\n|----------|----------------|---------------------|\n| In-depth research (2+ sources needed) | âœ… Yes | âŒ Too shallow |\n| Comprehensive coverage important | âœ… Yes | âŒ Incomplete |\n| Need audit trail for compliance | âœ… Yes | âŒ No logs |\n| Quick factual question | âŒ Overkill | âœ… Yes |\n| Simple documentation lookup | âŒ Too slow | âœ… Yes |\n\n**Example Comparison**:\n\n```\nDirect: \"What is quantum entanglement?\"\nâ†’ 45 seconds\nâ†’ 1 paragraph summary\nâ†’ 2 sources\n\nThis Skill: \"research quantum entanglement\"\nâ†’ 6 minutes\nâ†’ 4 research notes (foundations, experiments, applications, implications)\nâ†’ 1 synthesis report cross-referencing all findings\nâ†’ 12 authoritative sources\nâ†’ Complete session logs\n```\n\n**Bottom Line**: Use this when you need comprehensive, well-researched, auditable findings. Use direct questions for quick factual lookups.\n\n### Your First Research Query\n\nTry this example:\n```\nresearch quantum computing fundamentals\n```\n\n**What Happens**:\n1. **UserPromptSubmit hook** detects \"research\" keyword â†’ activates multi-agent-researcher skill\n2. **Orchestrator** decomposes topic into 3-4 focused subtopics\n3. **Four researcher agents** spawn in parallel (each conducts web searches)\n4. **Each researcher** writes findings to `files/research_notes/`\n5. **Report-writer agent** synthesizes all findings into comprehensive report\n6. **Orchestrator** delivers final summary to you\n\n**Expected Timing**:\n\n| Stage | First Run | Subsequent Runs |\n|-------|-----------|-----------------|\n| **Setup** (directory creation, session init) | ~2-3 seconds | ~1 second |\n| **Research** (4 agents in parallel) | 3-5 minutes | 3-5 minutes |\n| **Synthesis** (report-writer) | 1-2 minutes | 1-2 minutes |\n| **Total** | **5-8 minutes** | **4-6 minutes** |\n\n**First-Time Setup Messages**:\n\nOn your very first run, you'll see:\n```\nğŸ”§ First-time setup detected\nâœ… Created settings.local.json from template\nâœ… Created directories: files/research_notes/, files/reports/, logs/\nğŸ“ Session logs initialized: logs/session_20251216_150000_*\n```\n\n**Expected Output**:\n```\nğŸ“ Session logs initialized: logs/session_YYYYMMDD_HHMMSS_{transcript.txt,tool_calls.jsonl,state.json}\n\n# Research Complete: Quantum Computing Fundamentals\n\nComprehensive research completed with 3 specialized researchers.\n\n## Key Findings\n1. [Finding from researcher 1]\n2. [Finding from researcher 2]\n3. [Finding from researcher 3]\n\n## Files Generated\n**Research Notes**: `files/research_notes/`\n- quantum-computing-fundamentals-basics_YYYYMMDD-HHMMSS.md\n- quantum-computing-fundamentals-hardware_YYYYMMDD-HHMMSS.md\n- quantum-computing-fundamentals-algorithms_YYYYMMDD-HHMMSS.md\n\n**Final Report**: `files/reports/quantum-computing-fundamentals_YYYYMMDD-HHMMSS.md`\n```\n\n**Where to Find Results**:\n- **Individual research notes**: `files/research_notes/{subtopic}_YYYYMMDD-HHMMSS.md`\n- **Final synthesis**: `files/reports/{topic}_YYYYMMDD-HHMMSS.md`\n- **Session logs**: `logs/session_YYYYMMDD_HHMMSS_{transcript.txt,tool_calls.jsonl,state.json}`\n\n**What If Something Fails?**:\n\n1. **Import errors on startup**:\n   ```bash\n   python3 setup.py --repair\n   ```\n\n2. **Research produces no results**:\n   - Check API key: `echo $ANTHROPIC_API_KEY`\n   - Review logs: `cat logs/session_*_transcript.txt | tail -50`\n   - See [Troubleshooting](#troubleshooting) section\n\n3. **Takes longer than expected**:\n   - Normal: Research quality > speed\n   - Can interrupt with `Ctrl+C` and use partial results\n   - Check `files/research_notes/` for individual findings\n\n---\n\n## Why This Approach?\n\n### vs. Direct Tools (WebSearch/WebFetch)\n\n**Direct approach**:\n```\nUser: \"Tell me about quantum computing\"\nâ†’ Claude does 1-2 WebSearch calls\nâ†’ Returns summary from top results\nâ†’ Limited depth, single perspective\n```\n\n**This orchestrated approach**:\n```\nUser: \"Research quantum computing\"\nâ†’ Decomposes into 3-4 subtopics (basics, hardware, algorithms, applications)\nâ†’ Spawns 3-4 researcher agents in parallel\nâ†’ Each agent conducts focused, multi-source research\nâ†’ Report-writer synthesizes comprehensive findings\nâ†’ Cross-referenced, authoritative sources\n```\n\n**When direct tools are sufficient**: Single factual questions (\"What is X?\"), quick documentation lookups, specific URL fetches.\n\n### vs. MCP Servers\n\nThe **Model Context Protocol (MCP)**<sup>[[2]](#ref-2)</sup> is Anthropic's open standard for connecting AI systems to data sources through servers.\n\n**MCP Approach** (agent as MCP server):\n- Each agent is an **MCP server** providing tools\n- Claude Code calls MCP tools to interact with agents\n- âŒ **No enforced workflow** - Claude can skip decomposition or synthesis\n- âŒ **No architectural constraints** - relies entirely on prompts\n- âŒ **Agents don't coordinate** - just isolated tool calls\n- âŒ **No guaranteed synthesis phase**\n\n**This Orchestrated Approach**:\n- Agents are **Task subprocesses**<sup>[[3]](#ref-3)</sup> with defined roles (researcher, report-writer)\n- Orchestrator **enforces workflow phases** via `allowed-tools` constraint<sup>[[4]](#ref-4)</sup>\n- âœ… **Architectural enforcement** (~95% reliability)\n- âœ… **Parallel execution** - spawn all researchers simultaneously\n- âœ… **Mandatory synthesis** - orchestrator physically cannot write reports (lacks Write tool)\n- âœ… **Quality gates** - verify all phases complete before delivery\n\n**Example**:\n```\nMCP Approach:\nUser: \"research quantum computing\"\nâ†’ Claude calls researcher-mcp-tool (maybe)\nâ†’ Claude writes synthesis itself (no delegation enforcement)\nâ†’ May skip decomposition or parallel execution\nâ†’ Workflow depends on prompt compliance\n\nThis Approach:\nUser: \"research quantum computing\"\nâ†’ Orchestrator MUST decompose (Phase 1)\nâ†’ Orchestrator MUST spawn researchers in parallel (Phase 2)\nâ†’ Orchestrator CANNOT write synthesis - lacks Write tool (architectural constraint)\nâ†’ Orchestrator MUST delegate to report-writer agent (Phase 3)\nâ†’ Workflow enforced by architecture, not prompts\n```\n\n### vs. Sequential Research\n\n**Sequential Approach** (original SDK pattern<sup>[[5]](#ref-5)</sup>):\n- Research subtopics one-by-one\n- Total time: N Ã— (research time per subtopic)\n- Example: 3 subtopics Ã— 10 min each = **30 minutes**\n\n**Parallel Orchestration** (this project):\n- Research all subtopics simultaneously (Claude Code supports up to 10 parallel tasks<sup>[[6]](#ref-6)</sup>)\n- Total time: max(research times) + synthesis time\n- Example: max(10, 12, 8 min) + 3 min = **15 minutes**\n- **~30-50% faster** for typical 3-4 subtopic research<sup>[[7]](#ref-7)</sup>\n\n**Additional benefits**:\n- **Reliability**: If one researcher fails, others complete; orchestrator can retry failed subtopics\n- **Isolation**: Independent researchers can't block each other\n- **Scalability**: Performance scales with subtopic count\n\n### Architectural Benefits\n\n#### 1. Reliability Through Constraints\n\n```yaml\n# From SKILL.md frontmatter:\nallowed-tools: Task, Read, Glob, TodoWrite\n# Note: Write is deliberately excluded\n```\n\n- Orchestrator **physically cannot** bypass report-writer agent\n- Prompts can be ignored; architecture cannot\n- ~95% enforcement reliability (vs. ~20-50% for prompt-based approaches)<sup>[[4]](#ref-4)</sup>\n\n#### 2. Audit Trail & Compliance\n\nEvery tool call is logged to:\n- `transcript.txt` - human-readable session log\n- `tool_calls.jsonl` - structured JSON for analysis\n\n**Enables**:\n- Verify workflow compliance after-the-fact\n- Debug agent behavior\n- Compliance requirements (audit who did what, when)\n\n#### 3. Quality Gates\n\nBefore synthesis:\n- âœ… Verify all research notes exist\n- âœ… Detect violations (e.g., orchestrator writing reports)\n- âœ… Fail-fast on incomplete research\n\n#### 4. Scalability\n\n- Parallel execution scales with subtopic count\n- Independent researchers reduce single points of failure\n- Synthesis happens once after all research completes\n\n### When NOT to Use\n\nThis architecture is **overkill** for:\n\n- âŒ Single factual questions (\"What is the capital of France?\")\n- âŒ Quick lookups (\"Latest version of Python?\")\n- âŒ Code-related tasks (\"Debug this function\", \"Write a script\")\n- âŒ Decision evaluation (\"Should I use React or Vue?\")\n\n**Use direct tools** (WebSearch, WebFetch) for these instead.\n\n**Use this architecture when**:\n\n- âœ… Multi-source research needed (2+ authoritative sources)\n- âœ… Synthesis across perspectives required\n- âœ… Comprehensive coverage important\n- âœ… Audit trail needed for compliance\n- âœ… Quality gates required\n\n---\n\n## How It Works\n\nThe orchestrated multi-agent workflow has four enforced phases:\n\n### Phase 1: Decomposition\n\n**Orchestrator**:\n1. Analyzes user's research question\n2. Breaks topic into 2-4 focused subtopics that are:\n   - Mutually exclusive (minimal overlap)\n   - Collectively exhaustive (cover whole topic)\n   - Independently researchable\n\n**Example**:\n```\nQuery: \"Research quantum computing\"\nâ†’ Subtopics:\n  1. Theoretical foundations (qubits, superposition, entanglement)\n  2. Hardware implementations (superconducting, ion trap, topological)\n  3. Algorithms & applications (Shor's, Grover's, VQE, QAOA)\n```\n\n### Phase 2: Parallel Research\n\n**Orchestrator spawns all researchers simultaneously**:\n\n```python\n# Conceptual (actual implementation uses Task tool)\nspawn_parallel([\n    researcher(topic=\"Theoretical foundations\", context=\"quantum computing\"),\n    researcher(topic=\"Hardware implementations\", context=\"quantum computing\"),\n    researcher(topic=\"Algorithms & applications\", context=\"quantum computing\")\n])\n```\n\nEach researcher:\n- Conducts web research (WebSearch tool)\n- Gathers authoritative sources\n- Extracts key findings\n- Saves results to `files/research_notes/{subtopic-slug}.md`\n\n**Parallelism**: Claude Code supports up to 10 concurrent tasks<sup>[[6]](#ref-6)</sup>; excess tasks are queued.\n\n### Phase 3: Synthesis\n\n**âš ï¸ Architectural Enforcement Active**\n\nThe orchestrator **does not have Write tool access** (see `allowed-tools` in SKILL.md). This architectural constraint **physically prevents** the orchestrator from writing synthesis reports.\n\n**Enforced workflow**:\n1. Orchestrator verifies all research notes exist (Glob tool)\n2. Orchestrator **MUST** spawn report-writer agent (Task tool)\n3. Report-writer reads ALL research notes (Read tool)\n4. Report-writer synthesizes findings into comprehensive report\n5. Report-writer writes to `files/reports/{topic}_{timestamp}.md` (Write tool)\n\n**Cannot be bypassed**: Attempting to write reports from orchestrator results in tool permission error.\n\n### Phase 4: Delivery\n\nOrchestrator:\n1. Reads final report\n2. Creates user-facing summary with:\n   - Key findings (3-5 bullet points)\n   - Research scope (subtopics investigated)\n   - File paths (research notes + final report)\n3. Delivers to user\n\n---\n\n## Planning Workflow (New in v2.2.0)\n\nThe **spec-workflow-orchestrator** skill provides comprehensive project planning from ideation to development-ready specifications.\n\n### Trigger Keywords (90+)\n\n- \"plan\", \"design\", \"architect\", \"build\", \"create\", \"implement\"\n- \"specs\", \"requirements\", \"features\", \"PRD\", \"ADR\"\n- \"what should we build\", \"how should we structure\"\n\n### Workflow\n\n```\nUser: \"build a task tracker app\"\n    â†“\n1. ANALYZE â†’ spec-analyst gathers requirements\n    â†’ User stories with acceptance criteria\n    â†’ Functional/non-functional requirements\n    â†“\n2. ARCHITECT â†’ spec-architect designs system\n    â†’ Component architecture\n    â†’ Technology recommendations\n    â†’ Architecture Decision Records (ADRs)\n    â†“\n3. PLAN â†’ spec-planner breaks down tasks\n    â†’ Implementation tasks with dependencies\n    â†’ Complexity estimates\n    â†’ Suggested implementation order\n    â†“\n4. VALIDATE â†’ Quality gate (85% threshold)\n```\n\n### Features\n\n- **Per-Project Structure**: `docs/projects/{project-slug}/`\n- **Interactive Decision**: Detects existing projects â†’ New/Refine/Archive options\n- **Archive System**: Timestamped backups with integrity verification\n- **Quality Gates**: 85% threshold with up to 3 iterations\n- **State Management**: JSON-based workflow persistence\n\n### Outputs\n\n| File | Content |\n|------|---------|\n| `docs/projects/{slug}/requirements.md` | User stories, acceptance criteria |\n| `docs/projects/{slug}/architecture.md` | System design, components |\n| `docs/projects/{slug}/tasks.md` | Implementation tasks with dependencies |\n| `docs/adrs/*.md` | Architecture Decision Records |\n\n### Production Utilities\n\n```bash\n# Archive a project\n.claude/utils/archive_project.sh task-tracker-pwa\n\n# List archives\n.claude/utils/list_archives.sh task-tracker-pwa\n\n# Restore from archive\n.claude/utils/restore_archive.sh task-tracker-pwa 20251120-103602\n\n# Manage workflow state\n.claude/utils/workflow_state.sh set \"task-tracker-pwa\" \"refinement\" \"Add offline\"\n.claude/utils/workflow_state.sh get \"mode\"\n.claude/utils/workflow_state.sh show\n.claude/utils/workflow_state.sh clear\n```\n\nSee [PRODUCTION_READY_SUMMARY.md](PRODUCTION_READY_SUMMARY.md) for detailed implementation status.\n\n---\n\n## Semantic-Search Workflow (RAG System)\n\n### What is RAG?\n\n**RAG (Retrieval-Augmented Generation)** combines two AI capabilities to provide intelligent, context-aware responses:\n\n1. **Retrieval**: Search a knowledge base for relevant information using semantic similarity\n   - Converts code into vector embeddings (numerical representations)\n   - Finds semantically similar content based on meaning, not just keywords\n   - Uses FAISS (Facebook AI Similarity Search) for efficient vector search\n\n2. **Augmentation**: Provides retrieved context to the language model for accurate responses\n   - LLM receives: Your query + Retrieved code chunks\n   - Result: Project-specific answers grounded in actual code\n   - No hallucination - answers based on real codebase content\n\n**Why RAG for Code Search?**\n\nTraditional keyword search fails when code uses different terminology:\n\n- Search `\"authentication\"` â†’ Misses `signin()`, `verifyUser()`, `auth_middleware`\n- Search `\"database\"` â†’ Misses `Repository`, `ORM`, `queryBuilder`, `DataSource`\n- Search `\"error handling\"` â†’ Misses `try/catch`, `Result<T>`, `Exception`, `panic`\n\n**RAG understands meaning**, not just words:\n\n- Query: `\"find authentication logic\"`\n- Retrieves: Login functions, auth middleware, token validation, session handling\n- Even if they use different terminology like `signin`, `verify`, `authorize`\n\n**Real Example**:\n\n```\nTraditional grep: \"authentication\"  â†’ 12 matches, 8 false positives (documentation, comments)\nSemantic RAG:     \"auth logic\"     â†’ 15 semantically relevant code chunks, 0 false positives\n```\n\n### Trigger Keywords\n\nSemantic-search is automatically activated when your prompt contains these patterns (37+ keywords):\n\n**Search Operations** (18 keywords):\n```\n\"search for\", \"find\", \"locate\", \"show me\", \"where is\"\n\"look for\", \"get me\", \"retrieve\", \"fetch\", \"discover\"\n\"search code\", \"code search\", \"find code\"\n\"show implementation\", \"find implementation\"\n\"what code\", \"which files\"\n```\n\n**Code Discovery** (10 keywords):\n```\n\"how does\", \"what does\", \"explain\"\n\"similar to\", \"like this code\", \"resembles\"\n\"examples of\", \"patterns for\"\n\"find similar\", \"similar files\"\n```\n\n**Index Operations** (9 keywords):\n```\n\"reindex\", \"index\", \"rebuild index\"\n\"update index\", \"incremental reindex\"\n\"index status\", \"check index\"\n\"what's indexed\", \"indexed projects\"\n```\n\n**Examples**:\n```bash\nâœ… \"search for authentication logic\"        â†’ semantic-search-reader\nâœ… \"find database query patterns\"           â†’ semantic-search-reader\nâœ… \"reindex the project\"                    â†’ semantic-search-indexer\nâœ… \"show me error handling code\"            â†’ semantic-search-reader\nâœ… \"find similar implementations to auth.py\" â†’ semantic-search-reader\nâœ… \"what's the index status?\"               â†’ semantic-search-indexer\nâœ… \"how does the login system work\"         â†’ semantic-search-reader\n```\n\n**Note**: Full trigger list in `.claude/skills/skill-rules.json` (semantic-search section, 69 keywords + 27 patterns)\n\n### Agent Roles\n\nThe semantic-search skill uses two specialized agents with distinct responsibilities:\n\n| Agent | Operations | Triggers | Prerequisites | Output |\n|-------|-----------|----------|---------------|--------|\n| **semantic-search-indexer** | Build/update vector database | `index`, `reindex`, `status`, `incremental-reindex` | None (creates index if missing) | FAISS index, cache files, state tracking |\n| **semantic-search-reader** | Search and retrieve code | `search`, `find-similar`, `list-projects` | Project must be indexed (auto-triggers indexer if needed) | Ranked code chunks with relevance scores |\n\n**Indexer Operations**:\n- **Full reindex**: Complete rebuild of vector database from scratch\n- **Incremental reindex**: Smart updates using Merkle tree change detection (only re-embeds changed files)\n- **Status**: Report index state, bloat percentage, last update timestamp\n\n**Reader Operations**:\n- **Search**: Natural language code search (`\"find authentication logic\"`)\n- **Find-similar**: Find code similar to a specific file (`\"similar to auth.py\"`)\n- **List-projects**: Show all indexed projects\n\n**Auto-Triggering**:\n- **Session start**: Indexer runs if changes detected since last session\n- **File Write/Edit**: Indexer triggers after 5-minute cooldown\n- **Search without index**: Reader auto-triggers indexer if project not indexed\n\n### RAG Workflow Details\n\nThe RAG system operates in two main modes: **Index Building** (offline, happens once or on changes) and **Search & Retrieval** (online, happens on each query).\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    SEMANTIC-SEARCH RAG WORKFLOW                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nPHASE 1: INDEX BUILDING (Offline - Once per project, updates on changes)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Code Files  â”‚â”€â”€â”€â”€â”€â–¶â”‚  Chunking    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Embeddings   â”‚\nâ”‚ (.py, .js,  â”‚      â”‚ (functions,  â”‚      â”‚ (768-dim      â”‚\nâ”‚  .ts, etc)  â”‚      â”‚  classes,    â”‚      â”‚  vectors)     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  blocks)     â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n                     15+ languages                 â”‚\n                                                    â–¼\n                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                                            â”‚ FAISS Index   â”‚\n                                            â”‚ (IndexFlatIP) â”‚\n                                            â”‚ + Cache       â”‚\n                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                            Merkle tree tracks\n                                            changes for smart\n                                            incremental updates\n\nPHASE 2-4: SEARCH & RETRIEVAL (Online - Every query)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  User Query     â”‚â”€â”€â”€â”€â”€â–¶â”‚ Query        â”‚â”€â”€â”€â”€â”€â–¶â”‚  Vector    â”‚\nâ”‚  \"find auth     â”‚      â”‚ Embedding    â”‚      â”‚  Search    â”‚\nâ”‚   logic\"        â”‚      â”‚ (same model) â”‚      â”‚  (cosine   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  similarityâ”‚\n                                                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n                                                       â”‚\n                                                       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Claude +       â”‚â—€â”€â”€â”€â”€â”€â”‚  Retrieved   â”‚â—€â”€â”€â”€â”€â”€â”‚  Ranked    â”‚\nâ”‚  Context        â”‚      â”‚  Chunks      â”‚      â”‚  Results   â”‚\nâ”‚  (Augmented     â”‚      â”‚  (with file  â”‚      â”‚  (Top-k    â”‚\nâ”‚   Response)     â”‚      â”‚   paths)     â”‚      â”‚   similar) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n#### Phase 1: Index Building (Offline)\n\n**When it runs**: First use, file changes (5-min cooldown), session start\n\n**Process**:\n1. **Code Chunking**: Splits code files into meaningful chunks\n   - Language-aware parsing (15+ languages: Python, JavaScript, TypeScript, etc.)\n   - Chunks: Functions, classes, methods, blocks\n   - Preserves context: Includes docstrings, comments, signatures\n\n2. **Embedding Generation**: Converts chunks into 768-dimensional vectors\n   - Model: `google/embeddinggemma-300m` (1.2GB, one-time download)\n   - Each chunk â†’ 768 numbers representing semantic meaning\n   - Similar code produces similar vectors\n\n3. **Vector Storage**: Builds FAISS index for fast similarity search\n   - IndexFlatIP: Simple, reliable, cross-platform\n   - Stores vectors + metadata (file path, line numbers)\n   - Enables sub-second search across thousands of files\n\n4. **Smart Caching**: Merkle tree tracks file changes\n   - Only re-embeds changed files (incremental reindex)\n   - Embedding cache: 3.2x speedup on subsequent reindexes\n   - State tracking: Last update timestamp, bloat percentage\n\n**Output**: `~/.claude_code_search/projects/{project}/index.faiss` + metadata\n\n#### Phase 2: Query Processing (Online)\n\n**When it runs**: Every search query\n\n**Process**:\n1. **Trigger Detection**: Hook identifies semantic-search intent\n   - User: `\"find authentication logic\"`\n   - Hook: Detects \"find\" keyword â†’ Activates semantic-search skill\n\n2. **Agent Selection**: Routes to semantic-search-reader\n   - Checks if project is indexed\n   - If not indexed: Auto-triggers semantic-search-indexer first\n\n3. **Query Embedding**: Converts natural language query to vector\n   - Same model as index building (`embeddinggemma-300m`)\n   - Query: `\"find authentication logic\"` â†’ 768-dim vector\n   - Vector represents semantic meaning of the query\n\n#### Phase 3: Retrieval\n\n**Process**:\n1. **Vector Similarity Search**: Compares query vector with all code vectors\n   - FAISS performs cosine similarity: `similarity = dot(query_vec, code_vec) / (||query_vec|| * ||code_vec||)`\n   - Finds Top-k most similar chunks (default k=5, configurable)\n   - Sub-second search even for large codebases (10,000+ files)\n\n2. **Ranking**: Orders results by relevance score\n   - Higher similarity = more relevant\n   - Score range: 0.0 (unrelated) to 1.0 (identical)\n   - Returns top-k results ranked by score\n\n3. **Context Extraction**: Retrieves full chunk content with metadata\n   - File path: `src/auth/login.py`\n   - Line numbers: Lines 45-67\n   - Code content: Full function/class with context\n   - Relevance score: 0.87\n\n**Output**: Ranked list of code chunks with file locations\n\n#### Phase 4: Augmentation\n\n**Process**:\n1. **Context Assembly**: Combines query + retrieved chunks\n   - Original query: `\"find authentication logic\"`\n   - Retrieved: 15 code chunks from auth.py, middleware.ts, tokens.py\n   - Format: File paths + code snippets + relevance scores\n\n2. **LLM Augmentation**: Claude receives query + context\n   - Claude sees: User question + Relevant code from codebase\n   - No guessing: Answers grounded in actual project code\n   - No hallucination: If code doesn't exist, Claude says so\n\n3. **Response Generation**: Claude provides accurate, project-specific answer\n   - Cites specific files and line numbers\n   - Explains how the code works\n   - Can suggest improvements or answer follow-up questions\n\n**Example Output**:\n```\nClaude: I found your authentication logic across 3 files:\n\n1. src/auth/login.py:45-67 - Main login function with JWT generation\n2. src/middleware/auth.ts:12-34 - Express middleware for token validation\n3. src/utils/tokens.py:78-95 - Token refresh and expiration handling\n\nThe login flow uses JWT tokens with 24-hour expiration...\n```\n\n### Semantic-Search Features\n\n1. **Automatic Index Management**\n   - **Auto-reindex on file changes**: Triggers after Write/Edit operations (5-minute cooldown)\n   - **Auto-reindex on session start**: Smart change detection when Claude Code starts\n   - **Incremental updates**: Only re-embeds changed files using Merkle tree tracking\n   - **No manual intervention**: Index stays current automatically\n\n2. **Smart Caching & Performance**\n   - **Embedding cache**: Stores generated embeddings for 3.2x speedup on reindexes\n   - **Sub-second search**: FAISS enables fast similarity search even for large codebases\n   - **GPU acceleration**: Uses MPS (Metal Performance Shaders) on Apple Silicon for 2-3x faster embedding\n   - **Efficient storage**: Typical index size 5-50MB per project\n\n3. **Cross-Platform Compatibility**\n   - **IndexFlatIP**: Simple, reliable FAISS index type that works everywhere\n   - **Tested platforms**: macOS (Intel + Apple Silicon), Linux (x86_64, ARM64), Windows WSL\n   - **No special dependencies**: Works with standard Python packages\n\n4. **Multi-Language Support**\n   - **15+ programming languages**: Python, JavaScript, TypeScript, Java, C++, Go, Rust, etc.\n   - **Language-aware chunking**: Understands code structure (functions, classes, methods)\n   - **Context preservation**: Includes docstrings, comments, type hints\n\n5. **Large Codebase Support**\n   - **Scalable**: Handles projects with 10,000+ files\n   - **Memory efficient**: Doesn't load entire codebase into memory\n   - **Chunked processing**: Processes files incrementally\n\n6. **Comprehensive Decision Tracing**\n   - **Reindex decisions**: Full visibility into skip reasons, timing, errors\n   - **Status reporting**: Index state, bloat percentage, last update timestamp\n   - **Debug information**: Detailed logs for troubleshooting\n\n### Benefits Over Traditional Search\n\n1. **Semantic Understanding (Not Just Keywords)**\n\n   **Traditional grep**:\n   ```bash\n   $ grep -r \"authentication\" .\n   # Finds: 12 matches\n   # Misses: signin(), verifyUser(), auth_middleware, validateToken()\n   # False positives: Comments, documentation, variable names\n   ```\n\n   **Semantic RAG**:\n   ```bash\n   You: \"find authentication logic\"\n   # Finds: All auth-related code regardless of terminology\n   # Includes: login(), signin(), authenticate(), verifyUser(),\n   #          auth_middleware, validateToken(), checkSession()\n   # Zero false positives: Only actual implementation code\n   ```\n\n2. **Massive Token Savings**\n   - **Grep exploration**: 15+ attempts, 26 file reads, 5,000-10,000 tokens\n   - **Semantic search**: 1 query, 2 file reads, 500-1,000 tokens\n   - **Savings**: ~90% token reduction for code discovery tasks\n\n3. **No False Positives**\n   - Traditional search: `\"error\"` matches comments, strings, logs, tests\n   - RAG search: `\"error handling patterns\"` retrieves only actual error handling code\n   - Result: Higher signal-to-noise ratio, less time reviewing irrelevant results\n\n4. **Natural Language Queries**\n   - Don't need to know exact function/variable names\n   - Ask questions: `\"how does login work\"`, `\"where are API calls made\"`\n   - RAG understands intent and finds relevant code\n\n5. **Context-Aware Results**\n   - Results ranked by semantic relevance (not just keyword count)\n   - Includes file paths and line numbers for easy navigation\n   - Claude can explain, summarize, or suggest improvements based on retrieved code\n\n---\n\n## Testing\n\nThe project includes a comprehensive test suite following a 3-layer architecture for AI agent systems:\n\n| Layer | Tests | Purpose |\n|-------|-------|---------|\n| Infrastructure | 158 | Hook behavior (148), utilities (10) |\n| Behavior | 22 | Agent structure, file validation |\n| Integration | Manual | Deliverable format, ADR compliance (require skill output) |\n| Quality | Manual | Human evaluation of content quality |\n\n### Running Tests\n\n```bash\n# Layer 1: Infrastructure tests (tests/common/)\npython3 tests/common/e2e_hook_test.py\n./tests/common/test_production_implementation.sh\n\n# Layer 2: Structural validation\n./tests/common/test_agent_structure.sh\n./tests/spec-workflow/test_deliverable_structure.sh integration-test-hello-world\npython3 tests/spec-workflow/test_adr_format.py integration-test-hello-world\n\n# Integration: API-based E2E (requires ANTHROPIC_API_KEY)\npython3 tests/spec-workflow/test_skill_integration.py --dry-run   # Without API\npython3 tests/spec-workflow/test_skill_integration.py --quick     # With API\n```\n\n### Test Architecture\n\nSee [tests/TEST_ARCHITECTURE.md](tests/TEST_ARCHITECTURE.md) for detailed documentation on:\n- Why AI agents require different testing approaches\n- What can vs cannot be automated\n- Manual test evidence documentation\n\n**Total: 180 automated tests** (run without user input)\n\n---\n\n## Configuration\n\n### File Structure\n\n```\n.\nâ”œâ”€â”€ .claude/\nâ”‚   â”œâ”€â”€ agents/                    # Agent definitions\nâ”‚   â”‚   â”œâ”€â”€ researcher.md          # Research skill\nâ”‚   â”‚   â”œâ”€â”€ report-writer.md       # Research skill\nâ”‚   â”‚   â”œâ”€â”€ spec-analyst.md        # Planning skill (v2.2.0)\nâ”‚   â”‚   â”œâ”€â”€ spec-architect.md      # Planning skill (v2.2.0)\nâ”‚   â”‚   â””â”€â”€ spec-planner.md        # Planning skill (v2.2.0)\nâ”‚   â”œâ”€â”€ commands/                  # Slash commands (v2.2.0)\nâ”‚   â”‚   â”œâ”€â”€ plan-feature.md\nâ”‚   â”‚   â”œâ”€â”€ project-status.md\nâ”‚   â”‚   â”œâ”€â”€ research-topic.md\nâ”‚   â”‚   â””â”€â”€ verify-structure.md\nâ”‚   â”œâ”€â”€ hooks/                     # Python hook scripts\nâ”‚   â”‚   â”œâ”€â”€ user-prompt-submit.py  # Universal skill activation (v2.2.0)\nâ”‚   â”‚   â”œâ”€â”€ session-start.py\nâ”‚   â”‚   â””â”€â”€ post-tool-use-track-research.py\nâ”‚   â”œâ”€â”€ skills/\nâ”‚   â”‚   â”œâ”€â”€ multi-agent-researcher/\nâ”‚   â”‚   â”‚   â””â”€â”€ SKILL.md\nâ”‚   â”‚   â”œâ”€â”€ spec-workflow-orchestrator/  # (v2.2.0)\nâ”‚   â”‚   â”‚   â””â”€â”€ SKILL.md\nâ”‚   â”‚   â””â”€â”€ skill-rules.json       # Trigger configuration\nâ”‚   â”œâ”€â”€ utils/                     # Production utilities (v2.2.0)\nâ”‚   â”‚   â”œâ”€â”€ archive_project.sh\nâ”‚   â”‚   â”œâ”€â”€ restore_archive.sh\nâ”‚   â”‚   â”œâ”€â”€ list_archives.sh\nâ”‚   â”‚   â”œâ”€â”€ workflow_state.sh\nâ”‚   â”‚   â””â”€â”€ detect_next_version.sh\nâ”‚   â”œâ”€â”€ settings.json              # Hooks configuration (committed)\nâ”‚   â”œâ”€â”€ settings.local.json        # User overrides (gitignored)\nâ”‚   â””â”€â”€ config.json                # Path & research configuration\nâ”œâ”€â”€ files/\nâ”‚   â”œâ”€â”€ research_notes/            # Individual researcher outputs\nâ”‚   â””â”€â”€ reports/                   # Synthesis reports\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ projects/                  # Planning outputs (v2.2.0)\nâ”‚   â””â”€â”€ adrs/                      # Architecture Decision Records (v2.2.0)\nâ”œâ”€â”€ logs/                          # Session logs + state\nâ”‚   â”œâ”€â”€ session_*_{transcript,tool_calls,state}.*\nâ”‚   â””â”€â”€ state/current.json         # Active skill pointer\nâ””â”€â”€ setup.py                       # Interactive setup script\n```\n\n### File & Directory Reference\n\nComplete reference of all files and their roles:\n\n| File/Directory | Purpose | Type | User Action |\n|----------------|---------|------|-------------|\n| **Core Skill Files** | | | |\n| `.claude/skills/multi-agent-researcher/SKILL.md` | Skill definition with `allowed-tools` constraint that enforces workflow | Skill Definition | View/Customize |\n| `.claude/skills/spec-workflow-orchestrator/SKILL.md` | Planning orchestrator (v2.2.0) | Skill Definition | View/Customize |\n| `.claude/agents/researcher.md` | Instructions for researcher agents (web research, note-taking) | Agent Definition | View/Customize |\n| `.claude/agents/report-writer.md` | Instructions for report-writer agent (synthesis, cross-referencing) | Agent Definition | View/Customize |\n| `.claude/agents/spec-analyst.md` | Requirements gathering (v2.2.0) | Agent Definition | View/Customize |\n| `.claude/agents/spec-architect.md` | System design (v2.2.0) | Agent Definition | View/Customize |\n| `.claude/agents/spec-planner.md` | Task breakdown (v2.2.0) | Agent Definition | View/Customize |\n| **Hook System (Enforcement & Tracking)** | | | |\n| `.claude/hooks/user-prompt-submit.py` | Universal skill activation (v2.2.0) | Hook Script | Advanced Only |\n| `.claude/hooks/post-tool-use-track-research.py` | Logs every tool call, identifies agents, enforces quality gates | Hook Script | Advanced Only |\n| `.claude/hooks/session-start.py` | Auto-creates directories, restores sessions, displays status | Hook Script | Advanced Only |\n| `.claude/settings.json` | Registers hooks with Claude Code (committed to repo) | Settings | Caution |\n| `.claude/settings.local.json` | User-specific overrides (gitignored, optional) | Settings | Optional |\n| **Configuration & State** | | | |\n| `.claude/config.json` | Paths, logging settings, research parameters | Config | Customize |\n| `logs/state/current.json` | Active skill pointer for dual-skill routing (~100 bytes) | State | Auto-Generated |\n| `logs/session_*_state.json` | Per-session history: skill invocations (both skills) | State | Auto-Generated |\n| `.claude/skills/skill-rules.json` | Trigger patterns for skill activation | Config | View |\n| **Data Outputs** | | | |\n| `files/research_notes/*.md` | Individual researcher findings (one file per subtopic) | Research Data | Auto-Generated |\n| `files/reports/*.md` | Comprehensive synthesis reports (timestamped) | Final Reports | Auto-Generated |\n| `docs/projects/{slug}/*.md` | Planning deliverables (v2.2.0) | Planning Data | Auto-Generated |\n| `docs/adrs/*.md` | Architecture Decision Records (v2.2.0) | Planning Data | Auto-Generated |\n| **Logs & Audit Trail** | | | |\n| `logs/session_*_transcript.txt` | Human-readable session log with agent identification | Log | Auto-Generated |\n| `logs/session_*_tool_calls.jsonl` | Structured JSON log for programmatic analysis | Log | Auto-Generated |\n| `logs/session_*_state.json` | Session skill invocations and research sessions | Log | Auto-Generated |\n| **Utilities** | | | |\n| `setup.py` | Interactive configuration wizard for advanced customization | Setup Script | Run When Needed |\n| `.claude/utils/*.sh` | Production utilities for planning (v2.2.0) | Scripts | Run When Needed |\n\n**Key**:\n- **View**: Read to understand how system works\n- **Customize**: Safe to edit for your needs\n- **Advanced Only**: Don't edit unless you understand hook system deeply\n- **Caution**: Edit carefully; incorrect changes can break functionality\n- **Auto-Generated**: Created/updated by system; don't edit manually\n- **Optional**: Only create if you need user-specific overrides\n\n### Default Paths\n\nConfigured in `.claude/config.json`:\n\n```json\n{\n  \"paths\": {\n    \"research_notes\": \"files/research_notes\",\n    \"reports\": \"files/reports\",\n    \"logs\": \"logs\",\n    \"state\": \"logs/state\"\n  },\n  \"logging\": {\n    \"enabled\": true,\n    \"format\": \"flat\",\n    \"log_tool_calls\": true\n  },\n  \"research\": {\n    \"max_parallel_researchers\": 4,\n    \"require_synthesis_delegation\": true,\n    \"quality_gates_enabled\": true\n  }\n}\n```\n\n### Environment Variables\n\nOverride configuration without editing `config.json`:\n\n**Path Overrides**:\n```bash\nexport RESEARCH_NOTES_DIR=/custom/path/notes    # Default: files/research_notes\nexport REPORTS_DIR=/custom/path/reports          # Default: files/reports\nexport LOGS_DIR=/custom/path/logs                # Default: logs\nexport STATE_DIR=/custom/path/state              # Default: logs/state\n```\n\n**Research Settings**:\n```bash\nexport MAX_PARALLEL_RESEARCHERS=2                # Default: 4 (range: 1-10)\n```\n\n**Logging Settings**:\n```bash\nexport LOGGING_ENABLED=false                     # Default: true\n```\n\n**Priority Order** (highest to lowest):\n1. Environment variables (override everything)\n2. `.claude/config.json` values\n3. Hardcoded defaults\n\n**Usage Example**:\n```bash\n# Customize paths for this session\nexport RESEARCH_NOTES_DIR=/tmp/research\nexport REPORTS_DIR=/tmp/reports\nexport MAX_PARALLEL_RESEARCHERS=2\n\n# Start Claude Code with custom config\nclaude\n```\n\n**Verification**:\n```bash\n# Test that env vars are loaded\npython3 -c \"import sys; sys.path.insert(0, '.claude/utils'); \\\nfrom config_loader import load_config; \\\nimport os; os.environ['RESEARCH_NOTES_DIR'] = '/test'; \\\nprint(load_config()['paths']['research_notes'])\"\n# Should output: /test\n```\n\nThen restart Claude Code to apply changes.\n\n### Semantic-Search Configuration\n\nThe semantic-search skill implements **RAG (Retrieval-Augmented Generation)** for intelligent code search. It converts code into vector embeddings to find semantically similar content based on meaning, not just keyword matching:\n\n**Model Details**:\n- **Model**: `google/embeddinggemma-300m` (768-dimensional embeddings)\n- **Size**: ~1.2GB\n- **Download**: Automatic on first use (10-30 minutes, depends on internet speed)\n- **Cache Location**: `~/.claude_code_search/models/models--google--embeddinggemma-300m`\n- **Reuse**: Downloaded once, shared across all projects\n\n**First-Time Usage**:\n```\nYou: \"search for user authentication logic\"\n\nClaude: Starting semantic search...\n[Downloads model: 10-30 minutes]\nIndexing project files...\nSearch complete.\n```\n\n**Subsequent Usage**:\n```\nYou: \"search for database queries\"\n\nClaude: Starting semantic search...\n[Uses cached model: ~2 seconds]\nSearch complete.\n```\n\n**Storage Requirements**:\n- Model: ~1.2GB (`~/.claude_code_search/models/`)\n- Index per project: ~5-50MB (`~/.claude_code_search/projects/{project}/`)\n- Embedding cache: ~2-20MB per project (reused across reindexes)\n\n**Manual Model Management**:\n```bash\n# Check if model is downloaded\nls -lh ~/.claude_code_search/models/models--google--embeddinggemma-300m/\n\n# Check model size\ndu -sh ~/.claude_code_search/models/\n\n# Remove model (will re-download on next use)\nrm -rf ~/.claude_code_search/models/\n\n# Remove all indexes (safe, will rebuild on demand)\nrm -rf ~/.claude_code_search/projects/\n```\n\n**Performance Notes**:\n- **Apple Silicon**: Uses MPS (Metal Performance Shaders) GPU acceleration\n  - Model loads on `mps:0` device\n  - ~2-3x faster than CPU\n- **Other platforms**: Uses CPU (faiss-cpu)\n  - Still fast, but no GPU acceleration\n\n**Troubleshooting**:\n- **Slow first-time download**: Normal, model is 1.2GB (10-30 min)\n- **Disk space error**: Ensure 1.5GB+ free space in home directory\n- **Model corruption**: Delete `~/.claude_code_search/models/` and retry\n\n### Advanced Setup\n\nFor custom configuration:\n\n```bash\npython3 setup.py           # Interactive setup with prompts\npython3 setup.py --verify  # Check setup without changes\npython3 setup.py --repair  # Auto-fix issues\n```\n\nThe setup script allows you to:\n- Customize directory paths\n- Configure max parallel researchers (1-10)\n- Verify Python version and hooks\n- Check for missing files or directories\n\n#### Settings Files Overview\n\nThree settings files work together - understanding their roles prevents configuration errors:\n\n| File | Purpose | Location | User Action | Committed to Git |\n|------|---------|----------|-------------|------------------|\n| `.claude/settings.json` | **Golden configuration** (hooks, permissions, tools) | Project root | **âŒ DO NOT EDIT** | âœ… Yes |\n| `.claude/settings.template.json` | **Template for first-time setup** | Project root | **âŒ DO NOT EDIT** | âœ… Yes |\n| `.claude/settings.local.json` | **User-specific overrides** (gitignored) | Project root | âœ… Safe to customize | âŒ No (gitignored) |\n\n**How They Work Together**:\n\n1. **On first `claude` run**: `session-start.py` hook copies `settings.template.json` â†’ `settings.local.json`\n2. **Claude Code loads**: Reads `settings.json` (hooks) + `settings.local.json` (overrides)\n3. **Hooks execute**: Configured in `settings.json`, NOT `settings.local.json`\n\n**âš ï¸ CRITICAL: Do NOT Duplicate Hooks**\n\nIf you create or edit `.claude/settings.local.json`, **REMOVE any `hooks` section**:\n\n```json\n{\n  \"// WRONG - This will break things\": \"\",\n  \"hooks\": {\n    \"UserPromptSubmit\": \".../.claude/hooks/user-prompt-submit.py\"\n  }\n}\n```\n\n**Why?** Hooks are already in `settings.json`. Duplicating them causes:\n- âŒ Hooks run twice per event\n- âŒ Duplicate session logs\n- âŒ Race conditions in state management\n- âŒ Confusing \"which hooks are active\" debugging\n\n**Safe `settings.local.json` Example**:\n\n```json\n{\n  \"permissions\": {\n    \"allowedDomains\": [\"example.com\", \"mycompany.com\"]\n  }\n}\n```\n\n**When to Edit Each File**:\n- **`settings.json`**: Never (managed by project maintainers)\n- **`settings.template.json`**: Never (template only)\n- **`settings.local.json`**: Customize paths/permissions (no hooks!)\n\n---\n\n## Troubleshooting\n\nCommon issues and solutions for first-time users:\n\n### Fresh Clone Not Auto-Detecting Prerequisites\n\n**Symptom**: After cloning, you see `âš ï¸ Semantic-search prerequisites not found` even though you have prerequisites installed from another project.\n\n**Cause**: The state file may have stale data from git or the check-prerequisites script isn't finding global components.\n\n**Solution - Quick Diagnostic**:\n```bash\n# Run quick verification (5 checks)\n.claude/skills/semantic-search/scripts/verify-setup\n\n# If issues found, run full check\n.claude/skills/semantic-search/scripts/check-prerequisites\n```\n\n**Solution - Manual State Reset**:\n```bash\n# Delete stale state file (will regenerate on next session)\nrm -f logs/state/semantic-search-prerequisites.json\n\n# Restart Claude Code\nclaude\n# Should now show: âœ“ Semantic-search prerequisites found\n```\n\n**Expected Output After Fix**:\n```\nğŸ” Detecting semantic-search prerequisites...\nâœ“ Semantic-search prerequisites found (using global components)\nğŸ”„ Indexing project in background...\n```\n\n### Hooks Not Executing / Import Errors\n\n**Symptoms**:\n- Error message: `ImportError: No module named 'state_manager'`\n- Error message: `ImportError: No module named 'session_logger'`\n- No session logs created in `logs/` directory\n- No \"Session logs initialized\" message on startup\n\n**Solution**:\n```bash\npython3 setup.py --repair\n```\n\nThis validates and fixes:\n- Python version compatibility (requires 3.8+)\n- Utility module availability (.claude/utils/)\n- Hook executability permissions\n- Directory structure\n\n**Manual Verification**:\n```bash\n# Check Python version\npython3 --version  # Should show 3.8+\n\n# Check utility modules exist\nls -la .claude/utils/*.py\n\n# Check hooks are executable\nls -la .claude/hooks/*.py  # Should show -rwxr-xr-x\n\n# Test session-start hook manually\npython3 .claude/hooks/session-start.py\n```\n\n### Claude-Context-Local Not Found\n\n**Symptom**: Error during semantic-search: \"Failed to import dependencies\" or \"claude-context-local is not installed\"\n\n**Solution**: Clone the Python library:\n```bash\ngit clone https://github.com/FarhanAliRaza/claude-context-local.git \\\n  ~/.local/share/claude-context-local\n\n# Verify installation\nls -la ~/.local/share/claude-context-local/\n```\n\n**Important**: No venv, no pip install, no `uv` needed. Just clone!\n\n### Embedding Model Download Issues\n\n**Symptom 1**: Slow first semantic-search (10-30 minutes)\n\n**Solution**: This is NORMAL - the 1.2GB embedding model downloads automatically on first use. Subsequent searches are instant (~2 seconds).\n\n**Symptom 2**: Download fails or hangs\n\n**Solutions**:\n```bash\n# Check disk space (needs 1.5GB+)\ndf -h ~\n\n# Check internet connection\ncurl -I https://huggingface.co\n\n# Remove corrupted download and retry\nrm -rf ~/.claude_code_search/models/\n# Then retry semantic-search\n```\n\n### Hooks Not Running / No Session Logs\n\n**Symptoms**:\n- No files in `logs/` directory\n- No \"Session logs initialized\" message when starting Claude Code\n- Research skill doesn't enforce delegation\n\n**Solutions**:\n\n1. **Check settings.json exists**:\n   ```bash\n   cat .claude/settings.json | head -20\n   # Should show hooks configuration\n   ```\n\n2. **Check hooks are executable**:\n   ```bash\n   ls -la .claude/hooks/*.py\n   # Should show -rwxr-xr-x (executable)\n   ```\n\n3. **Manually test hooks**:\n   ```bash\n   python3 .claude/hooks/session-start.py\n   # Should create directories and show status\n   ```\n\n4. **Check for Python errors**:\n   ```bash\n   python3 -c \"import sys; sys.path.insert(0, '.claude/utils'); import state_manager\"\n   # Should return no errors\n   ```\n\n### Research Produces No Results\n\n**Symptoms**:\n- Research completes but no files in `files/reports/`\n- Empty or incomplete results\n- Agents spawn but produce nothing\n\n**Possible Causes & Solutions**:\n\n1. **API quota exceeded**:\n   ```bash\n   # Check API key is set\n   echo $ANTHROPIC_API_KEY  # Should not be empty\n   ```\n\n2. **Web search disabled**:\n   ```bash\n   # Check permissions in settings.json\n   grep -A5 '\"permissions\"' .claude/settings.json\n   # Should show WebSearch allowed\n   ```\n\n3. **Write permissions**:\n   ```bash\n   # Check directories are writable\n   ls -ld files/research_notes/ files/reports/\n   # Should show drwxr-xr-x (writable)\n   ```\n\n4. **Review session logs**:\n   ```bash\n   # Check latest session for errors\n   cat logs/session_*_transcript.txt | tail -50\n   # Look for \"Error\" or \"âš ï¸\" messages\n   ```\n\n### Performance Issues / Slow Research\n\n**Symptom**: Research takes longer than expected (>10 minutes)\n\n**Possible Causes**:\n- Slow internet connection (affects web searches)\n- Rate limited by search APIs\n- Large topic requiring extensive research\n- Multiple parallel agents competing for resources\n\n**Not a Problem**: Research quality > speed. You can interrupt with `Ctrl+C` and use partial results from `files/research_notes/`.\n\n**Optimization Tips**:\n```bash\n# Reduce parallel researchers in config.json\n# Change from 4 to 2 for slower connections\n\"max_parallel_researchers\": 2\n```\n\n### Session State Corruption\n\n**Symptoms**:\n- Weird behavior with workflow state\n- \"Skip research\" when you didn't ask to\n- Duplicate research sessions logged\n- State conflicts between skills\n\n**Solution - Clear state** (safe to delete):\n```bash\n# Remove all state files\nrm -f logs/state/*.json logs/session_*\n\n# Restart Claude Code - fresh state will be created\nclaude\n```\n\n**What gets reset**:\n- Workflow state (current skill pointer)\n- Session history\n- Research session tracking\n\n**What's preserved**:\n- Configuration (config.json)\n- Research outputs (files/research_notes/, files/reports/)\n- Semantic search indexes\n\n### Paths Resolved to Wrong Location\n\n**Symptoms**:\n- Files created in unexpected directories\n- config.json paths not being respected\n- \"File not found\" errors for existing files\n\n**Solution - Start Claude Code from project root**:\n```bash\n# WRONG - Don't start from parent or subdirectory\ncd ~/projects/\nclaude  # âŒ Wrong working directory\n\n# RIGHT - Start from project root\ncd ~/projects/Claude-Multi-Agent-Research-System-Skill/\nclaude  # âœ… Correct\n```\n\n**Why**: All paths in config.json are relative to project root. Hooks use `Path(__file__).parent.parent.parent` to find project root.\n\n### Semantic-Search Not Working\n\n**Symptom**: Semantic-search commands fail or produce no results\n\n**Diagnostic Checklist**:\n\n```bash\n# 1. Check claude-context-local is installed\nls -la ~/.local/share/claude-context-local/\n# Should show directories: merkle/, chunking/, embeddings/\n\n# 2. Check embedding model is downloaded\nls -la ~/.claude_code_search/models/models--google--embeddinggemma-300m/\n# Should show model files (1.2GB total)\n\n# 3. Check project is indexed\nls -la ~/.claude_code_search/projects/*/\n# Should show index files for your project\n\n# 4. Test indexing manually\npython3 .claude/skills/semantic-search/scripts/incremental-reindex $(pwd)\n# Should show indexing progress\n\n# 5. Test search manually\npython3 .claude/skills/semantic-search/scripts/search $(pwd) \"test query\"\n# Should return results\n```\n\n### Git Command Not Found (Semantic-Search)\n\n**Symptom**: Semantic-search fails with git-related errors\n\n**Solution**: Install git:\n```bash\n# macOS\nbrew install git\n\n# Linux (Debian/Ubuntu)\nsudo apt-get install git\n\n# Linux (RHEL/CentOS)\nsudo yum install git\n\n# Verify\ngit --version\n```\n\n**Why needed**: Semantic-search uses `git rev-parse` to find project root.\n\n### Still Having Issues?\n\n1. **Enable detailed logging**:\n   ```bash\n   # Check config.json has logging enabled\n   grep -A3 '\"logging\"' .claude/config.json\n   ```\n\n2. **Review session logs**:\n   ```bash\n   ls -lt logs/session_* | head -3\n   # Check most recent session logs\n   ```\n\n3. **Run full diagnostic**:\n   ```bash\n   python3 setup.py --verify\n   # Shows detailed system status\n   ```\n\n4. **Check prerequisites**:\n   ```bash\n   python3 --version  # 3.8+\n   git --version      # Any version\n   which bash         # /bin/bash or similar\n   df -h ~            # >1.5GB free\n   ```\n\n---\n\n## Architecture Deep Dive\n\n### Architecture Decision Records (ADRs)\n\n**ADR-001: Direct Script vs Agent for Auto-Reindex** ([Full ADR](docs/architecture/ADR-001-direct-script-vs-agent-for-auto-reindex.md) | [Quick Reference](docs/architecture/auto-reindex-design-quick-reference.md))\n\n**Decision**: Use direct bash scripts for automatic reindex operations (session start, post-write hooks)\n\n**Key Metrics**:\n- **Performance**: 5x faster (2.7s vs 14.6s)\n- **Cost**: $0 vs $144/year per 10 developers\n- **Reliability**: Deterministic, works offline\n- **Hook Safety**: 9s buffer vs risky timeout\n\n**Agent Use**: Reserved for manual operations where intelligence and rich output add value (user explicitly invokes reindex, troubleshooting, diagnostics)\n\n---\n\n### Comparison to Reference SDK\n\nThis project adapts the multi-agent research pattern from [Anthropic's research-agent demo](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent)<sup>[[5]](#ref-5)</sup> for Claude Code's skill system.\n\n| Feature | Reference (Python SDK) | This Project (Claude Code) |\n|---------|------------------------|----------------------------|\n| **Platform** | Python Agent SDK (standalone) | **Claude Code Skill** (integrated) |\n| **Hooks** | Python SDK hooks (`HookMatcher`) | Shell-based hooks (Python scripts) |\n| **Enforcement** | Behavioral (via prompts) | **Architectural** (via `allowed-tools` ~95% reliability)<sup>[[4]](#ref-4)</sup> |\n| **Logging** | SDK-managed with `parent_tool_use_id` | **Custom hooks with heuristic agent detection** |\n| **Agent Identification** | SDK's `parent_tool_use_id` field | **File path + tool usage heuristics** |\n| **Configuration** | Python code | **JSON config + environment variables** |\n| **Deployment** | Standalone Python app | **Claude Code skill + hooks** |\n| **Session Logs** | Nested directories | **Flat structure** (configurable) |\n| **Setup** | Manual installation | **Automatic first-time setup** |\n\n**Use Reference Implementation If**:\n- Building standalone Python application\n- Need SDK's native hook system\n- Want official Anthropic patterns without modification\n\n**Use This Implementation If**:\n- Using Claude Code as primary environment\n- Need workflow enforcement via architecture\n- Require audit logging for compliance\n- Want configuration flexibility (JSON + env vars)\n\n### Enforcement Mechanisms\n\n#### 1. `allowed-tools` Constraint\n\nFrom `.claude/skills/multi-agent-researcher/SKILL.md`:\n\n```yaml\n---\nname: multi-agent-researcher\nallowed-tools: Task, Read, Glob, TodoWrite\n---\n```\n\nWhen this skill is active, Claude can **only** use the listed tools<sup>[[4]](#ref-4)</sup>. The Write tool is deliberately excluded, making it **architecturally impossible** for the orchestrator to write synthesis reports.\n\n**Reliability**: ~95% (cannot be bypassed through prompt injection).\n\nFrom `.claude/skills/spec-workflow-orchestrator/SKILL.md`:\n\n```yaml\n---\nname: spec-workflow-orchestrator\nallowed-tools: Task, Read, Glob, TodoWrite, Write, Edit\n---\n```\n\nSpec skill **has Write access** - enforcement is via quality gates (85% threshold), not tool restriction. Orchestrator delegates to spec-analyst â†’ spec-architect â†’ spec-planner sequentially, validating each deliverable before proceeding.\n\n#### 2. Quality Gates\n\n**Research Skill** - Implemented in hooks:\n\n```python\n# Detect orchestrator bypassing report-writer\nif synthesis_phase and tool == \"Write\" and agent == \"orchestrator\":\n    violation = \"Orchestrator attempted to write synthesis report\"\n    log_violation(violation)\n```\n\n**Spec Skill** - 85% threshold scoring (100 points total):\n\n| Criteria | Points | Applies To |\n|----------|--------|------------|\n| Completeness | 25 | All deliverables |\n| Technical Depth | 25 | Architecture, ADRs |\n| Actionability | 25 | Tasks, requirements |\n| Clarity | 25 | All deliverables |\n\nMax 3 iterations per agent. Below threshold â†’ feedback loop â†’ retry.\n\n#### 3. Session State Tracking\n\nTracks active skill and workflow progression for the **dual-skill platform**.\n\n**Current State** (`logs/state/current.json` ~100 bytes):\n- `currentSkill`: Which skill is active (multi-agent-researcher **or** spec-workflow-orchestrator)\n- `currentResearch`: Active research session details (if research skill)\n\n**Session History** (`logs/session_*_state.json`):\n- `skillInvocations[]`: All skill activations this session (both skills)\n- `researchSessions[]`: Completed research sessions\n\n**Enables**:\n- **Routing**: Hooks check `currentSkill` before activating another skill\n- **Restoration**: Resume interrupted workflows (either skill)\n- **Audit**: Track all skill usage across sessions\n\n**Why Split Architecture?** Claude Code's Read tool has 25K token limit. A single persistent file would fail at ~359 skill invocations. Split keeps `current.json` tiny (~100 bytes) while session files are bounded per-session.\n\n### Hooks Architecture\n\nThe hook system is the **foundation of enforcement and tracking**. Without hooks, this system wouldn't workâ€”`allowed-tools` constraints prevent unauthorized actions, but hooks provide logging, quality gates, and session management.\n\n#### How Hooks Work\n\nClaude Code fires hooks at specific lifecycle events:\n- **UserPromptSubmit**: Before processing user prompt (v2.2.0)\n- **PostToolUse**: After every tool call (Read, Write, Task, WebSearch, etc.)\n- **SessionStart**: When Claude Code session begins\n\nOur hooks are registered in `.claude/settings.json`:\n\n```json\n{\n  \"hooks\": {\n    \"UserPromptSubmit\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/user-prompt-submit.py\\\"\"\n      }]\n    }],\n    \"PostToolUse\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/post-tool-use-track-research.py\\\"\"\n      }]\n    }],\n    \"SessionStart\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/session-start.py\\\"\"\n      }]\n    }]\n  }\n}\n```\n\n#### UserPromptSubmit Hook (v2.2.0)\n\n**Runs BEFORE every user prompt is processed** to enforce skill activation.\n\n**Responsibilities**:\n1. Detects research triggers (37+ keywords, 15 patterns)\n2. Detects planning triggers (90+ keywords, 23 patterns)\n3. Injects enforcement reminders into Claude's context\n\n#### PostToolUse Hook (`post-tool-use-track-research.py`)\n\n**Runs after EVERY tool call** to provide comprehensive tracking and enforcement.\n\n**Responsibilities**:\n\n1. **Agent Identification**\n   ```python\n   # Heuristics to identify which agent made the call\n   if tool == \"Task\" and \"subagent_type\" in input:\n       agent = \"orchestrator\"\n   elif file_path.startswith(\"files/research_notes/\"):\n       agent = \"researcher\"\n   elif file_path.startswith(\"files/reports/\"):\n       agent = \"report-writer\"\n   ```\n\n2. **Logging**\n   - Appends to `transcript.txt` with human-readable format\n   - Appends to `tool_calls.jsonl` with structured JSON\n   - Includes: timestamp, agent, tool, input, output, duration\n\n3. **Quality Gate Enforcement**\n   ```python\n   # Detect workflow violations\n   if synthesis_phase and tool == \"Write\" and agent == \"orchestrator\":\n       violation = \"Orchestrator attempted synthesis (should use report-writer)\"\n       log_violation(violation)\n   ```\n\n4. **Skill & Phase Tracking**\n   - Updates `logs/state/current.json` with active skill\n   - Writes completed skills to `logs/session_*_state.json`\n   - **Research**: decomposition â†’ parallel research â†’ synthesis â†’ delivery\n   - **Planning**: analyze â†’ architect â†’ plan â†’ validate (quality gate)\n\n**Example log entry**:\n```\n[10:57:22] ORCHESTRATOR â†’ Task âœ…\n  Input: {\"subagent_type\": \"researcher\", \"description\": \"Research quantum computing\"}\n  Output: Success (2.4 KB)\n  Duration: 1250ms\n```\n\n#### SessionStart Hook (`session-start.py`)\n\n**Runs once when Claude Code session begins**.\n\n**Responsibilities**:\n\n1. **Auto-Setup**\n   ```python\n   # Create directories if missing\n   create_directory(\"files/research_notes/\")\n   create_directory(\"files/reports/\")\n   create_directory(\"logs/\")\n   create_directory(\"logs/state/\")\n   ```\n\n2. **Session Initialization**\n   - Generates unique session ID (e.g., `session_20251118_105714`)\n   - Creates log files (`transcript.txt`, `tool_calls.jsonl`, `state.json`)\n   - Displays setup status to user\n\n3. **Session Restoration** (if previous session was interrupted)\n   - Reads `logs/state/current.json` for active skill\n   - Detects incomplete research **or** planning workflows\n   - Offers to resume or start fresh\n\n**Example output**:\n```\nğŸ“ Session logs initialized: logs/session_20251118_105714_{transcript.txt,tool_calls.jsonl,state.json}\nâœ… All directories exist\nâœ… Hooks configured correctly\n```\n\n#### Hook + Constraint Synergy\n\nThe **combination** of hooks and `allowed-tools` creates robust enforcement:\n\n| Component | Role | Reliability |\n|-----------|------|-------------|\n| `allowed-tools: Task, Read, Glob, TodoWrite` | **Prevents** orchestrator from writing reports | ~95% (architectural) |\n| PostToolUse quality gates | **Detects** if violation somehow occurs | ~100% (catches everything) |\n| Session state tracking | **Verifies** all workflow phases complete | ~100% (checks existence) |\n\n**Together**: ~99%+ enforcement reliability with full audit trail.\n\n#### Hook Execution Flow\n\n```\nUser: \"research quantum computing\"\n    â†“\nUserPromptSubmit hook fires (v2.2.0)\n    â†’ Detects research trigger\n    â†’ Injects skill enforcement reminder\n    â†“\nSessionStart hook fires\n    â†’ Creates directories\n    â†’ Initializes session logs\n    â†’ Displays status\n    â†“\nOrchestrator decomposes query\n    â†“\nOrchestrator spawns researchers (Task tool)\n    â†“ PostToolUse hook fires\n        â†’ Identifies agent: orchestrator\n        â†’ Logs: Task call\n        â†’ Updates phase: research (in progress)\n    â†“\nEach researcher conducts research (WebSearch, Write tools)\n    â†“ PostToolUse hook fires (multiple times)\n        â†’ Identifies agent: researcher (via file path heuristic)\n        â†’ Logs: WebSearch + Write calls\n        â†’ Tracks: research note paths\n    â†“\nAll researchers complete\n    â†“\nOrchestrator spawns report-writer (Task tool)\n    â†“ PostToolUse hook fires\n        â†’ Identifies agent: orchestrator\n        â†’ Logs: Task call\n        â†’ Updates phase: synthesis (in progress)\n    â†“\nReport-writer synthesizes (Read, Write tools)\n    â†“ PostToolUse hook fires (multiple times)\n        â†’ Identifies agent: report-writer (via file path heuristic)\n        â†’ Logs: Read + Write calls\n        â†’ Updates phase: synthesis (complete)\n    â†“\nSession ends\n    â†“\nAll tool calls logged âœ…\nAll phases tracked âœ…\nAudit trail complete âœ…\n```\n\n**Same pattern for Planning Skill**: Replace \"research X\" â†’ \"plan X\", researchers â†’ spec-analyst/architect/planner, report-writer â†’ quality gate validation. State tracks `currentSkill: spec-workflow-orchestrator`.\n\n**Without hooks**: `allowed-tools` would prevent violations, but you'd have no logs, no tracking, no session management, no quality gate verification.\n\n**With hooks**: Complete observability + enforcement + automation.\n\n### Session Logging\n\n#### Log Format: Flat Structure\n\n```\nlogs/\nâ”œâ”€â”€ session_20251118_105714_transcript.txt      # Human-readable\nâ”œâ”€â”€ session_20251118_105714_tool_calls.jsonl    # Structured JSON\nâ”œâ”€â”€ session_20251118_105714_state.json          # Session skill/research history\nâ””â”€â”€ state/\n    â””â”€â”€ current.json                            # Active skill pointer (~100 bytes)\n```\n\n**Benefits of flat structure**:\n- Easier navigation (no nested directories)\n- Simpler programmatic analysis (`grep`, `jq`)\n- Compatible with log aggregation tools\n\n#### transcript.txt Example\n\n```\nResearch Agent Session Log\nSession ID: session_20251118_105714\nStarted: 2025-11-18T10:57:14.369265\n================================================================================\n\n[10:57:22] ORCHESTRATOR â†’ Task âœ…\n  Input: {\"subagent_type\": \"researcher\", \"description\": \"Research theoretical foundations\", ...}\n  Output: Success (2.4 KB)\n  Duration: 1250ms\n\n[10:58:45] RESEARCHER â†’ WebSearch âœ…\n  Input: {\"query\": \"quantum computing qubits superposition\"}\n  Output: Found 10 results\n  Duration: 850ms\n\n[11:02:10] ORCHESTRATOR â†’ Task âœ…\n  Input: {\"subagent_type\": \"report-writer\", ...}\n  Output: Success (15.2 KB)\n  Duration: 3400ms\n```\n\n#### Agent Identification Heuristics\n\nSince Claude Code doesn't provide `parent_tool_use_id` (SDK feature), agents are identified via:\n\n1. **File paths**: Writing to `files/research_notes/` â†’ researcher; `files/reports/` â†’ report-writer\n2. **Tool usage**: Task tool with `subagent_type` â†’ orchestrator\n3. **Session phase**: During synthesis + WebSearch â†’ researcher\n\n**Accuracy**: ~90% (trade-off for not requiring SDK).\n\n---\n\n## Inspiration & Credits\n\nThis project adapts the multi-agent research pattern for Claude Code's skill system, combining patterns from multiple production-proven projects:\n\n### Primary Inspiration\n\n- **[claude-agent-sdk-demos/research-agent](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent)** by Anthropic PBC<sup>[[5]](#ref-5)</sup>\n  - Multi-agent research orchestration concept\n  - Decomposition â†’ Research â†’ Synthesis workflow\n  - Session logging patterns\n  - License: Apache-2.0\n\n### Workflow Patterns\n\n- **[DevFlow](https://github.com/mathewtaylor/devflow)** by Mathew Taylor<sup>[[8]](#ref-8)</sup>\n  - Architectural enforcement via `allowed-tools` constraint\n  - State tracking with `state.json`\n  - Quality gates for phase validation\n  - License: MIT\n\n- **[Claude-Flow](https://github.com/ruvnet/claude-flow)** by ruvnet<sup>[[9]](#ref-9)</sup>\n  - Session persistence patterns\n  - Research session restoration\n  - License: MIT\n\n- **[TDD-Guard](https://github.com/nizos/tdd-guard)** by nizos<sup>[[10]](#ref-10)</sup>\n  - Agent tracking via tool usage patterns\n  - Multi-context workflow enforcement\n  - License: MIT\n\n- **[claude-code-infrastructure-showcase](https://github.com/diet103/claude-code-infrastructure-showcase)** by diet103<sup>[[11]](#ref-11)</sup>\n  - Skill auto-activation patterns\n  - `skill-rules.json` configuration\n  - License: MIT\n\n### Semantic Search Infrastructure\n\n- **[claude-context-local](https://github.com/FarhanAliRaza/claude-context-local)** by FarhanAliRaza<sup>[[12]](#ref-12)</sup>\n  - Foundation for semantic-search skill (RAG system)\n  - FAISS-based vector indexing (IndexFlatIP)\n  - Multi-language code chunking (15+ languages)\n  - Merkle tree change detection for smart reindexing\n  - Embedding generation (sentence-transformers)\n  - License: GPL-3.0 (imported via PYTHONPATH for license compatibility)\n\nAll projects are MIT, Apache-2.0, or GPL-3.0 licensed and used in compliance with their terms.\n\n---\n\n## Author & Acknowledgments\n\n**Created by Ahmed Maged**\nGitHub: [@ahmedibrahim085](https://github.com/ahmedibrahim085)\n\nThis project was conceived, architected, and guided at every step by Ahmed Maged. Implementation was assisted by Claude Code, but all architectural decisions, design choices, and strategic direction came from the author.\n\n**Special Acknowledgments**:\n- Anthropic team for the [claude-agent-sdk-demos/research-agent](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent) inspiration\n- FarhanAliRaza for [claude-context-local](https://github.com/FarhanAliRaza/claude-context-local), the foundation of our semantic-search skill\n- Authors of DevFlow, Claude-Flow, TDD-Guard, and Infrastructure Showcase for proven workflow patterns\n- Claude Code community for feature requests and feedback\n\n---\n\n## License\n\nThis project is licensed under the **Apache License 2.0** - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## References\n\n<a id=\"ref-1\"></a>**[1]** Anthropic. \"Introducing Agent Skills.\" Anthropic News, October 16, 2025. https://www.anthropic.com/news/skills\n\n<a id=\"ref-2\"></a>**[2]** Anthropic. \"Introducing the Model Context Protocol.\" Anthropic News, November 2024. https://www.anthropic.com/news/model-context-protocol\n\n<a id=\"ref-3\"></a>**[3]** Anthropic. \"Agent Skills - Claude Code Docs.\" Accessed November 2025. https://code.claude.com/docs/en/skills\n\n<a id=\"ref-4\"></a>**[4]** Willison, Simon. \"Claude Skills are awesome, maybe a bigger deal than MCP.\" Simon Willison's Weblog, October 16, 2025. https://simonwillison.net/2025/Oct/16/claude-skills/\n\n<a id=\"ref-5\"></a>**[5]** Anthropic. \"How we built our multi-agent research system.\" Anthropic Engineering Blog, 2025. https://www.anthropic.com/engineering/multi-agent-research-system\n\n<a id=\"ref-6\"></a>**[6]** \"Multi-Agent Orchestration: Running 10+ Claude Instances in Parallel (Part 3).\" DEV Community, 2025. https://dev.to/bredmond1019/multi-agent-orchestration-running-10-claude-instances-in-parallel-part-3-29da\n\n<a id=\"ref-7\"></a>**[7]** Greyling, Cobus. \"Orchestrating Parallel AI Agents.\" Medium, 2025. https://cobusgreyling.medium.com/orchestrating-parallel-ai-agents-dab96e5f2e61\n\n<a id=\"ref-8\"></a>**[8]** Taylor, Mathew. \"DevFlow - Agentic Feature Management.\" GitHub Repository. https://github.com/mathewtaylor/devflow\n\n<a id=\"ref-9\"></a>**[9]** ruvnet. \"Claude-Flow - Agent Orchestration Platform.\" GitHub Repository. https://github.com/ruvnet/claude-flow\n\n<a id=\"ref-10\"></a>**[10]** nizos. \"TDD-Guard - TDD Enforcement for Claude Code.\" GitHub Repository. https://github.com/nizos/tdd-guard\n\n<a id=\"ref-11\"></a>**[11]** diet103. \"Claude Code Infrastructure Showcase.\" GitHub Repository. https://github.com/diet103/claude-code-infrastructure-showcase\n\n<a id=\"ref-12\"></a>**[12]** FarhanAliRaza. \"claude-context-local - Local Context for Claude.\" GitHub Repository. https://github.com/FarhanAliRaza/claude-context-local\n\n---\n\n**â­ Star this repo** if you find it useful!\n",
  "installCommand": "git clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill ~/.claude/skills/multi-agent-research-system",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}