{
  "id": "29c25bdd4fe0bcc5",
  "slug": "multi-agent-research-system",
  "name": "Multi Agent Research System",
  "description": "A Multi-Agent Research System using Claude Code Skills. it is inspired by Anthropic claude-agent-sdk-demos",
  "author": "ahmedibrahim085",
  "authorAvatar": "https://avatars.githubusercontent.com/u/1140606?v=4",
  "repoUrl": "https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill",
  "repoFullName": "ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill",
  "stars": 6,
  "forks": 1,
  "category": "coding",
  "categories": [
    "coding"
  ],
  "tags": [
    "agents",
    "anthropic-claude",
    "claude",
    "claude-code",
    "claude-skills",
    "multi-agent",
    "multi-agent-systems",
    "orchestration",
    "skills",
    "subagents"
  ],
  "tier": 3,
  "status": "active",
  "createdAt": "2025-11-17T14:49:27Z",
  "updatedAt": "2025-12-09T16:00:27Z",
  "lastCommitAt": "2025-11-25T19:59:30Z",
  "source": "github-topic",
  "collectedAt": "2025-12-12T03:37:36.794Z",
  "authorUrl": "https://github.com/ahmedibrahim085",
  "license": "Apache-2.0",
  "readme": "# Claude Code Multi-Agent Research Skill\n\n**Orchestrated multi-agent research with architectural enforcement, parallel execution, and comprehensive audit trails.**\n\n[![Version](https://img.shields.io/badge/version-2.3.0-blue.svg)](https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill/releases)\n[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)\n[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n\n---\n\n## üéâ v2.2.x: Dual-Skill Orchestration Platform\n\nA **dual-skill platform** with smart routing and compound request detection:\n\n| Skill | Purpose | Agents |\n|-------|---------|--------|\n| **multi-agent-researcher** | Comprehensive topic investigation | researcher, report-writer |\n| **spec-workflow-orchestrator** | Planning from ideation to dev-ready specs | spec-analyst, spec-architect, spec-planner |\n\n**Key Features**:\n- **Smart Compound Detection** - When prompts trigger both skills, asks for clarification\n- **148 Trigger Keywords** - Automatic skill routing via hook\n- **Quality Gates** - 85% threshold with max 3 iterations\n\n**Quick Examples**:\n```\nresearch quantum computing fundamentals     ‚Üí multi-agent-researcher\nplan a task management PWA with offline     ‚Üí spec-workflow-orchestrator\nresearch auth methods and build login page  ‚Üí asks which skill to use\n```\n\nSee [Planning Workflow](#planning-workflow-new-in-v220) and [CHANGELOG.md](CHANGELOG.md) for details.\n\n---\n\n## Table of Contents\n\n- [Quick Start](#quick-start)\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n  - [Your First Research Query](#your-first-research-query)\n- [Why This Approach?](#why-this-approach)\n  - [vs. Direct Tools (WebSearch/WebFetch)](#vs-direct-tools-websearchwebfetch)\n  - [vs. MCP Servers](#vs-mcp-servers)\n  - [vs. Sequential Research](#vs-sequential-research)\n  - [Architectural Benefits](#architectural-benefits)\n  - [When NOT to Use](#when-not-to-use)\n- [How It Works](#how-it-works)\n  - [Phase 1: Decomposition](#phase-1-decomposition)\n  - [Phase 2: Parallel Research](#phase-2-parallel-research)\n  - [Phase 3: Synthesis](#phase-3-synthesis)\n  - [Phase 4: Delivery](#phase-4-delivery)\n- [Planning Workflow (New in v2.2.0)](#planning-workflow-new-in-v220)\n- [Testing](#testing)\n- [Configuration](#configuration)\n  - [File Structure](#file-structure)\n  - [File & Directory Reference](#file--directory-reference)\n  - [Environment Variables](#environment-variables)\n  - [Advanced Setup](#advanced-setup)\n- [Architecture Deep Dive](#architecture-deep-dive)\n  - [Comparison to Reference SDK](#comparison-to-reference-sdk)\n  - [Enforcement Mechanisms](#enforcement-mechanisms)\n  - [Hooks Architecture](#hooks-architecture)\n  - [Session Logging](#session-logging)\n- [Inspiration & Credits](#inspiration--credits)\n- [Author & Acknowledgments](#author--acknowledgments)\n- [License](#license)\n- [References](#references)\n\n---\n\n## Quick Start\n\n### Prerequisites\n\n- **Claude Code** installed ([Pro, Max, Team, or Enterprise tier](https://www.anthropic.com/news/skills))<sup>[[1]](#ref-1)</sup>\n- **Python 3.8+**\n- **Git**\n\n### Installation\n\n1. **Clone the repository**:\n```bash\ngit clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill.git\ncd Claude-Multi-Agent-Research-System-Skill\n```\n\n2. **Start Claude Code** in the project directory:\n```bash\nclaude\n```\n\nThe SessionStart hook will automatically:\n- Create required directories (`files/research_notes/`, `files/reports/`, `logs/`)\n- Initialize session logging\n- Display setup status\n\n**Note**: Hooks are pre-configured in `.claude/settings.json` and work out-of-the-box. **Do not duplicate hooks in `settings.local.json`** to avoid duplicate hook executions.\n\n### Your First Research Query\n\nTry this example:\n```\nresearch quantum computing fundamentals\n```\n\n**Expected output**:\n```\nüìù Session logs initialized: logs/session_YYYYMMDD_HHMMSS_{transcript.txt,tool_calls.jsonl,state.json}\n\n# Research Complete: Quantum Computing Fundamentals\n\nComprehensive research completed with 3 specialized researchers.\n\n## Key Findings\n1. [Finding from researcher 1]\n2. [Finding from researcher 2]\n3. [Finding from researcher 3]\n\n## Files Generated\n**Research Notes**: `files/research_notes/`\n- quantum-computing-fundamentals-basics_YYYYMMDD-HHMMSS.md\n- quantum-computing-fundamentals-hardware_YYYYMMDD-HHMMSS.md\n- quantum-computing-fundamentals-algorithms_YYYYMMDD-HHMMSS.md\n\n**Final Report**: `files/reports/quantum-computing-fundamentals_YYYYMMDD-HHMMSS.md`\n```\n\n---\n\n## Why This Approach?\n\n### vs. Direct Tools (WebSearch/WebFetch)\n\n**Direct approach**:\n```\nUser: \"Tell me about quantum computing\"\n‚Üí Claude does 1-2 WebSearch calls\n‚Üí Returns summary from top results\n‚Üí Limited depth, single perspective\n```\n\n**This orchestrated approach**:\n```\nUser: \"Research quantum computing\"\n‚Üí Decomposes into 3-4 subtopics (basics, hardware, algorithms, applications)\n‚Üí Spawns 3-4 researcher agents in parallel\n‚Üí Each agent conducts focused, multi-source research\n‚Üí Report-writer synthesizes comprehensive findings\n‚Üí Cross-referenced, authoritative sources\n```\n\n**When direct tools are sufficient**: Single factual questions (\"What is X?\"), quick documentation lookups, specific URL fetches.\n\n### vs. MCP Servers\n\nThe **Model Context Protocol (MCP)**<sup>[[2]](#ref-2)</sup> is Anthropic's open standard for connecting AI systems to data sources through servers.\n\n**MCP Approach** (agent as MCP server):\n- Each agent is an **MCP server** providing tools\n- Claude Code calls MCP tools to interact with agents\n- ‚ùå **No enforced workflow** - Claude can skip decomposition or synthesis\n- ‚ùå **No architectural constraints** - relies entirely on prompts\n- ‚ùå **Agents don't coordinate** - just isolated tool calls\n- ‚ùå **No guaranteed synthesis phase**\n\n**This Orchestrated Approach**:\n- Agents are **Task subprocesses**<sup>[[3]](#ref-3)</sup> with defined roles (researcher, report-writer)\n- Orchestrator **enforces workflow phases** via `allowed-tools` constraint<sup>[[4]](#ref-4)</sup>\n- ‚úÖ **Architectural enforcement** (~95% reliability)\n- ‚úÖ **Parallel execution** - spawn all researchers simultaneously\n- ‚úÖ **Mandatory synthesis** - orchestrator physically cannot write reports (lacks Write tool)\n- ‚úÖ **Quality gates** - verify all phases complete before delivery\n\n**Example**:\n```\nMCP Approach:\nUser: \"research quantum computing\"\n‚Üí Claude calls researcher-mcp-tool (maybe)\n‚Üí Claude writes synthesis itself (no delegation enforcement)\n‚Üí May skip decomposition or parallel execution\n‚Üí Workflow depends on prompt compliance\n\nThis Approach:\nUser: \"research quantum computing\"\n‚Üí Orchestrator MUST decompose (Phase 1)\n‚Üí Orchestrator MUST spawn researchers in parallel (Phase 2)\n‚Üí Orchestrator CANNOT write synthesis - lacks Write tool (architectural constraint)\n‚Üí Orchestrator MUST delegate to report-writer agent (Phase 3)\n‚Üí Workflow enforced by architecture, not prompts\n```\n\n### vs. Sequential Research\n\n**Sequential Approach** (original SDK pattern<sup>[[5]](#ref-5)</sup>):\n- Research subtopics one-by-one\n- Total time: N √ó (research time per subtopic)\n- Example: 3 subtopics √ó 10 min each = **30 minutes**\n\n**Parallel Orchestration** (this project):\n- Research all subtopics simultaneously (Claude Code supports up to 10 parallel tasks<sup>[[6]](#ref-6)</sup>)\n- Total time: max(research times) + synthesis time\n- Example: max(10, 12, 8 min) + 3 min = **15 minutes**\n- **~30-50% faster** for typical 3-4 subtopic research<sup>[[7]](#ref-7)</sup>\n\n**Additional benefits**:\n- **Reliability**: If one researcher fails, others complete; orchestrator can retry failed subtopics\n- **Isolation**: Independent researchers can't block each other\n- **Scalability**: Performance scales with subtopic count\n\n### Architectural Benefits\n\n#### 1. Reliability Through Constraints\n\n```yaml\n# From SKILL.md frontmatter:\nallowed-tools: Task, Read, Glob, TodoWrite\n# Note: Write is deliberately excluded\n```\n\n- Orchestrator **physically cannot** bypass report-writer agent\n- Prompts can be ignored; architecture cannot\n- ~95% enforcement reliability (vs. ~20-50% for prompt-based approaches)<sup>[[4]](#ref-4)</sup>\n\n#### 2. Audit Trail & Compliance\n\nEvery tool call is logged to:\n- `transcript.txt` - human-readable session log\n- `tool_calls.jsonl` - structured JSON for analysis\n\n**Enables**:\n- Verify workflow compliance after-the-fact\n- Debug agent behavior\n- Compliance requirements (audit who did what, when)\n\n#### 3. Quality Gates\n\nBefore synthesis:\n- ‚úÖ Verify all research notes exist\n- ‚úÖ Detect violations (e.g., orchestrator writing reports)\n- ‚úÖ Fail-fast on incomplete research\n\n#### 4. Scalability\n\n- Parallel execution scales with subtopic count\n- Independent researchers reduce single points of failure\n- Synthesis happens once after all research completes\n\n### When NOT to Use\n\nThis architecture is **overkill** for:\n\n- ‚ùå Single factual questions (\"What is the capital of France?\")\n- ‚ùå Quick lookups (\"Latest version of Python?\")\n- ‚ùå Code-related tasks (\"Debug this function\", \"Write a script\")\n- ‚ùå Decision evaluation (\"Should I use React or Vue?\")\n\n**Use direct tools** (WebSearch, WebFetch) for these instead.\n\n**Use this architecture when**:\n\n- ‚úÖ Multi-source research needed (2+ authoritative sources)\n- ‚úÖ Synthesis across perspectives required\n- ‚úÖ Comprehensive coverage important\n- ‚úÖ Audit trail needed for compliance\n- ‚úÖ Quality gates required\n\n---\n\n## How It Works\n\nThe orchestrated multi-agent workflow has four enforced phases:\n\n### Phase 1: Decomposition\n\n**Orchestrator**:\n1. Analyzes user's research question\n2. Breaks topic into 2-4 focused subtopics that are:\n   - Mutually exclusive (minimal overlap)\n   - Collectively exhaustive (cover whole topic)\n   - Independently researchable\n\n**Example**:\n```\nQuery: \"Research quantum computing\"\n‚Üí Subtopics:\n  1. Theoretical foundations (qubits, superposition, entanglement)\n  2. Hardware implementations (superconducting, ion trap, topological)\n  3. Algorithms & applications (Shor's, Grover's, VQE, QAOA)\n```\n\n### Phase 2: Parallel Research\n\n**Orchestrator spawns all researchers simultaneously**:\n\n```python\n# Conceptual (actual implementation uses Task tool)\nspawn_parallel([\n    researcher(topic=\"Theoretical foundations\", context=\"quantum computing\"),\n    researcher(topic=\"Hardware implementations\", context=\"quantum computing\"),\n    researcher(topic=\"Algorithms & applications\", context=\"quantum computing\")\n])\n```\n\nEach researcher:\n- Conducts web research (WebSearch tool)\n- Gathers authoritative sources\n- Extracts key findings\n- Saves results to `files/research_notes/{subtopic-slug}.md`\n\n**Parallelism**: Claude Code supports up to 10 concurrent tasks<sup>[[6]](#ref-6)</sup>; excess tasks are queued.\n\n### Phase 3: Synthesis\n\n**‚ö†Ô∏è Architectural Enforcement Active**\n\nThe orchestrator **does not have Write tool access** (see `allowed-tools` in SKILL.md). This architectural constraint **physically prevents** the orchestrator from writing synthesis reports.\n\n**Enforced workflow**:\n1. Orchestrator verifies all research notes exist (Glob tool)\n2. Orchestrator **MUST** spawn report-writer agent (Task tool)\n3. Report-writer reads ALL research notes (Read tool)\n4. Report-writer synthesizes findings into comprehensive report\n5. Report-writer writes to `files/reports/{topic}_{timestamp}.md` (Write tool)\n\n**Cannot be bypassed**: Attempting to write reports from orchestrator results in tool permission error.\n\n### Phase 4: Delivery\n\nOrchestrator:\n1. Reads final report\n2. Creates user-facing summary with:\n   - Key findings (3-5 bullet points)\n   - Research scope (subtopics investigated)\n   - File paths (research notes + final report)\n3. Delivers to user\n\n---\n\n## Planning Workflow (New in v2.2.0)\n\nThe **spec-workflow-orchestrator** skill provides comprehensive project planning from ideation to development-ready specifications.\n\n### Trigger Keywords (90+)\n\n- \"plan\", \"design\", \"architect\", \"build\", \"create\", \"implement\"\n- \"specs\", \"requirements\", \"features\", \"PRD\", \"ADR\"\n- \"what should we build\", \"how should we structure\"\n\n### Workflow\n\n```\nUser: \"build a task tracker app\"\n    ‚Üì\n1. ANALYZE ‚Üí spec-analyst gathers requirements\n    ‚Üí User stories with acceptance criteria\n    ‚Üí Functional/non-functional requirements\n    ‚Üì\n2. ARCHITECT ‚Üí spec-architect designs system\n    ‚Üí Component architecture\n    ‚Üí Technology recommendations\n    ‚Üí Architecture Decision Records (ADRs)\n    ‚Üì\n3. PLAN ‚Üí spec-planner breaks down tasks\n    ‚Üí Implementation tasks with dependencies\n    ‚Üí Complexity estimates\n    ‚Üí Suggested implementation order\n    ‚Üì\n4. VALIDATE ‚Üí Quality gate (85% threshold)\n```\n\n### Features\n\n- **Per-Project Structure**: `docs/projects/{project-slug}/`\n- **Interactive Decision**: Detects existing projects ‚Üí New/Refine/Archive options\n- **Archive System**: Timestamped backups with integrity verification\n- **Quality Gates**: 85% threshold with up to 3 iterations\n- **State Management**: JSON-based workflow persistence\n\n### Outputs\n\n| File | Content |\n|------|---------|\n| `docs/projects/{slug}/requirements.md` | User stories, acceptance criteria |\n| `docs/projects/{slug}/architecture.md` | System design, components |\n| `docs/projects/{slug}/tasks.md` | Implementation tasks with dependencies |\n| `docs/adrs/*.md` | Architecture Decision Records |\n\n### Production Utilities\n\n```bash\n# Archive a project\n.claude/utils/archive_project.sh task-tracker-pwa\n\n# List archives\n.claude/utils/list_archives.sh task-tracker-pwa\n\n# Restore from archive\n.claude/utils/restore_archive.sh task-tracker-pwa 20251120-103602\n\n# Manage workflow state\n.claude/utils/workflow_state.sh set \"task-tracker-pwa\" \"refinement\" \"Add offline\"\n.claude/utils/workflow_state.sh get \"mode\"\n.claude/utils/workflow_state.sh show\n.claude/utils/workflow_state.sh clear\n```\n\nSee [PRODUCTION_READY_SUMMARY.md](PRODUCTION_READY_SUMMARY.md) for detailed implementation status.\n\n---\n\n## Testing\n\nThe project includes a comprehensive test suite following a 3-layer architecture for AI agent systems:\n\n| Layer | Tests | Purpose |\n|-------|-------|---------|\n| Infrastructure | 158 | Hook behavior (148), utilities (10) |\n| Behavior | 22 | Agent structure, file validation |\n| Integration | Manual | Deliverable format, ADR compliance (require skill output) |\n| Quality | Manual | Human evaluation of content quality |\n\n### Running Tests\n\n```bash\n# Layer 1: Infrastructure tests (tests/common/)\npython3 tests/common/e2e_hook_test.py\n./tests/common/test_production_implementation.sh\n\n# Layer 2: Structural validation\n./tests/common/test_agent_structure.sh\n./tests/spec-workflow/test_deliverable_structure.sh integration-test-hello-world\npython3 tests/spec-workflow/test_adr_format.py integration-test-hello-world\n\n# Integration: API-based E2E (requires ANTHROPIC_API_KEY)\npython3 tests/spec-workflow/test_skill_integration.py --dry-run   # Without API\npython3 tests/spec-workflow/test_skill_integration.py --quick     # With API\n```\n\n### Test Architecture\n\nSee [tests/TEST_ARCHITECTURE.md](tests/TEST_ARCHITECTURE.md) for detailed documentation on:\n- Why AI agents require different testing approaches\n- What can vs cannot be automated\n- Manual test evidence documentation\n\n**Total: 180 automated tests** (run without user input)\n\n---\n\n## Configuration\n\n### File Structure\n\n```\n.\n‚îú‚îÄ‚îÄ .claude/\n‚îÇ   ‚îú‚îÄ‚îÄ agents/                    # Agent definitions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ researcher.md          # Research skill\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report-writer.md       # Research skill\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spec-analyst.md        # Planning skill (v2.2.0)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spec-architect.md      # Planning skill (v2.2.0)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spec-planner.md        # Planning skill (v2.2.0)\n‚îÇ   ‚îú‚îÄ‚îÄ commands/                  # Slash commands (v2.2.0)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plan-feature.md\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project-status.md\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ research-topic.md\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verify-structure.md\n‚îÇ   ‚îú‚îÄ‚îÄ hooks/                     # Python hook scripts\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user-prompt-submit.py  # Universal skill activation (v2.2.0)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session-start.py\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ post-tool-use-track-research.py\n‚îÇ   ‚îú‚îÄ‚îÄ skills/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multi-agent-researcher/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spec-workflow-orchestrator/  # (v2.2.0)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ skill-rules.json       # Trigger configuration\n‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Production utilities (v2.2.0)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ archive_project.sh\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ restore_archive.sh\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ list_archives.sh\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workflow_state.sh\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ detect_next_version.sh\n‚îÇ   ‚îú‚îÄ‚îÄ settings.json              # Hooks configuration (committed)\n‚îÇ   ‚îú‚îÄ‚îÄ settings.local.json        # User overrides (gitignored)\n‚îÇ   ‚îî‚îÄ‚îÄ config.json                # Path & research configuration\n‚îú‚îÄ‚îÄ files/\n‚îÇ   ‚îú‚îÄ‚îÄ research_notes/            # Individual researcher outputs\n‚îÇ   ‚îî‚îÄ‚îÄ reports/                   # Synthesis reports\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îú‚îÄ‚îÄ projects/                  # Planning outputs (v2.2.0)\n‚îÇ   ‚îî‚îÄ‚îÄ adrs/                      # Architecture Decision Records (v2.2.0)\n‚îú‚îÄ‚îÄ logs/                          # Session logs + state\n‚îÇ   ‚îú‚îÄ‚îÄ session_*_{transcript,tool_calls,state}.*\n‚îÇ   ‚îî‚îÄ‚îÄ state/current.json         # Active skill pointer\n‚îî‚îÄ‚îÄ setup.py                       # Interactive setup script\n```\n\n### File & Directory Reference\n\nComplete reference of all files and their roles:\n\n| File/Directory | Purpose | Type | User Action |\n|----------------|---------|------|-------------|\n| **Core Skill Files** | | | |\n| `.claude/skills/multi-agent-researcher/SKILL.md` | Skill definition with `allowed-tools` constraint that enforces workflow | Skill Definition | View/Customize |\n| `.claude/skills/spec-workflow-orchestrator/SKILL.md` | Planning orchestrator (v2.2.0) | Skill Definition | View/Customize |\n| `.claude/agents/researcher.md` | Instructions for researcher agents (web research, note-taking) | Agent Definition | View/Customize |\n| `.claude/agents/report-writer.md` | Instructions for report-writer agent (synthesis, cross-referencing) | Agent Definition | View/Customize |\n| `.claude/agents/spec-analyst.md` | Requirements gathering (v2.2.0) | Agent Definition | View/Customize |\n| `.claude/agents/spec-architect.md` | System design (v2.2.0) | Agent Definition | View/Customize |\n| `.claude/agents/spec-planner.md` | Task breakdown (v2.2.0) | Agent Definition | View/Customize |\n| **Hook System (Enforcement & Tracking)** | | | |\n| `.claude/hooks/user-prompt-submit.py` | Universal skill activation (v2.2.0) | Hook Script | Advanced Only |\n| `.claude/hooks/post-tool-use-track-research.py` | Logs every tool call, identifies agents, enforces quality gates | Hook Script | Advanced Only |\n| `.claude/hooks/session-start.py` | Auto-creates directories, restores sessions, displays status | Hook Script | Advanced Only |\n| `.claude/settings.json` | Registers hooks with Claude Code (committed to repo) | Settings | Caution |\n| `.claude/settings.local.json` | User-specific overrides (gitignored, optional) | Settings | Optional |\n| **Configuration & State** | | | |\n| `.claude/config.json` | Paths, logging settings, research parameters | Config | Customize |\n| `logs/state/current.json` | Active skill pointer for dual-skill routing (~100 bytes) | State | Auto-Generated |\n| `logs/session_*_state.json` | Per-session history: skill invocations (both skills) | State | Auto-Generated |\n| `.claude/skills/skill-rules.json` | Trigger patterns for skill activation | Config | View |\n| **Data Outputs** | | | |\n| `files/research_notes/*.md` | Individual researcher findings (one file per subtopic) | Research Data | Auto-Generated |\n| `files/reports/*.md` | Comprehensive synthesis reports (timestamped) | Final Reports | Auto-Generated |\n| `docs/projects/{slug}/*.md` | Planning deliverables (v2.2.0) | Planning Data | Auto-Generated |\n| `docs/adrs/*.md` | Architecture Decision Records (v2.2.0) | Planning Data | Auto-Generated |\n| **Logs & Audit Trail** | | | |\n| `logs/session_*_transcript.txt` | Human-readable session log with agent identification | Log | Auto-Generated |\n| `logs/session_*_tool_calls.jsonl` | Structured JSON log for programmatic analysis | Log | Auto-Generated |\n| `logs/session_*_state.json` | Session skill invocations and research sessions | Log | Auto-Generated |\n| **Utilities** | | | |\n| `setup.py` | Interactive configuration wizard for advanced customization | Setup Script | Run When Needed |\n| `.claude/utils/*.sh` | Production utilities for planning (v2.2.0) | Scripts | Run When Needed |\n\n**Key**:\n- **View**: Read to understand how system works\n- **Customize**: Safe to edit for your needs\n- **Advanced Only**: Don't edit unless you understand hook system deeply\n- **Caution**: Edit carefully; incorrect changes can break functionality\n- **Auto-Generated**: Created/updated by system; don't edit manually\n- **Optional**: Only create if you need user-specific overrides\n\n### Default Paths\n\nConfigured in `.claude/config.json`:\n\n```json\n{\n  \"paths\": {\n    \"research_notes\": \"files/research_notes\",\n    \"reports\": \"files/reports\",\n    \"logs\": \"logs\",\n    \"state\": \"logs/state\"\n  },\n  \"logging\": {\n    \"enabled\": true,\n    \"format\": \"flat\",\n    \"log_tool_calls\": true\n  },\n  \"research\": {\n    \"max_parallel_researchers\": 4,\n    \"require_synthesis_delegation\": true,\n    \"quality_gates_enabled\": true\n  }\n}\n```\n\n### Environment Variables\n\nOverride paths without editing config:\n\n```bash\nexport RESEARCH_NOTES_DIR=/custom/path/notes\nexport REPORTS_DIR=/custom/path/reports\nexport LOGS_DIR=/custom/path/logs\n```\n\nThen restart Claude Code.\n\n### Advanced Setup\n\nFor custom configuration:\n\n```bash\npython3 setup.py           # Interactive setup with prompts\npython3 setup.py --verify  # Check setup without changes\npython3 setup.py --repair  # Auto-fix issues\n```\n\nThe setup script allows you to:\n- Customize directory paths\n- Configure max parallel researchers (1-10)\n- Verify Python version and hooks\n- Check for missing files or directories\n\n**‚ö†Ô∏è Important**: If you create `settings.local.json`, **remove the `hooks` section** from it. Hooks are already configured in `settings.json` and duplicating them will cause duplicate hook executions.\n\n---\n\n## Architecture Deep Dive\n\n### Comparison to Reference SDK\n\nThis project adapts the multi-agent research pattern from [Anthropic's research-agent demo](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent)<sup>[[5]](#ref-5)</sup> for Claude Code's skill system.\n\n| Feature | Reference (Python SDK) | This Project (Claude Code) |\n|---------|------------------------|----------------------------|\n| **Platform** | Python Agent SDK (standalone) | **Claude Code Skill** (integrated) |\n| **Hooks** | Python SDK hooks (`HookMatcher`) | Shell-based hooks (Python scripts) |\n| **Enforcement** | Behavioral (via prompts) | **Architectural** (via `allowed-tools` ~95% reliability)<sup>[[4]](#ref-4)</sup> |\n| **Logging** | SDK-managed with `parent_tool_use_id` | **Custom hooks with heuristic agent detection** |\n| **Agent Identification** | SDK's `parent_tool_use_id` field | **File path + tool usage heuristics** |\n| **Configuration** | Python code | **JSON config + environment variables** |\n| **Deployment** | Standalone Python app | **Claude Code skill + hooks** |\n| **Session Logs** | Nested directories | **Flat structure** (configurable) |\n| **Setup** | Manual installation | **Automatic first-time setup** |\n\n**Use Reference Implementation If**:\n- Building standalone Python application\n- Need SDK's native hook system\n- Want official Anthropic patterns without modification\n\n**Use This Implementation If**:\n- Using Claude Code as primary environment\n- Need workflow enforcement via architecture\n- Require audit logging for compliance\n- Want configuration flexibility (JSON + env vars)\n\n### Enforcement Mechanisms\n\n#### 1. `allowed-tools` Constraint\n\nFrom `.claude/skills/multi-agent-researcher/SKILL.md`:\n\n```yaml\n---\nname: multi-agent-researcher\nallowed-tools: Task, Read, Glob, TodoWrite\n---\n```\n\nWhen this skill is active, Claude can **only** use the listed tools<sup>[[4]](#ref-4)</sup>. The Write tool is deliberately excluded, making it **architecturally impossible** for the orchestrator to write synthesis reports.\n\n**Reliability**: ~95% (cannot be bypassed through prompt injection).\n\nFrom `.claude/skills/spec-workflow-orchestrator/SKILL.md`:\n\n```yaml\n---\nname: spec-workflow-orchestrator\nallowed-tools: Task, Read, Glob, TodoWrite, Write, Edit\n---\n```\n\nSpec skill **has Write access** - enforcement is via quality gates (85% threshold), not tool restriction. Orchestrator delegates to spec-analyst ‚Üí spec-architect ‚Üí spec-planner sequentially, validating each deliverable before proceeding.\n\n#### 2. Quality Gates\n\n**Research Skill** - Implemented in hooks:\n\n```python\n# Detect orchestrator bypassing report-writer\nif synthesis_phase and tool == \"Write\" and agent == \"orchestrator\":\n    violation = \"Orchestrator attempted to write synthesis report\"\n    log_violation(violation)\n```\n\n**Spec Skill** - 85% threshold scoring (100 points total):\n\n| Criteria | Points | Applies To |\n|----------|--------|------------|\n| Completeness | 25 | All deliverables |\n| Technical Depth | 25 | Architecture, ADRs |\n| Actionability | 25 | Tasks, requirements |\n| Clarity | 25 | All deliverables |\n\nMax 3 iterations per agent. Below threshold ‚Üí feedback loop ‚Üí retry.\n\n#### 3. Session State Tracking\n\nTracks active skill and workflow progression for the **dual-skill platform**.\n\n**Current State** (`logs/state/current.json` ~100 bytes):\n- `currentSkill`: Which skill is active (multi-agent-researcher **or** spec-workflow-orchestrator)\n- `currentResearch`: Active research session details (if research skill)\n\n**Session History** (`logs/session_*_state.json`):\n- `skillInvocations[]`: All skill activations this session (both skills)\n- `researchSessions[]`: Completed research sessions\n\n**Enables**:\n- **Routing**: Hooks check `currentSkill` before activating another skill\n- **Restoration**: Resume interrupted workflows (either skill)\n- **Audit**: Track all skill usage across sessions\n\n**Why Split Architecture?** Claude Code's Read tool has 25K token limit. A single persistent file would fail at ~359 skill invocations. Split keeps `current.json` tiny (~100 bytes) while session files are bounded per-session.\n\n### Hooks Architecture\n\nThe hook system is the **foundation of enforcement and tracking**. Without hooks, this system wouldn't work‚Äî`allowed-tools` constraints prevent unauthorized actions, but hooks provide logging, quality gates, and session management.\n\n#### How Hooks Work\n\nClaude Code fires hooks at specific lifecycle events:\n- **UserPromptSubmit**: Before processing user prompt (v2.2.0)\n- **PostToolUse**: After every tool call (Read, Write, Task, WebSearch, etc.)\n- **SessionStart**: When Claude Code session begins\n\nOur hooks are registered in `.claude/settings.json`:\n\n```json\n{\n  \"hooks\": {\n    \"UserPromptSubmit\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/user-prompt-submit.py\\\"\"\n      }]\n    }],\n    \"PostToolUse\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/post-tool-use-track-research.py\\\"\"\n      }]\n    }],\n    \"SessionStart\": [{\n      \"hooks\": [{\n        \"type\": \"command\",\n        \"command\": \"python3 \\\"$CLAUDE_PROJECT_DIR/.claude/hooks/session-start.py\\\"\"\n      }]\n    }]\n  }\n}\n```\n\n#### UserPromptSubmit Hook (v2.2.0)\n\n**Runs BEFORE every user prompt is processed** to enforce skill activation.\n\n**Responsibilities**:\n1. Detects research triggers (37+ keywords, 15 patterns)\n2. Detects planning triggers (90+ keywords, 23 patterns)\n3. Injects enforcement reminders into Claude's context\n\n#### PostToolUse Hook (`post-tool-use-track-research.py`)\n\n**Runs after EVERY tool call** to provide comprehensive tracking and enforcement.\n\n**Responsibilities**:\n\n1. **Agent Identification**\n   ```python\n   # Heuristics to identify which agent made the call\n   if tool == \"Task\" and \"subagent_type\" in input:\n       agent = \"orchestrator\"\n   elif file_path.startswith(\"files/research_notes/\"):\n       agent = \"researcher\"\n   elif file_path.startswith(\"files/reports/\"):\n       agent = \"report-writer\"\n   ```\n\n2. **Logging**\n   - Appends to `transcript.txt` with human-readable format\n   - Appends to `tool_calls.jsonl` with structured JSON\n   - Includes: timestamp, agent, tool, input, output, duration\n\n3. **Quality Gate Enforcement**\n   ```python\n   # Detect workflow violations\n   if synthesis_phase and tool == \"Write\" and agent == \"orchestrator\":\n       violation = \"Orchestrator attempted synthesis (should use report-writer)\"\n       log_violation(violation)\n   ```\n\n4. **Skill & Phase Tracking**\n   - Updates `logs/state/current.json` with active skill\n   - Writes completed skills to `logs/session_*_state.json`\n   - **Research**: decomposition ‚Üí parallel research ‚Üí synthesis ‚Üí delivery\n   - **Planning**: analyze ‚Üí architect ‚Üí plan ‚Üí validate (quality gate)\n\n**Example log entry**:\n```\n[10:57:22] ORCHESTRATOR ‚Üí Task ‚úÖ\n  Input: {\"subagent_type\": \"researcher\", \"description\": \"Research quantum computing\"}\n  Output: Success (2.4 KB)\n  Duration: 1250ms\n```\n\n#### SessionStart Hook (`session-start.py`)\n\n**Runs once when Claude Code session begins**.\n\n**Responsibilities**:\n\n1. **Auto-Setup**\n   ```python\n   # Create directories if missing\n   create_directory(\"files/research_notes/\")\n   create_directory(\"files/reports/\")\n   create_directory(\"logs/\")\n   create_directory(\"logs/state/\")\n   ```\n\n2. **Session Initialization**\n   - Generates unique session ID (e.g., `session_20251118_105714`)\n   - Creates log files (`transcript.txt`, `tool_calls.jsonl`, `state.json`)\n   - Displays setup status to user\n\n3. **Session Restoration** (if previous session was interrupted)\n   - Reads `logs/state/current.json` for active skill\n   - Detects incomplete research **or** planning workflows\n   - Offers to resume or start fresh\n\n**Example output**:\n```\nüìù Session logs initialized: logs/session_20251118_105714_{transcript.txt,tool_calls.jsonl,state.json}\n‚úÖ All directories exist\n‚úÖ Hooks configured correctly\n```\n\n#### Hook + Constraint Synergy\n\nThe **combination** of hooks and `allowed-tools` creates robust enforcement:\n\n| Component | Role | Reliability |\n|-----------|------|-------------|\n| `allowed-tools: Task, Read, Glob, TodoWrite` | **Prevents** orchestrator from writing reports | ~95% (architectural) |\n| PostToolUse quality gates | **Detects** if violation somehow occurs | ~100% (catches everything) |\n| Session state tracking | **Verifies** all workflow phases complete | ~100% (checks existence) |\n\n**Together**: ~99%+ enforcement reliability with full audit trail.\n\n#### Hook Execution Flow\n\n```\nUser: \"research quantum computing\"\n    ‚Üì\nUserPromptSubmit hook fires (v2.2.0)\n    ‚Üí Detects research trigger\n    ‚Üí Injects skill enforcement reminder\n    ‚Üì\nSessionStart hook fires\n    ‚Üí Creates directories\n    ‚Üí Initializes session logs\n    ‚Üí Displays status\n    ‚Üì\nOrchestrator decomposes query\n    ‚Üì\nOrchestrator spawns researchers (Task tool)\n    ‚Üì PostToolUse hook fires\n        ‚Üí Identifies agent: orchestrator\n        ‚Üí Logs: Task call\n        ‚Üí Updates phase: research (in progress)\n    ‚Üì\nEach researcher conducts research (WebSearch, Write tools)\n    ‚Üì PostToolUse hook fires (multiple times)\n        ‚Üí Identifies agent: researcher (via file path heuristic)\n        ‚Üí Logs: WebSearch + Write calls\n        ‚Üí Tracks: research note paths\n    ‚Üì\nAll researchers complete\n    ‚Üì\nOrchestrator spawns report-writer (Task tool)\n    ‚Üì PostToolUse hook fires\n        ‚Üí Identifies agent: orchestrator\n        ‚Üí Logs: Task call\n        ‚Üí Updates phase: synthesis (in progress)\n    ‚Üì\nReport-writer synthesizes (Read, Write tools)\n    ‚Üì PostToolUse hook fires (multiple times)\n        ‚Üí Identifies agent: report-writer (via file path heuristic)\n        ‚Üí Logs: Read + Write calls\n        ‚Üí Updates phase: synthesis (complete)\n    ‚Üì\nSession ends\n    ‚Üì\nAll tool calls logged ‚úÖ\nAll phases tracked ‚úÖ\nAudit trail complete ‚úÖ\n```\n\n**Same pattern for Planning Skill**: Replace \"research X\" ‚Üí \"plan X\", researchers ‚Üí spec-analyst/architect/planner, report-writer ‚Üí quality gate validation. State tracks `currentSkill: spec-workflow-orchestrator`.\n\n**Without hooks**: `allowed-tools` would prevent violations, but you'd have no logs, no tracking, no session management, no quality gate verification.\n\n**With hooks**: Complete observability + enforcement + automation.\n\n### Session Logging\n\n#### Log Format: Flat Structure\n\n```\nlogs/\n‚îú‚îÄ‚îÄ session_20251118_105714_transcript.txt      # Human-readable\n‚îú‚îÄ‚îÄ session_20251118_105714_tool_calls.jsonl    # Structured JSON\n‚îú‚îÄ‚îÄ session_20251118_105714_state.json          # Session skill/research history\n‚îî‚îÄ‚îÄ state/\n    ‚îî‚îÄ‚îÄ current.json                            # Active skill pointer (~100 bytes)\n```\n\n**Benefits of flat structure**:\n- Easier navigation (no nested directories)\n- Simpler programmatic analysis (`grep`, `jq`)\n- Compatible with log aggregation tools\n\n#### transcript.txt Example\n\n```\nResearch Agent Session Log\nSession ID: session_20251118_105714\nStarted: 2025-11-18T10:57:14.369265\n================================================================================\n\n[10:57:22] ORCHESTRATOR ‚Üí Task ‚úÖ\n  Input: {\"subagent_type\": \"researcher\", \"description\": \"Research theoretical foundations\", ...}\n  Output: Success (2.4 KB)\n  Duration: 1250ms\n\n[10:58:45] RESEARCHER ‚Üí WebSearch ‚úÖ\n  Input: {\"query\": \"quantum computing qubits superposition\"}\n  Output: Found 10 results\n  Duration: 850ms\n\n[11:02:10] ORCHESTRATOR ‚Üí Task ‚úÖ\n  Input: {\"subagent_type\": \"report-writer\", ...}\n  Output: Success (15.2 KB)\n  Duration: 3400ms\n```\n\n#### Agent Identification Heuristics\n\nSince Claude Code doesn't provide `parent_tool_use_id` (SDK feature), agents are identified via:\n\n1. **File paths**: Writing to `files/research_notes/` ‚Üí researcher; `files/reports/` ‚Üí report-writer\n2. **Tool usage**: Task tool with `subagent_type` ‚Üí orchestrator\n3. **Session phase**: During synthesis + WebSearch ‚Üí researcher\n\n**Accuracy**: ~90% (trade-off for not requiring SDK).\n\n---\n\n## Inspiration & Credits\n\nThis project adapts the multi-agent research pattern for Claude Code's skill system, combining patterns from multiple production-proven projects:\n\n### Primary Inspiration\n\n- **[claude-agent-sdk-demos/research-agent](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent)** by Anthropic PBC<sup>[[5]](#ref-5)</sup>\n  - Multi-agent research orchestration concept\n  - Decomposition ‚Üí Research ‚Üí Synthesis workflow\n  - Session logging patterns\n  - License: Apache-2.0\n\n### Workflow Patterns\n\n- **[DevFlow](https://github.com/mathewtaylor/devflow)** by Mathew Taylor<sup>[[8]](#ref-8)</sup>\n  - Architectural enforcement via `allowed-tools` constraint\n  - State tracking with `state.json`\n  - Quality gates for phase validation\n  - License: MIT\n\n- **[Claude-Flow](https://github.com/ruvnet/claude-flow)** by ruvnet<sup>[[9]](#ref-9)</sup>\n  - Session persistence patterns\n  - Research session restoration\n  - License: MIT\n\n- **[TDD-Guard](https://github.com/nizos/tdd-guard)** by nizos<sup>[[10]](#ref-10)</sup>\n  - Agent tracking via tool usage patterns\n  - Multi-context workflow enforcement\n  - License: MIT\n\n- **[claude-code-infrastructure-showcase](https://github.com/diet103/claude-code-infrastructure-showcase)** by diet103<sup>[[11]](#ref-11)</sup>\n  - Skill auto-activation patterns\n  - `skill-rules.json` configuration\n  - License: MIT\n\nAll projects are MIT or Apache-2.0 licensed and used in compliance with their terms.\n\n---\n\n## Author & Acknowledgments\n\n**Created by Ahmed Maged**\nGitHub: [@ahmedibrahim085](https://github.com/ahmedibrahim085)\n\nThis project was conceived, architected, and guided at every step by Ahmed Maged. Implementation was assisted by Claude Code, but all architectural decisions, design choices, and strategic direction came from the author.\n\n**Special Acknowledgments**:\n- Anthropic team for the [claude-agent-sdk-demos/research-agent](https://github.com/anthropics/claude-agent-sdk-demos/tree/main/research-agent) inspiration\n- Authors of DevFlow, Claude-Flow, TDD-Guard, and Infrastructure Showcase for proven workflow patterns\n- Claude Code community for feature requests and feedback\n\n---\n\n## License\n\nThis project is licensed under the **Apache License 2.0** - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## References\n\n<a id=\"ref-1\"></a>**[1]** Anthropic. \"Introducing Agent Skills.\" Anthropic News, October 16, 2025. https://www.anthropic.com/news/skills\n\n<a id=\"ref-2\"></a>**[2]** Anthropic. \"Introducing the Model Context Protocol.\" Anthropic News, November 2024. https://www.anthropic.com/news/model-context-protocol\n\n<a id=\"ref-3\"></a>**[3]** Anthropic. \"Agent Skills - Claude Code Docs.\" Accessed November 2025. https://code.claude.com/docs/en/skills\n\n<a id=\"ref-4\"></a>**[4]** Willison, Simon. \"Claude Skills are awesome, maybe a bigger deal than MCP.\" Simon Willison's Weblog, October 16, 2025. https://simonwillison.net/2025/Oct/16/claude-skills/\n\n<a id=\"ref-5\"></a>**[5]** Anthropic. \"How we built our multi-agent research system.\" Anthropic Engineering Blog, 2025. https://www.anthropic.com/engineering/multi-agent-research-system\n\n<a id=\"ref-6\"></a>**[6]** \"Multi-Agent Orchestration: Running 10+ Claude Instances in Parallel (Part 3).\" DEV Community, 2025. https://dev.to/bredmond1019/multi-agent-orchestration-running-10-claude-instances-in-parallel-part-3-29da\n\n<a id=\"ref-7\"></a>**[7]** Greyling, Cobus. \"Orchestrating Parallel AI Agents.\" Medium, 2025. https://cobusgreyling.medium.com/orchestrating-parallel-ai-agents-dab96e5f2e61\n\n<a id=\"ref-8\"></a>**[8]** Taylor, Mathew. \"DevFlow - Agentic Feature Management.\" GitHub Repository. https://github.com/mathewtaylor/devflow\n\n<a id=\"ref-9\"></a>**[9]** ruvnet. \"Claude-Flow - Agent Orchestration Platform.\" GitHub Repository. https://github.com/ruvnet/claude-flow\n\n<a id=\"ref-10\"></a>**[10]** nizos. \"TDD-Guard - TDD Enforcement for Claude Code.\" GitHub Repository. https://github.com/nizos/tdd-guard\n\n<a id=\"ref-11\"></a>**[11]** diet103. \"Claude Code Infrastructure Showcase.\" GitHub Repository. https://github.com/diet103/claude-code-infrastructure-showcase\n\n---\n\n**‚≠ê Star this repo** if you find it useful!\n",
  "installCommand": "git clone https://github.com/ahmedibrahim085/Claude-Multi-Agent-Research-System-Skill ~/.claude/skills/multi-agent-research-system",
  "defaultBranch": "main",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}