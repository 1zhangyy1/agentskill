{
  "id": "4b74aafeb6e45268",
  "slug": "skill-seekers",
  "name": "Skill_Seekers",
  "description": "Convert documentation websites, GitHub repositories, and PDFs into Claude AI skills with automatic conflict detection",
  "author": "yusufkaraaslan",
  "authorAvatar": "https://avatars.githubusercontent.com/u/11597362?v=4",
  "repoUrl": "https://github.com/yusufkaraaslan/Skill_Seekers",
  "repoFullName": "yusufkaraaslan/Skill_Seekers",
  "stars": 5189,
  "forks": 546,
  "category": "automation",
  "categories": [
    "automation"
  ],
  "tags": [
    "ai-tools",
    "ast-parser",
    "automation",
    "claude-ai",
    "claude-skills",
    "code-analysis",
    "conflict-detection",
    "documentation",
    "documentation-generator",
    "github",
    "github-scraper",
    "mcp",
    "mcp-server",
    "multi-source",
    "ocr",
    "pdf",
    "python",
    "web-scraping"
  ],
  "tier": 1,
  "status": "active",
  "createdAt": "2025-10-17T14:43:48Z",
  "updatedAt": "2025-12-19T03:02:18Z",
  "lastCommitAt": "2025-11-30T17:45:32Z",
  "source": "github-topic",
  "collectedAt": "2025-12-19T03:37:15.086Z",
  "authorUrl": "https://github.com/yusufkaraaslan",
  "license": "MIT",
  "readme": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/yusufkaraaslan-skill-seekers-badge.png)](https://mseep.ai/app/yusufkaraaslan-skill-seekers)\n\n# Skill Seeker\n\n[![Version](https://img.shields.io/badge/version-2.1.1-blue.svg)](https://github.com/yusufkaraaslan/Skill_Seekers/releases/tag/v2.1.1)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)\n[![MCP Integration](https://img.shields.io/badge/MCP-Integrated-blue.svg)](https://modelcontextprotocol.io)\n[![Tested](https://img.shields.io/badge/Tests-427%20Passing-brightgreen.svg)](tests/)\n[![Project Board](https://img.shields.io/badge/Project-Board-purple.svg)](https://github.com/users/yusufkaraaslan/projects/2)\n[![PyPI version](https://badge.fury.io/py/skill-seekers.svg)](https://pypi.org/project/skill-seekers/)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/skill-seekers.svg)](https://pypi.org/project/skill-seekers/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/skill-seekers.svg)](https://pypi.org/project/skill-seekers/)\n\n**Automatically convert documentation websites, GitHub repositories, and PDFs into Claude AI skills in minutes.**\n\n> üìã **[View Development Roadmap & Tasks](https://github.com/users/yusufkaraaslan/projects/2)** - 134 tasks across 10 categories, pick any to contribute!\n\n## What is Skill Seeker?\n\nSkill Seeker is an automated tool that transforms documentation websites, GitHub repositories, and PDF files into production-ready [Claude AI skills](https://www.anthropic.com/news/skills). Instead of manually reading and summarizing documentation, Skill Seeker:\n\n1. **Scrapes** multiple sources (docs, GitHub repos, PDFs) automatically\n2. **Analyzes** code repositories with deep AST parsing\n3. **Detects** conflicts between documentation and code implementation\n4. **Organizes** content into categorized reference files\n5. **Enhances** with AI to extract best examples and key concepts\n6. **Packages** everything into an uploadable `.zip` file for Claude\n\n**Result:** Get comprehensive Claude skills for any framework, API, or tool in 20-40 minutes instead of hours of manual work.\n\n## Why Use This?\n\n- üéØ **For Developers**: Create skills from documentation + GitHub repos with conflict detection\n- üéÆ **For Game Devs**: Generate skills for game engines (Godot docs + GitHub, Unity, etc.)\n- üîß **For Teams**: Combine internal docs + code repositories into single source of truth\n- üìö **For Learners**: Build comprehensive skills from docs, code examples, and PDFs\n- üîç **For Open Source**: Analyze repos to find documentation gaps and outdated examples\n\n## Key Features\n\n### üåê Documentation Scraping\n- ‚úÖ **llms.txt Support** - Automatically detects and uses LLM-ready documentation files (10x faster)\n- ‚úÖ **Universal Scraper** - Works with ANY documentation website\n- ‚úÖ **Smart Categorization** - Automatically organizes content by topic\n- ‚úÖ **Code Language Detection** - Recognizes Python, JavaScript, C++, GDScript, etc.\n- ‚úÖ **8 Ready-to-Use Presets** - Godot, React, Vue, Django, FastAPI, and more\n\n### üìÑ PDF Support (**v1.2.0**)\n- ‚úÖ **Basic PDF Extraction** - Extract text, code, and images from PDF files\n- ‚úÖ **OCR for Scanned PDFs** - Extract text from scanned documents\n- ‚úÖ **Password-Protected PDFs** - Handle encrypted PDFs\n- ‚úÖ **Table Extraction** - Extract complex tables from PDFs\n- ‚úÖ **Parallel Processing** - 3x faster for large PDFs\n- ‚úÖ **Intelligent Caching** - 50% faster on re-runs\n\n### üêô GitHub Repository Scraping (**v2.0.0**)\n- ‚úÖ **Deep Code Analysis** - AST parsing for Python, JavaScript, TypeScript, Java, C++, Go\n- ‚úÖ **API Extraction** - Functions, classes, methods with parameters and types\n- ‚úÖ **Repository Metadata** - README, file tree, language breakdown, stars/forks\n- ‚úÖ **GitHub Issues & PRs** - Fetch open/closed issues with labels and milestones\n- ‚úÖ **CHANGELOG & Releases** - Automatically extract version history\n- ‚úÖ **Conflict Detection** - Compare documented APIs vs actual code implementation\n- ‚úÖ **MCP Integration** - Natural language: \"Scrape GitHub repo facebook/react\"\n\n### üîÑ Unified Multi-Source Scraping (**NEW - v2.0.0**)\n- ‚úÖ **Combine Multiple Sources** - Mix documentation + GitHub + PDF in one skill\n- ‚úÖ **Conflict Detection** - Automatically finds discrepancies between docs and code\n- ‚úÖ **Intelligent Merging** - Rule-based or AI-powered conflict resolution\n- ‚úÖ **Transparent Reporting** - Side-by-side comparison with ‚ö†Ô∏è warnings\n- ‚úÖ **Documentation Gap Analysis** - Identifies outdated docs and undocumented features\n- ‚úÖ **Single Source of Truth** - One skill showing both intent (docs) and reality (code)\n- ‚úÖ **Backward Compatible** - Legacy single-source configs still work\n\n### ü§ñ AI & Enhancement\n- ‚úÖ **AI-Powered Enhancement** - Transforms basic templates into comprehensive guides\n- ‚úÖ **No API Costs** - FREE local enhancement using Claude Code Max\n- ‚úÖ **MCP Server for Claude Code** - Use directly from Claude Code with natural language\n\n### ‚ö° Performance & Scale\n- ‚úÖ **Async Mode** - 2-3x faster scraping with async/await (use `--async` flag)\n- ‚úÖ **Large Documentation Support** - Handle 10K-40K+ page docs with intelligent splitting\n- ‚úÖ **Router/Hub Skills** - Intelligent routing to specialized sub-skills\n- ‚úÖ **Parallel Scraping** - Process multiple skills simultaneously\n- ‚úÖ **Checkpoint/Resume** - Never lose progress on long scrapes\n- ‚úÖ **Caching System** - Scrape once, rebuild instantly\n\n### ‚úÖ Quality Assurance\n- ‚úÖ **Fully Tested** - 391 tests with comprehensive coverage\n\n---\n\n## üì¶ Now Available on PyPI!\n\n**Skill Seekers is now published on the Python Package Index!** Install with a single command:\n\n```bash\npip install skill-seekers\n```\n\nGet started in seconds. No cloning, no setup - just install and run. See installation options below.\n\n---\n\n## Quick Start\n\n### Option 1: Install from PyPI (Recommended)\n\n```bash\n# Install from PyPI (easiest method!)\npip install skill-seekers\n\n# Use the unified CLI\nskill-seekers scrape --config configs/react.json\nskill-seekers github --repo facebook/react\nskill-seekers enhance output/react/\nskill-seekers package output/react/\n```\n\n**Time:** ~25 minutes | **Quality:** Production-ready | **Cost:** Free\n\nüìñ **New to Skill Seekers?** Check out our [Quick Start Guide](QUICKSTART.md) or [Bulletproof Guide](BULLETPROOF_QUICKSTART.md)\n\n### Option 2: Install via uv (Modern Python Tool)\n\n```bash\n# Install with uv (fast, modern alternative)\nuv tool install skill-seekers\n\n# Or run directly without installing\nuv tool run --from skill-seekers skill-seekers scrape --config https://raw.githubusercontent.com/yusufkaraaslan/Skill_Seekers/main/configs/react.json\n\n# Unified CLI - simple commands\nskill-seekers scrape --config configs/react.json\nskill-seekers github --repo facebook/react\nskill-seekers package output/react/\n```\n\n**Time:** ~25 minutes | **Quality:** Production-ready | **Cost:** Free\n\n### Option 3: Development Install (From Source)\n\n```bash\n# Clone and install in editable mode\ngit clone https://github.com/yusufkaraaslan/Skill_Seekers.git\ncd Skill_Seekers\npip install -e .\n\n# Use the unified CLI\nskill-seekers scrape --config configs/react.json\n```\n\n### Option 4: Use from Claude Code (MCP Integration)\n\n```bash\n# One-time setup (5 minutes)\n./setup_mcp.sh\n\n# Then in Claude Code, just ask:\n\"Generate a React skill from https://react.dev/\"\n\"Scrape PDF at docs/manual.pdf and create skill\"\n```\n\n**Time:** Automated | **Quality:** Production-ready | **Cost:** Free\n\n### Option 5: Legacy CLI (Backwards Compatible)\n\n```bash\n# Install dependencies\npip3 install requests beautifulsoup4\n\n# Run scripts directly (old method)\npython3 src/skill_seekers/cli/doc_scraper.py --config configs/react.json\n\n# Upload output/react.zip to Claude - Done!\n```\n\n**Time:** ~25 minutes | **Quality:** Production-ready | **Cost:** Free\n\n## Usage Examples\n\n### Documentation Scraping\n\n```bash\n# Scrape documentation website\nskill-seekers scrape --config configs/react.json\n\n# Quick scrape without config\nskill-seekers scrape --url https://react.dev --name react\n\n# With async mode (3x faster)\nskill-seekers scrape --config configs/godot.json --async --workers 8\n```\n\n### PDF Extraction\n\n```bash\n# Basic PDF extraction\nskill-seekers pdf --pdf docs/manual.pdf --name myskill\n\n# Advanced features\nskill-seekers pdf --pdf docs/manual.pdf --name myskill \\\n    --extract-tables \\        # Extract tables\n    --parallel \\              # Fast parallel processing\n    --workers 8               # Use 8 CPU cores\n\n# Scanned PDFs (requires: pip install pytesseract Pillow)\nskill-seekers pdf --pdf docs/scanned.pdf --name myskill --ocr\n\n# Password-protected PDFs\nskill-seekers pdf --pdf docs/encrypted.pdf --name myskill --password mypassword\n```\n\n**Time:** ~5-15 minutes (or 2-5 minutes with parallel) | **Quality:** Production-ready | **Cost:** Free\n\n### GitHub Repository Scraping\n\n```bash\n# Basic repository scraping\nskill-seekers github --repo facebook/react\n\n# Using a config file\nskill-seekers github --config configs/react_github.json\n\n# With authentication (higher rate limits)\nexport GITHUB_TOKEN=ghp_your_token_here\nskill-seekers github --repo facebook/react\n\n# Customize what to include\nskill-seekers github --repo django/django \\\n    --include-issues \\        # Extract GitHub Issues\n    --max-issues 100 \\        # Limit issue count\n    --include-changelog \\     # Extract CHANGELOG.md\n    --include-releases        # Extract GitHub Releases\n```\n\n**Time:** ~5-10 minutes | **Quality:** Production-ready | **Cost:** Free\n\n### Unified Multi-Source Scraping (**NEW - v2.0.0**)\n\n**The Problem:** Documentation and code often drift apart. Docs might be outdated, missing features that exist in code, or documenting features that were removed.\n\n**The Solution:** Combine documentation + GitHub + PDF into one unified skill that shows BOTH what's documented AND what actually exists, with clear warnings about discrepancies.\n\n```bash\n# Use existing unified configs\nskill-seekers unified --config configs/react_unified.json\nskill-seekers unified --config configs/django_unified.json\n\n# Or create unified config (mix documentation + GitHub)\ncat > configs/myframework_unified.json << 'EOF'\n{\n  \"name\": \"myframework\",\n  \"description\": \"Complete framework knowledge from docs + code\",\n  \"merge_mode\": \"rule-based\",\n  \"sources\": [\n    {\n      \"type\": \"documentation\",\n      \"base_url\": \"https://docs.myframework.com/\",\n      \"extract_api\": true,\n      \"max_pages\": 200\n    },\n    {\n      \"type\": \"github\",\n      \"repo\": \"owner/myframework\",\n      \"include_code\": true,\n      \"code_analysis_depth\": \"surface\"\n    }\n  ]\n}\nEOF\n\n# Run unified scraper\nskill-seekers unified --config configs/myframework_unified.json\n\n# Package and upload\nskill-seekers package output/myframework/\n# Upload output/myframework.zip to Claude - Done!\n```\n\n**Time:** ~30-45 minutes | **Quality:** Production-ready with conflict detection | **Cost:** Free\n\n**What Makes It Special:**\n\n‚úÖ **Conflict Detection** - Automatically finds 4 types of discrepancies:\n- üî¥ **Missing in code** (high): Documented but not implemented\n- üü° **Missing in docs** (medium): Implemented but not documented\n- ‚ö†Ô∏è **Signature mismatch**: Different parameters/types\n- ‚ÑπÔ∏è **Description mismatch**: Different explanations\n\n‚úÖ **Transparent Reporting** - Shows both versions side-by-side:\n```markdown\n#### `move_local_x(delta: float)`\n\n‚ö†Ô∏è **Conflict**: Documentation signature differs from implementation\n\n**Documentation says:**\n```\ndef move_local_x(delta: float)\n```\n\n**Code implementation:**\n```python\ndef move_local_x(delta: float, snap: bool = False) -> None\n```\n```\n\n‚úÖ **Advantages:**\n- **Identifies documentation gaps** - Find outdated or missing docs automatically\n- **Catches code changes** - Know when APIs change without docs being updated\n- **Single source of truth** - One skill showing intent (docs) AND reality (code)\n- **Actionable insights** - Get suggestions for fixing each conflict\n- **Development aid** - See what's actually in the codebase vs what's documented\n\n**Example Unified Configs:**\n- `configs/react_unified.json` - React docs + GitHub repo\n- `configs/django_unified.json` - Django docs + GitHub repo\n- `configs/fastapi_unified.json` - FastAPI docs + GitHub repo\n\n**Full Guide:** See [docs/UNIFIED_SCRAPING.md](docs/UNIFIED_SCRAPING.md) for complete documentation.\n\n## How It Works\n\n```mermaid\ngraph LR\n    A[Documentation Website] --> B[Skill Seeker]\n    B --> C[Scraper]\n    B --> D[AI Enhancement]\n    B --> E[Packager]\n    C --> F[Organized References]\n    D --> F\n    F --> E\n    E --> G[Claude Skill .zip]\n    G --> H[Upload to Claude AI]\n```\n\n0. **Detect llms.txt** - Checks for llms-full.txt, llms.txt, llms-small.txt first\n1. **Scrape**: Extracts all pages from documentation\n2. **Categorize**: Organizes content into topics (API, guides, tutorials, etc.)\n3. **Enhance**: AI analyzes docs and creates comprehensive SKILL.md with examples\n4. **Package**: Bundles everything into a Claude-ready `.zip` file\n\n## üìã Prerequisites\n\n**Before you start, make sure you have:**\n\n1. **Python 3.10 or higher** - [Download](https://www.python.org/downloads/) | Check: `python3 --version`\n2. **Git** - [Download](https://git-scm.com/) | Check: `git --version`\n3. **15-30 minutes** for first-time setup\n\n**First time user?** ‚Üí **[Start Here: Bulletproof Quick Start Guide](BULLETPROOF_QUICKSTART.md)** üéØ\n\nThis guide walks you through EVERYTHING step-by-step (Python install, git clone, first skill creation).\n\n---\n\n## üöÄ Quick Start\n\n### Method 1: MCP Server for Claude Code (Easiest)\n\nUse Skill Seeker directly from Claude Code with natural language!\n\n```bash\n# Clone repository\ngit clone https://github.com/yusufkaraaslan/Skill_Seekers.git\ncd Skill_Seekers\n\n# One-time setup (5 minutes)\n./setup_mcp.sh\n\n# Restart Claude Code, then just ask:\n```\n\n**In Claude Code:**\n```\nList all available configs\nGenerate config for Tailwind at https://tailwindcss.com/docs\nScrape docs using configs/react.json\nPackage skill at output/react/\n```\n\n**Benefits:**\n- ‚úÖ No manual CLI commands\n- ‚úÖ Natural language interface\n- ‚úÖ Integrated with your workflow\n- ‚úÖ 9 tools available instantly (includes automatic upload!)\n- ‚úÖ **Tested and working** in production\n\n**Full guides:**\n- üìò [MCP Setup Guide](docs/MCP_SETUP.md) - Complete installation instructions\n- üß™ [MCP Testing Guide](docs/TEST_MCP_IN_CLAUDE_CODE.md) - Test all 9 tools\n- üì¶ [Large Documentation Guide](docs/LARGE_DOCUMENTATION.md) - Handle 10K-40K+ pages\n- üì§ [Upload Guide](docs/UPLOAD_GUIDE.md) - How to upload skills to Claude\n\n### Method 2: CLI (Traditional)\n\n#### One-Time Setup: Create Virtual Environment\n\n```bash\n# Clone repository\ngit clone https://github.com/yusufkaraaslan/Skill_Seekers.git\ncd Skill_Seekers\n\n# Create virtual environment\npython3 -m venv venv\n\n# Activate virtual environment\nsource venv/bin/activate  # macOS/Linux\n# OR on Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install requests beautifulsoup4 pytest\n\n# Save dependencies\npip freeze > requirements.txt\n\n# Optional: Install anthropic for API-based enhancement (not needed for LOCAL enhancement)\n# pip install anthropic\n```\n\n**Always activate the virtual environment before using Skill Seeker:**\n```bash\nsource venv/bin/activate  # Run this each time you start a new terminal session\n```\n\n#### Easiest: Use a Preset\n\n```bash\n# Make sure venv is activated (you should see (venv) in your prompt)\nsource venv/bin/activate\n\n# Optional: Estimate pages first (fast, 1-2 minutes)\nskill-seekers estimate configs/godot.json\n\n# Use Godot preset\nskill-seekers scrape --config configs/godot.json\n\n# Use React preset\nskill-seekers scrape --config configs/react.json\n\n# See all presets\nls configs/\n```\n\n### Interactive Mode\n\n```bash\nskill-seekers scrape --interactive\n```\n\n### Quick Mode\n\n```bash\nskill-seekers scrape \\\n  --name react \\\n  --url https://react.dev/ \\\n  --description \"React framework for UIs\"\n```\n\n## üì§ Uploading Skills to Claude\n\nOnce your skill is packaged, you need to upload it to Claude:\n\n### Option 1: Automatic Upload (API-based)\n\n```bash\n# Set your API key (one-time)\nexport ANTHROPIC_API_KEY=sk-ant-...\n\n# Package and upload automatically\nskill-seekers package output/react/ --upload\n\n# OR upload existing .zip\nskill-seekers upload output/react.zip\n```\n\n**Benefits:**\n- ‚úÖ Fully automatic\n- ‚úÖ No manual steps\n- ‚úÖ Works from command line\n\n**Requirements:**\n- Anthropic API key (get from https://console.anthropic.com/)\n\n### Option 2: Manual Upload (No API Key)\n\n```bash\n# Package skill\nskill-seekers package output/react/\n\n# This will:\n# 1. Create output/react.zip\n# 2. Open the output/ folder automatically\n# 3. Show upload instructions\n\n# Then manually upload:\n# - Go to https://claude.ai/skills\n# - Click \"Upload Skill\"\n# - Select output/react.zip\n# - Done!\n```\n\n**Benefits:**\n- ‚úÖ No API key needed\n- ‚úÖ Works for everyone\n- ‚úÖ Folder opens automatically\n\n### Option 3: Claude Code (MCP) - Smart & Automatic\n\n```\nIn Claude Code, just ask:\n\"Package and upload the React skill\"\n\n# With API key set:\n# - Packages the skill\n# - Uploads to Claude automatically\n# - Done! ‚úÖ\n\n# Without API key:\n# - Packages the skill\n# - Shows where to find the .zip\n# - Provides manual upload instructions\n```\n\n**Benefits:**\n- ‚úÖ Natural language\n- ‚úÖ Smart auto-detection (uploads if API key available)\n- ‚úÖ Works with or without API key\n- ‚úÖ No errors or failures\n\n---\n\n## üìÅ Simple Structure\n\n```\ndoc-to-skill/\n‚îú‚îÄ‚îÄ cli/\n‚îÇ   ‚îú‚îÄ‚îÄ doc_scraper.py      # Main scraping tool\n‚îÇ   ‚îú‚îÄ‚îÄ package_skill.py    # Package to .zip\n‚îÇ   ‚îú‚îÄ‚îÄ upload_skill.py     # Auto-upload (API)\n‚îÇ   ‚îî‚îÄ‚îÄ enhance_skill.py    # AI enhancement\n‚îú‚îÄ‚îÄ mcp/                    # MCP server for Claude Code\n‚îÇ   ‚îî‚îÄ‚îÄ server.py           # 9 MCP tools\n‚îú‚îÄ‚îÄ configs/                # Preset configurations\n‚îÇ   ‚îú‚îÄ‚îÄ godot.json         # Godot Engine\n‚îÇ   ‚îú‚îÄ‚îÄ react.json         # React\n‚îÇ   ‚îú‚îÄ‚îÄ vue.json           # Vue.js\n‚îÇ   ‚îú‚îÄ‚îÄ django.json        # Django\n‚îÇ   ‚îî‚îÄ‚îÄ fastapi.json       # FastAPI\n‚îî‚îÄ‚îÄ output/                 # All output (auto-created)\n    ‚îú‚îÄ‚îÄ godot_data/        # Scraped data\n    ‚îú‚îÄ‚îÄ godot/             # Built skill\n    ‚îî‚îÄ‚îÄ godot.zip          # Packaged skill\n```\n\n## ‚ú® Features\n\n### 1. Fast Page Estimation (NEW!)\n\n```bash\nskill-seekers estimate configs/react.json\n\n# Output:\nüìä ESTIMATION RESULTS\n‚úÖ Pages Discovered: 180\nüìà Estimated Total: 230\n‚è±Ô∏è  Time Elapsed: 1.2 minutes\nüí° Recommended max_pages: 280\n```\n\n**Benefits:**\n- Know page count BEFORE scraping (saves time)\n- Validates URL patterns work correctly\n- Estimates total scraping time\n- Recommends optimal `max_pages` setting\n- Fast (1-2 minutes vs 20-40 minutes full scrape)\n\n### 2. Auto-Detect Existing Data\n\n```bash\nskill-seekers scrape --config configs/godot.json\n\n# If data exists:\n‚úì Found existing data: 245 pages\nUse existing data? (y/n): y\n‚è≠Ô∏è  Skipping scrape, using existing data\n```\n\n### 3. Knowledge Generation\n\n**Automatic pattern extraction:**\n- Extracts common code patterns from docs\n- Detects programming language\n- Creates quick reference with real examples\n- Smarter categorization with scoring\n\n**Enhanced SKILL.md:**\n- Real code examples from documentation\n- Language-annotated code blocks\n- Common patterns section\n- Quick reference from actual usage examples\n\n### 4. Smart Categorization\n\nAutomatically infers categories from:\n- URL structure\n- Page titles\n- Content keywords\n- With scoring for better accuracy\n\n### 5. Code Language Detection\n\n```python\n# Automatically detects:\n- Python (def, import, from)\n- JavaScript (const, let, =>)\n- GDScript (func, var, extends)\n- C++ (#include, int main)\n- And more...\n```\n\n### 5. Skip Scraping\n\n```bash\n# Scrape once\nskill-seekers scrape --config configs/react.json\n\n# Later, just rebuild (instant)\nskill-seekers scrape --config configs/react.json --skip-scrape\n```\n\n### 6. Async Mode for Faster Scraping (2-3x Speed!)\n\n```bash\n# Enable async mode with 8 workers (recommended for large docs)\nskill-seekers scrape --config configs/react.json --async --workers 8\n\n# Small docs (~100-500 pages)\nskill-seekers scrape --config configs/mydocs.json --async --workers 4\n\n# Large docs (2000+ pages) with no rate limiting\nskill-seekers scrape --config configs/largedocs.json --async --workers 8 --no-rate-limit\n```\n\n**Performance Comparison:**\n- **Sync mode (threads):** ~18 pages/sec, 120 MB memory\n- **Async mode:** ~55 pages/sec, 40 MB memory\n- **Result:** 3x faster, 66% less memory!\n\n**When to use:**\n- ‚úÖ Large documentation (500+ pages)\n- ‚úÖ Network latency is high\n- ‚úÖ Memory is constrained\n- ‚ùå Small docs (< 100 pages) - overhead not worth it\n\n**See full guide:** [ASYNC_SUPPORT.md](ASYNC_SUPPORT.md)\n\n### 7. AI-Powered SKILL.md Enhancement\n\n```bash\n# Option 1: During scraping (API-based, requires API key)\npip3 install anthropic\nexport ANTHROPIC_API_KEY=sk-ant-...\nskill-seekers scrape --config configs/react.json --enhance\n\n# Option 2: During scraping (LOCAL, no API key - uses Claude Code Max)\nskill-seekers scrape --config configs/react.json --enhance-local\n\n# Option 3: After scraping (API-based, standalone)\nskill-seekers enhance output/react/\n\n# Option 4: After scraping (LOCAL, no API key, standalone)\nskill-seekers enhance output/react/\n```\n\n**What it does:**\n- Reads your reference documentation\n- Uses Claude to generate an excellent SKILL.md\n- Extracts best code examples (5-10 practical examples)\n- Creates comprehensive quick reference\n- Adds domain-specific key concepts\n- Provides navigation guidance for different skill levels\n- Automatically backs up original\n- **Quality:** Transforms 75-line templates into 500+ line comprehensive guides\n\n**LOCAL Enhancement (Recommended):**\n- Uses your Claude Code Max plan (no API costs)\n- Opens new terminal with Claude Code\n- Analyzes reference files automatically\n- Takes 30-60 seconds\n- Quality: 9/10 (comparable to API version)\n\n### 7. Large Documentation Support (10K-40K+ Pages)\n\n**For massive documentation sites like Godot (40K pages), AWS, or Microsoft Docs:**\n\n```bash\n# 1. Estimate first (discover page count)\nskill-seekers estimate configs/godot.json\n\n# 2. Auto-split into focused sub-skills\npython3 -m skill_seekers.cli.split_config configs/godot.json --strategy router\n\n# Creates:\n# - godot-scripting.json (5K pages)\n# - godot-2d.json (8K pages)\n# - godot-3d.json (10K pages)\n# - godot-physics.json (6K pages)\n# - godot-shaders.json (11K pages)\n\n# 3. Scrape all in parallel (4-8 hours instead of 20-40!)\nfor config in configs/godot-*.json; do\n  skill-seekers scrape --config $config &\ndone\nwait\n\n# 4. Generate intelligent router/hub skill\npython3 -m skill_seekers.cli.generate_router configs/godot-*.json\n\n# 5. Package all skills\npython3 -m skill_seekers.cli.package_multi output/godot*/\n\n# 6. Upload all .zip files to Claude\n# Users just ask questions naturally!\n# Router automatically directs to the right sub-skill!\n```\n\n**Split Strategies:**\n- **auto** - Intelligently detects best strategy based on page count\n- **category** - Split by documentation categories (scripting, 2d, 3d, etc.)\n- **router** - Create hub skill + specialized sub-skills (RECOMMENDED)\n- **size** - Split every N pages (for docs without clear categories)\n\n**Benefits:**\n- ‚úÖ Faster scraping (parallel execution)\n- ‚úÖ More focused skills (better Claude performance)\n- ‚úÖ Easier maintenance (update one topic at a time)\n- ‚úÖ Natural user experience (router handles routing)\n- ‚úÖ Avoids context window limits\n\n**Configuration:**\n```json\n{\n  \"name\": \"godot\",\n  \"max_pages\": 40000,\n  \"split_strategy\": \"router\",\n  \"split_config\": {\n    \"target_pages_per_skill\": 5000,\n    \"create_router\": true,\n    \"split_by_categories\": [\"scripting\", \"2d\", \"3d\", \"physics\"]\n  }\n}\n```\n\n**Full Guide:** [Large Documentation Guide](docs/LARGE_DOCUMENTATION.md)\n\n### 8. Checkpoint/Resume for Long Scrapes\n\n**Never lose progress on long-running scrapes:**\n\n```bash\n# Enable in config\n{\n  \"checkpoint\": {\n    \"enabled\": true,\n    \"interval\": 1000  // Save every 1000 pages\n  }\n}\n\n# If scrape is interrupted (Ctrl+C or crash)\nskill-seekers scrape --config configs/godot.json --resume\n\n# Resume from last checkpoint\n‚úÖ Resuming from checkpoint (12,450 pages scraped)\n‚è≠Ô∏è  Skipping 12,450 already-scraped pages\nüîÑ Continuing from where we left off...\n\n# Start fresh (clear checkpoint)\nskill-seekers scrape --config configs/godot.json --fresh\n```\n\n**Benefits:**\n- ‚úÖ Auto-saves every 1000 pages (configurable)\n- ‚úÖ Saves on interruption (Ctrl+C)\n- ‚úÖ Resume with `--resume` flag\n- ‚úÖ Never lose hours of scraping progress\n\n## üéØ Complete Workflows\n\n### First Time (With Scraping + Enhancement)\n\n```bash\n# 1. Scrape + Build + AI Enhancement (LOCAL, no API key)\nskill-seekers scrape --config configs/godot.json --enhance-local\n\n# 2. Wait for new terminal to close (enhancement completes)\n# Check the enhanced SKILL.md:\ncat output/godot/SKILL.md\n\n# 3. Package\nskill-seekers package output/godot/\n\n# 4. Done! You have godot.zip with excellent SKILL.md\n```\n\n**Time:** 20-40 minutes (scraping) + 60 seconds (enhancement) = ~21-41 minutes\n\n### Using Existing Data (Fast!)\n\n```bash\n# 1. Use cached data + Local Enhancement\nskill-seekers scrape --config configs/godot.json --skip-scrape\nskill-seekers enhance output/godot/\n\n# 2. Package\nskill-seekers package output/godot/\n\n# 3. Done!\n```\n\n**Time:** 1-3 minutes (build) + 60 seconds (enhancement) = ~2-4 minutes total\n\n### Without Enhancement (Basic)\n\n```bash\n# 1. Scrape + Build (no enhancement)\nskill-seekers scrape --config configs/godot.json\n\n# 2. Package\nskill-seekers package output/godot/\n\n# 3. Done! (SKILL.md will be basic template)\n```\n\n**Time:** 20-40 minutes\n**Note:** SKILL.md will be generic - enhancement strongly recommended!\n\n## üìã Available Presets\n\n| Config | Framework | Description |\n|--------|-----------|-------------|\n| `godot.json` | Godot Engine | Game development |\n| `react.json` | React | UI framework |\n| `vue.json` | Vue.js | Progressive framework |\n| `django.json` | Django | Python web framework |\n| `fastapi.json` | FastAPI | Modern Python API |\n| `ansible-core.json` | Ansible Core 2.19 | Automation & configuration |\n\n### Using Presets\n\n```bash\n# Godot\nskill-seekers scrape --config configs/godot.json\n\n# React\nskill-seekers scrape --config configs/react.json\n\n# Vue\nskill-seekers scrape --config configs/vue.json\n\n# Django\nskill-seekers scrape --config configs/django.json\n\n# FastAPI\nskill-seekers scrape --config configs/fastapi.json\n\n# Ansible\nskill-seekers scrape --config configs/ansible-core.json\n```\n\n## üé® Creating Your Own Config\n\n### Option 1: Interactive\n\n```bash\nskill-seekers scrape --interactive\n# Follow prompts, it will create the config for you\n```\n\n### Option 2: Copy and Edit\n\n```bash\n# Copy a preset\ncp configs/react.json configs/myframework.json\n\n# Edit it\nnano configs/myframework.json\n\n# Use it\nskill-seekers scrape --config configs/myframework.json\n```\n\n### Config Structure\n\n```json\n{\n  \"name\": \"myframework\",\n  \"description\": \"When to use this skill\",\n  \"base_url\": \"https://docs.myframework.com/\",\n  \"selectors\": {\n    \"main_content\": \"article\",\n    \"title\": \"h1\",\n    \"code_blocks\": \"pre code\"\n  },\n  \"url_patterns\": {\n    \"include\": [\"/docs\", \"/guide\"],\n    \"exclude\": [\"/blog\", \"/about\"]\n  },\n  \"categories\": {\n    \"getting_started\": [\"intro\", \"quickstart\"],\n    \"api\": [\"api\", \"reference\"]\n  },\n  \"rate_limit\": 0.5,\n  \"max_pages\": 500\n}\n```\n\n## üìä What Gets Created\n\n```\noutput/\n‚îú‚îÄ‚îÄ godot_data/              # Scraped raw data\n‚îÇ   ‚îú‚îÄ‚îÄ pages/              # JSON files (one per page)\n‚îÇ   ‚îî‚îÄ‚îÄ summary.json        # Overview\n‚îÇ\n‚îî‚îÄ‚îÄ godot/                   # The skill\n    ‚îú‚îÄ‚îÄ SKILL.md            # Enhanced with real examples\n    ‚îú‚îÄ‚îÄ references/         # Categorized docs\n    ‚îÇ   ‚îú‚îÄ‚îÄ index.md\n    ‚îÇ   ‚îú‚îÄ‚îÄ getting_started.md\n    ‚îÇ   ‚îú‚îÄ‚îÄ scripting.md\n    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n    ‚îú‚îÄ‚îÄ scripts/            # Empty (add your own)\n    ‚îî‚îÄ‚îÄ assets/             # Empty (add your own)\n```\n\n## üéØ Command Line Options\n\n```bash\n# Interactive mode\nskill-seekers scrape --interactive\n\n# Use config file\nskill-seekers scrape --config configs/godot.json\n\n# Quick mode\nskill-seekers scrape --name react --url https://react.dev/\n\n# Skip scraping (use existing data)\nskill-seekers scrape --config configs/godot.json --skip-scrape\n\n# With description\nskill-seekers scrape \\\n  --name react \\\n  --url https://react.dev/ \\\n  --description \"React framework for building UIs\"\n```\n\n## üí° Tips\n\n### 1. Test Small First\n\nEdit `max_pages` in config to test:\n```json\n{\n  \"max_pages\": 20  // Test with just 20 pages\n}\n```\n\n### 2. Reuse Scraped Data\n\n```bash\n# Scrape once\nskill-seekers scrape --config configs/react.json\n\n# Rebuild multiple times (instant)\nskill-seekers scrape --config configs/react.json --skip-scrape\nskill-seekers scrape --config configs/react.json --skip-scrape\n```\n\n### 3. Finding Selectors\n\n```python\n# Test in Python\nfrom bs4 import BeautifulSoup\nimport requests\n\nurl = \"https://docs.example.com/page\"\nsoup = BeautifulSoup(requests.get(url).content, 'html.parser')\n\n# Try different selectors\nprint(soup.select_one('article'))\nprint(soup.select_one('main'))\nprint(soup.select_one('div[role=\"main\"]'))\n```\n\n### 4. Check Output Quality\n\n```bash\n# After building, check:\ncat output/godot/SKILL.md  # Should have real examples\ncat output/godot/references/index.md  # Categories\n```\n\n## üêõ Troubleshooting\n\n### No Content Extracted?\n- Check your `main_content` selector\n- Try: `article`, `main`, `div[role=\"main\"]`\n\n### Data Exists But Won't Use It?\n```bash\n# Force re-scrape\nrm -rf output/myframework_data/\nskill-seekers scrape --config configs/myframework.json\n```\n\n### Categories Not Good?\nEdit the config `categories` section with better keywords.\n\n### Want to Update Docs?\n```bash\n# Delete old data\nrm -rf output/godot_data/\n\n# Re-scrape\nskill-seekers scrape --config configs/godot.json\n```\n\n## üìà Performance\n\n| Task | Time | Notes |\n|------|------|-------|\n| Scraping (sync) | 15-45 min | First time only, thread-based |\n| Scraping (async) | 5-15 min | 2-3x faster with --async flag |\n| Building | 1-3 min | Fast! |\n| Re-building | <1 min | With --skip-scrape |\n| Packaging | 5-10 sec | Final zip |\n\n## ‚úÖ Summary\n\n**One tool does everything:**\n1. ‚úÖ Scrapes documentation\n2. ‚úÖ Auto-detects existing data\n3. ‚úÖ Generates better knowledge\n4. ‚úÖ Creates enhanced skills\n5. ‚úÖ Works with presets or custom configs\n6. ‚úÖ Supports skip-scraping for fast iteration\n\n**Simple structure:**\n- `doc_scraper.py` - The tool\n- `configs/` - Presets\n- `output/` - Everything else\n\n**Better output:**\n- Real code examples with language detection\n- Common patterns extracted from docs\n- Smart categorization\n- Enhanced SKILL.md with actual examples\n\n## üìö Documentation\n\n### Getting Started\n- **[BULLETPROOF_QUICKSTART.md](BULLETPROOF_QUICKSTART.md)** - üéØ **START HERE** if you're new!\n- **[QUICKSTART.md](QUICKSTART.md)** - Quick start for experienced users\n- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Common issues and solutions\n\n### Guides\n- **[docs/LARGE_DOCUMENTATION.md](docs/LARGE_DOCUMENTATION.md)** - Handle 10K-40K+ page docs\n- **[ASYNC_SUPPORT.md](ASYNC_SUPPORT.md)** - Async mode guide (2-3x faster scraping)\n- **[docs/ENHANCEMENT.md](docs/ENHANCEMENT.md)** - AI enhancement guide\n- **[docs/TERMINAL_SELECTION.md](docs/TERMINAL_SELECTION.md)** - Configure terminal app for local enhancement\n- **[docs/UPLOAD_GUIDE.md](docs/UPLOAD_GUIDE.md)** - How to upload skills to Claude\n- **[docs/MCP_SETUP.md](docs/MCP_SETUP.md)** - MCP integration setup\n\n### Technical\n- **[docs/CLAUDE.md](docs/CLAUDE.md)** - Technical architecture\n- **[STRUCTURE.md](STRUCTURE.md)** - Repository structure\n\n## üéÆ Ready?\n\n```bash\n# Try Godot\nskill-seekers scrape --config configs/godot.json\n\n# Try React\nskill-seekers scrape --config configs/react.json\n\n# Or go interactive\nskill-seekers scrape --interactive\n```\n\n## üìù License\n\nMIT License - see [LICENSE](LICENSE) file for details\n\n---\n\nHappy skill building! üöÄ\n",
  "installCommand": "git clone https://github.com/yusufkaraaslan/Skill_Seekers ~/.claude/skills/skill-seekers",
  "defaultBranch": "development",
  "hasMarketplaceJson": false,
  "skillPath": "README.md"
}